<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://cdn.baomitu.com/index/fonts/css?family=Ma Shan Zheng:300,300italic,400,400italic,700,700italic|Noto Sans Simplified Chinese:300,300italic,400,400italic,700,700italic|Noto Serif SC:300,300italic,400,400italic,700,700italic|Monaco:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="//lib.baomitu.com/font-awesome/5.15.4/css/all.min.css">
  <link rel="stylesheet" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
  <link rel="stylesheet" href="//lib.baomitu.com/pace/1.0.2/themes/blue/pace-theme-minimal.min.css">
  <script src="//lib.baomitu.com/pace/1.0.2/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"xuemingde.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":true,"sidebar":{"position":"left","width":300,"display":"always","padding":18,"offset":10,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="我的愿望，世界和平">
<meta property="og:type" content="website">
<meta property="og:title" content="Middle&#39;s blog">
<meta property="og:url" content="https://xuemingde.com/page/14/index.html">
<meta property="og:site_name" content="Middle&#39;s blog">
<meta property="og:description" content="我的愿望，世界和平">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="meadel">
<meta property="article:tag" content="meadel">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://xuemingde.com/page/14/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Middle's blog - 一位程序员的成长之路</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Middle's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">一位程序员的成长之路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-notepad">

    <a href="/notepad/" rel="section"><i class="fa fa-book fa-fw"></i>备忘录</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源库</a>

  </li>
        <li class="menu-item menu-item-collect">

    <a href="/collect/" rel="section"><i class="fa fa-star fa-fw"></i>收藏夹</a>

  </li>
        <li class="menu-item menu-item-links">

    <a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>友链</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

           <div id="container-1">
            <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/3DS4M6Q.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/3DS4M6Q.html" class="post-title-link" itemprop="url">Kafka面试连环炮-上</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-08 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-08T00:00:00+08:00">2022-04-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" itemprop="url" rel="index"><span itemprop="name">消息队列</span></a>
                </span>
            </span>

          
            <span id="/posts/3DS4M6Q.html" class="post-meta-item leancloud_visitors" data-flag-title="Kafka面试连环炮-上" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/3DS4M6Q.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/3DS4M6Q.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>16k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>14 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Kafka-是什么-适应场景有哪些"><a href="#Kafka-是什么-适应场景有哪些" class="headerlink" title="Kafka 是什么, 适应场景有哪些"></a>Kafka 是什么, 适应场景有哪些</h2><p>Kafka 是一个分布式的流式处理平台，用于实时构建流处理应用。主要应用在大数据实时处理领域。Kafka 凭借「<strong>高性能</strong>」、「<strong>高吞吐</strong>」、「<strong>高可用</strong>」、「<strong>低延迟</strong>」、「<strong>可伸缩</strong>」几大特性，成为「<strong>消息队列」</strong>的首选。</p>
<p><strong>其主要设计目标如下：</strong></p>
<blockquote>
<p>1）<strong>高性能：</strong>以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</p>
<p>2）<strong>高吞吐、低延迟：</strong>在非常廉价的机器上也能做到单机支持每秒几十万条消息的传输，并保持毫秒级延迟。</p>
<p>3）<strong>持久性、可靠性：</strong>消息最终被持久化到磁盘，且提供数据备份机制防止数据丢失。</p>
<p>4）<strong>容错性：</strong>支持集群节点故障容灾恢复，即使 Kafka 集群中的某一台 Kafka 服务节点宕机，也不会影响整个系统的功能（若副本数量为N， 则允许N-1台节点故障）。</p>
<p>5）<strong>高并发：</strong>可以支撑数千个客户端同时进行读写操作。</p>
</blockquote>
<p><strong>其适应场景主要有：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0931-ZCwdNL.png" alt="图片"></p>
<blockquote>
<p>1）<strong>日志收集方向：</strong>可以用 Kafka 来收集各种服务的 log，然后统一输出，比如日志系统 elk，用 Kafka 进行数据中转。</p>
<p>2）<strong>消息系统方向：</strong>Kafka 具备系统解耦、副本冗余、流量削峰、消息缓冲、可伸缩性、容错性等功能，同时还提供了消息顺序性保障以及消息回溯功能等。</p>
<p>3）<strong>大数据实时计算方向：</strong>Kafka 提供了一套完整的流式处理框架， 被广泛应用到大数据处理，如与 flink、spark、storm 等整合。</p>
</blockquote>
<h2 id="Kafka-核心组件有哪些-分别有什么作用呢"><a href="#Kafka-核心组件有哪些-分别有什么作用呢" class="headerlink" title="Kafka 核心组件有哪些, 分别有什么作用呢"></a>Kafka 核心组件有哪些, 分别有什么作用呢</h2><p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0932-MsBc1g.png" alt="图片"></p>
<p><strong>Kafka 核心组件的基础概念：</strong></p>
<blockquote>
<p>1）<strong>Producer：</strong>即消息生产者，向 Kafka Broker 发消息的客户端。</p>
<p>2）<strong>Consumer：</strong>即消息消费者，从 Kafka Broker 读消息的客户端。</p>
<p>3）<strong>Consumer Group：</strong>即消费者组，<strong>由多个 Consumer 组成</strong>。消费者组内每个消费者负责消费不同分区的数据，以提高消费能力。<strong>一个分区只能由组内一个消费者消费，不同消费者组之间互不影响</strong>。</p>
<p>4）<strong>Broker：</strong> <strong>一台 Kafka 服务节点就是一个 Broker</strong>。一个集群是由1个或者多个 Broker 组成的，且一个 Broker 可以容纳多个 Topic。</p>
<p>5）<strong>Topic：</strong>一个逻辑上的概念，Topic 将消息分类，生产者和消费者面向的都是同一个 Topic, <strong>同一个 Topic 下的 Partition 的消息内容是不相同的</strong>。</p>
<p>6）<strong>Partition：</strong>为了实现 Topic 扩展性，提高并发能力，一个非常大的 Topic 可以分布到多个 Broker 上，<strong>一个 Topic 可以分为多个 Partition 进行存储，且每个 Partition 是消息内容是有序的</strong>。</p>
<p>7）<strong>Replica：</strong>即副本，为实现<strong>数据备份</strong>的功能，保证集群中的某个节点发生故障时，该节点上的 Partition 数据不丢失，且 Kafka 仍然能够继续工作，为此 Kafka 提供了副本机制，<strong>一个 Topic 的每个 Partition 都有若干个副本，一个 Leader 副本和若干个 Follower 副本</strong>。</p>
<p>8）<strong>Leader：</strong>即每个分区多个副本的主副本，<strong>生产者发送数据的对象，以及消费者消费数据的对象，都是 Leader</strong>。</p>
<p>9）<strong>Follower：</strong>即每个分区多个副本的从副本，<strong>会实时从 Leader 副本中同步数据，并保持和 Leader 数据的同步</strong>。Leader 发生故障时，某个 Follower 还会被选举并成为新的 Leader , 且不能跟 Leader 在同一个 Broker 上, 防止崩溃数据可恢复。</p>
<p>10）<strong>Offset：</strong>消费者消费的位置信息，<strong>监控数据消费到什么位置</strong>，当消费者挂掉再重新恢复的时候，可以从消费位置继续消费。</p>
</blockquote>
<h2 id="在-Kafka-中-Zookeeper-作用是什么"><a href="#在-Kafka-中-Zookeeper-作用是什么" class="headerlink" title="在 Kafka 中 Zookeeper 作用是什么"></a>在 Kafka 中 Zookeeper 作用是什么</h2><p>Kafka 集群能够正常工作，<strong>目前还是</strong>需要依赖于 ZooKeeper，主要用来「<strong>负责 Kafka集群元数据管理，集群协调工作</strong>」，在每个 Kafka 服务器启动的时候去连接并将自己注册到 Zookeeper，类似注册中心。</p>
<p>Kafka 使用 Zookeeper 存放「<strong>集群元数据</strong>」、「<strong>集群成员管理</strong>」、 「<strong>Controller 选举</strong>」、「<strong>其他管理类任务</strong>」等。待 KRaft 提案完成后，Kafka 将完全不依赖 Zookeeper。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0934-e4kwIb.png" alt="图片"></p>
<blockquote>
<p>1）<strong>集群元数据：</strong>Topic 对应 Partition 的所有数据都存放在 Zookeeper 中，且以 Zookeeper 保存的数据为准。</p>
<p>2）<strong>集群成员管理：</strong>Broker 节点的注册、删除以及属性变更操作等。主要包括两个方面：<strong>成员数量的管理</strong>，主要体现在新增成员和移除现有成员；<strong>单个成员的管理</strong>，如变更单个 Broker 的数据等。</p>
<p>3）<strong>Controller 选举：</strong>即选举 Broker 集群的控制器 Controller。其实它除了具有一般 Broker 的功能之外，还具有<strong>选举主题分区 Leader 节点的功能</strong>。在启动 Kafka系统时，其中一个 Broker 会被选举为控制器，负责管理主题分区和副本状态，还会执行分区重新分配的管理任务。如果在 Kafka  系统运行过程中，当前的控制器出现故障导致不可用，那么 Kafka 系统会从其他正常运行的 Broker 中重新选举出新的控制器。</p>
<p>4）<strong>其他管理类任务：</strong>包括但不限于 Topic 的管理、参数配置等等。</p>
</blockquote>
<p>Kafka 3.X 「<strong>2.8版本开始</strong>」为什么移除 Zookeeper 的依赖的原因有以下2点：</p>
<blockquote>
<p>1）<strong>集群运维层面：</strong>Kafka 本身就是一个分布式系统，如果还需要重度依赖 Zookeeper，集群运维成本和系统复杂度都很高。</p>
<p>2）<strong>集群性能层面：</strong>Zookeeper 架构设计并不适合这种高频的读写更新操作, 由于之前的提交位移的操作都是保存在 Zookeeper 里面的，这样的话会严重影响 Zookeeper 集群的性能。</p>
</blockquote>
<h2 id="生产者有哪些发消息的模式"><a href="#生产者有哪些发消息的模式" class="headerlink" title="生产者有哪些发消息的模式"></a>生产者有哪些发消息的模式</h2><p>Kafka 生产者发送消息主要有三种模式:</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0936-L44AG0.png" alt="图片"></p>
<h3 id="发后即忘发送模式"><a href="#发后即忘发送模式" class="headerlink" title="发后即忘发送模式"></a>发后即忘发送模式</h3><p><strong>发后即忘模式「fire-and-forget」，它只管发送消息，并不需要关心消息是否发送成功</strong>。其本质上也是一种<strong>异步发送</strong>的方式，消息先存储在缓冲区中，达到设定条件后再批量进行发送。<strong>这是 kafka 吞吐量最高的方式，但同时也是消息最不可靠的方式</strong>，因为对于发送失败的消息并没有做任何处理，某些异常情况下会导致消息丢失。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;k,v&gt; record = <span class="keyword">new</span> ProducerRecord&lt;k,v&gt;(<span class="string">&quot;this-topic&quot;</span>, key, value);</span><br><span class="line"><span class="keyword">try</span> &#123;  </span><br><span class="line">  <span class="comment">//fire-and-forget 模式     </span></span><br><span class="line">  producer.send(record);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="同步发送模式"><a href="#同步发送模式" class="headerlink" title="同步发送模式"></a>同步发送模式</h3><p>同步发送模式 「<strong>sync</strong>」，调用 send() 方法会返回一个 Future 对象，再通过调用 Future 对象的 get() 方法，等待结果返回，根据返回的结果可以判断消息是否发送成功， 由于是同步发送会阻塞，只有当消息通过 <strong>get()</strong> 返回数据时，才会继续下一条消息的发送。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;k,v&gt; record = <span class="keyword">new</span> ProducerRecord&lt;k,v&gt;(<span class="string">&quot;this-topic&quot;</span>, key, value);</span><br><span class="line"><span class="keyword">try</span> &#123; <span class="comment">//sync 模式 调用future.get() </span></span><br><span class="line">  future = producer.send(record); </span><br><span class="line">  RecordMetadata metadata = future.get();</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">&#125;producer.flush();</span><br><span class="line">producer.close();</span><br></pre></td></tr></table></figure>
<h3 id="异步发送模式"><a href="#异步发送模式" class="headerlink" title="异步发送模式"></a>异步发送模式</h3><p>异步发送模式「<strong>async</strong>」，在调用 send() 方法的时候指定一个 callback 函数，当 Broker 接收到返回的时候，该 callback 函数会被触发执行，通过回调函数能够对异常情况进行处理，当调用了回调函数时，只有回调函数执行完毕生产者才会结束，否则一直会阻塞。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//intercept the record, which can be potentially modified; this method does not throw exceptions        </span></span><br><span class="line">  ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="keyword">this</span>.interceptors == <span class="keyword">null</span> ? record :<span class="keyword">this</span>.interceptors.onSend(record);        </span><br><span class="line">  <span class="keyword">return</span> doSend(interceptedRecord, callback);&#125;</span><br></pre></td></tr></table></figure>
<p><strong>以上三种方式各有各的特点，具体还要看业务的应用场景适合哪一种：</strong></p>
<blockquote>
<p>1）<strong>场景1：</strong>如果业务只是关心消息的吞吐量，且允许少量消息发送失败，也不关注消息的发送顺序的话，那么可以使用发后即忘发送「<strong>fire-and-forget</strong>」的方式，配合参数 acks = 0，这样生产者并不需要等待服务器的响应，以网络能支持的最大速度发送消息。</p>
<p>2）<strong>场景2：</strong>如果业务要求消息必须是按<strong>顺序发送</strong>的话，且数据只能落在一个 Partition 上，那么可以使用同步发送「<strong>sync</strong>」的方式，并结合参数来设置 retries 的值让消息发送失败时可以进行多次重试「<strong>retries &gt; 0</strong>」，再结合参数设置「<strong>acks=all &amp; max_in_flight_requests_per_connection=1</strong>」，可以控制生产者在收到服务器成功响应之前只能发送1条消息，在消息发送成功后立即进行 flush, 从而达到控制消息顺序发送。</p>
<p>3）<strong>场景3：</strong>如果业务需要知道消息是否发送成功，但对消息的顺序并不关心的话，那么可以用「<strong>异步async + 回调 callback 函数</strong>」的方式来发送消息，并配合参数 retries=0，待发送失败时将失败的消息记录到日志文件中进行后续处理。</p>
</blockquote>
<h2 id="Kafka-为什么要设计分区"><a href="#Kafka-为什么要设计分区" class="headerlink" title="Kafka 为什么要设计分区"></a>Kafka 为什么要设计分区</h2><p>其实这个问题说来很简单, 假如不进行分区的话就如同 MySQL 单表存储一样，发消息就会被集中存储，这样会导致某台 Kafka 服务器存储 Topic  消息过多，如果在写消息压力很大的情况下，最终会导致这台 Kafka 服务器吞吐量出现瓶颈, 因此 Kafka 设计了分区的概念，同时也带来了「<strong>负载均衡</strong>」、「<strong>横向扩展</strong>」的能力，如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0944-PgOS8q.png" alt="图片"></p>
<blockquote>
<p>1）<strong>负载均衡：</strong>发送消息时可以根据分区的数量进行数据均匀分布，使其落在不同的分区上, 这样可以提高并发写性能；同时消费的时候多个订阅者可以从一个或者多个分区中同时消费数据，以支撑海量数据处理能力，提高读消息性能。</p>
<p>2）<strong>横向扩展：</strong>可以将一个 Topic 分成了多个 Partition，将不同的 Partition 尽可能的部署在不同的物理节点上，这样扩展起来非常方便，另外一个消费者可以消费多个分区中的数据，但是这样还是不能够充分的发挥横向扩展，<strong>这时候消费者组就出现了</strong>，我们用消费者组，来消费整个的 Topic，一个消费者消费 Topic 中的一个分区。</p>
</blockquote>
<h2 id="生产者发送消息时如何选择分区的"><a href="#生产者发送消息时如何选择分区的" class="headerlink" title="生产者发送消息时如何选择分区的"></a>生产者发送消息时如何选择分区的</h2><p>生产者发送消息的时候选择分区的策略方式主要有以下4种：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0945-fF7vL4.png" alt="图片"></p>
<blockquote>
<p>1）<strong>轮询策略：</strong>顺序分配消息，即按照消息顺序依次发送到某Topic下不同的分区，它总是能保证消息最大限度地被平均分配到所有分区上，<strong>如果消息在创建的时候 key 为 null， 那么Kafka 默认会采用这种策略</strong>。</p>
<p>2）<strong>消息key指定分区策略：</strong>Kafka 允许为每条消息定义 key，即消息在创建的时候 key 不为空，此时 Kafka 会根据消息的 key 进行 hash, 然后根据 hash 值对 Partition 进行取模映射到指定的分区上， 这样的好处就是相同 key的消息会发送到同一个分区上， 这样 <strong>Kafka 虽然不能保证全局有序，但是可以保证每个分区的消息是有序的，这就是消息分区有序性</strong>，适应场景有下单支付的时候希望消息有序，可以通过订单 id 作为 key 发送消息达到分区有序性。</p>
<p>3）<strong>随机策略：</strong>随机发送到某个分区上，看似也是将消息均匀打散分配到各个分区，但是性能还是无法跟轮询策略比，「<strong>如果追求数据的均匀分布，最好还是使用轮询策略</strong>」。</p>
<p>4）<strong>自定义策略：</strong>可以通过实现 org.apache.kafka.clients.producer.Partitioner 接口，重写 partition 方法来达到自定义分区效果。</p>
</blockquote>
<h2 id="Kafka-如何合理设置分区数-越多越好吗"><a href="#Kafka-如何合理设置分区数-越多越好吗" class="headerlink" title="Kafka 如何合理设置分区数,越多越好吗"></a>Kafka 如何合理设置分区数,越多越好吗</h2><p><strong>一、Kafka 如何合理设置分区数</strong></p>
<p>首先我们要<strong>了解在 Partition 级别上达到负载均衡是实现高吞吐量的关键</strong>，合适的 Partition 数量可以达到并行读写和负载均衡的目的，<strong>需要根据每个分区的生产者和消费者的目标吞吐量进行估计</strong>。</p>
<p>此时我们可以遵循一定的步骤来计算确定分区数：</p>
<blockquote>
<p>1）首先根据某个 Topic 当前接收的数据量等经验来确定分区的初始值。</p>
<p>2）然后针对这个 Topic，进行测试 Producer 端吞吐量和 Consumer 端的吞吐量。</p>
<p>3）测试的结果， 假设此时他们的值分别是 Tp「<strong>Producer 端吞吐量</strong>」、Tc「<strong>负Consumer 端吞吐量</strong>」，总的目标吞吐量是 Tt， 单位是 MB/s， 那么结果 numPartition = Tt / max (Tp, Tc)。</p>
<p>4）<strong>特殊说明：</strong>测试 Tp 通常是很容易的，因为它的逻辑非常简单，就是直接发送消息到 Kafka 就好了。而测试 Tc 通常与应用消费消息后进行其他什么处理有关，相对复杂一些。</p>
</blockquote>
<p><strong>二、分区设置越多越好吗？</strong></p>
<p>首先 <strong>Kafka 高吞吐量的原因之一就是通过 Partition 将 Topic 中的消息均衡保存到 Kafka 集群中不同的 Broker 中</strong>。</p>
<p>「<strong>理论上说，如果一个 Topic 分区越多，整个集群所能达到的吞吐量就越大</strong>」。但是，实际生产中 Kafka Topic 的分区数真的配置越多越好吗？<strong>很显然不是！分区数过多会有什么弊端和问题呢，我们可以从下面4个方向进行深度分析：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0946-lFzucv.png" alt="图片"></p>
<h3 id="使用内存方面分析"><a href="#使用内存方面分析" class="headerlink" title="使用内存方面分析"></a><strong>使用内存方面分析</strong></h3><blockquote>
<p>1）<strong>Broker端：</strong>有很多组件都在内存中维护了分区级别的缓存，比如 Controller，FetcherManager 等，因此分区数越多，这类缓存的成本就越大。</p>
<p>2）<strong>Producer端：</strong>比如参数 batch.size，默认是16KB。它会为每个分区缓存消息，在数据积累到一定大小或者足够的时间时，累积的消息将会从缓存中移除并发往Broker 节点。这个功能是为了提高性能而设计，但是随着分区数增多，这部分缓存所需的内存占用也会更多。</p>
<p>3）<strong>Consumer端：</strong>消费者数跟分区数是直接挂钩的，在消费消息时的内存占用、以及为达到更高的吞吐性能需要开启的 Consumer 数也会随着分区数增加而增加。</p>
</blockquote>
<h3 id="消耗文件句柄方面分析"><a href="#消耗文件句柄方面分析" class="headerlink" title="消耗文件句柄方面分析"></a><strong>消耗文件句柄方面分析</strong></h3><p><strong>在 Kafka 的 Broker 中，每个 Partition 都会对应磁盘文件系统中一个目录</strong>。在 Kafka 的日志文件目录中，每个日志数据段都会分配三个文件，两个索引文件和一个数据文件。<strong>每个 Broker 会为每个日志段文件打开两个 index 文件句柄和一个 log 数据文件句柄</strong>。因此，随着 Partition 的增多，所需要保持打开状态的文件句柄数也就越多，最终可能超过底层操作系统配置的文件句柄数量限制。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0947-XYbmGY.png" alt="图片"></p>
<h3 id="端到端的延迟方面分析"><a href="#端到端的延迟方面分析" class="headerlink" title="端到端的延迟方面分析"></a><strong>端到端的延迟方面分析</strong></h3><p>首先我们得先了解 Kafka 端对端延迟是什么? Producer 端发布消息到 Consumer 端接收消息所需要的时间，<strong>即 Consumer 端接收消息的时间减去 Producer 端发布消息的时间</strong>。</p>
<p>在 Kafka 中只对「<strong>已提交的消息做最大限度的持久化保证不丢失</strong>」，因此 Kafka 只有在消息提交之后，才会将消息暴露给消费者。<strong>此时如果分区越多那么副本之间需要同步的数据就会越多</strong>，假如消息需要在所有 ISR 副本集合列表同步复制完成之后才能进行暴露。<strong>因此 ISR 副本集合间复制数据所花时间将是 kafka 端对端延迟的最主要部分</strong>。</p>
<p>此时我们可以通过加大 kafka 集群来进行缓解。比如，我们将 100 个分区 Leader 放到一个 Broker 节点和放到 10 个 Broker  节点，它们之间的延迟是不一样的。如在 10 个 Broker 节点的集群中，每个 Broker 节点平均只需要处理  10 个分区的数据复制。此时端对端的延迟将会变成原来的十分之一。</p>
<p><strong>因此根据实战经验，如果你特别关心消息延迟问题的话，此时限制每个 Broker 节点的 Partition 数量是一个非常不错的主意：</strong>对于 N 个 Broker 节点和复制副本因子「<strong>replication-factor</strong>」为 F 的 Kafka 集群，那么整个 Kafka 集群的 Partition 数量最好不超过 「<strong>100 * N * F</strong>」 个，即单个  Broker 节点 Partition 的 Leader 数量不超过100。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0948-jPFAuB.png" alt="图片"></p>
<h3 id="高可用性方面分析"><a href="#高可用性方面分析" class="headerlink" title="高可用性方面分析"></a><strong>高可用性方面分析</strong></h3><p><strong>我们知道 Kafka 是通过多副本复制技术来实现集群的高可用和稳定性的</strong>。每个 Partition 都会有多个数据副本，每个副本分别存在于不同的 Broker 上。所有的数据副本中，其中一个数据副本为 Leader，其他的数据副本为 Follower。</p>
<p><strong>在Kafka集群内部，所有的数据副本采用自动化的方式管理且会确保所有副本之间的数据是保持同步状态的。</strong>当 Broker 发生故障时，对于 Leader 副本所在 Broker 的所有 Partition 将会变得暂不可用。Kafka  将自动在其它副本中选择出一个 Leader，用于接收客户端的请求。这个过程由 Kafka Controller 节点 Broker  自动选举完成。</p>
<p>正常情况下，当一个 Broker 在有计划地停止服务时候，那么 Controller 会在服务停止之前，将该 Broker上 的所有 Leader  副本一个个地移走。对于单个 Leader 副本的移动速度非常快，从客户层面看，有计划的服务停服只会导致系统很短时间窗口不可用。</p>
<p>但是，当 Broker 不是正常停止服务时「<strong>kill -9 强杀方式</strong>」，系统的不可用时间窗口将会与受影响的 Partition 数量有关。如果此时发生宕机的 Broker 是 Controller 节点时, 这时 Controller 节点故障恢复会自动的进行，<strong>但是新的 Controller 节点需要从 Zookeeper 中读取每一个 Partition 的元数据信息用于初始化数据</strong>。假设一个 Kafka 集群存在10000个 Partition，从 Zookeeper 中恢复元数据时每个 Partition 大约花费2ms，则 Controller 恢复将会增加约20秒的不可用时间窗口。</p>
<p><strong>总之，通常情况下 Kafka 集群中越多的 P**</strong>artition 会带来越高的吞吐量。但是，如果 Kafka 集群中 Partition 总量过大或者单个 Broker 节点 Partition 过多，都可能会对系统的可用性和消息延迟带来潜在的负面影响，需要引起我们的重视。</p>
<h2 id="如何保证-Kafka-中的消息是有序的"><a href="#如何保证-Kafka-中的消息是有序的" class="headerlink" title="如何保证 Kafka 中的消息是有序的"></a>如何保证 Kafka 中的消息是有序的</h2><p>我们知道在 Kafka 中，并不保证消息全局有序，但是可以<strong>保证分区有序性，</strong>分区与分区之间是无序的。<strong>那么如何保证 Kafka 中的消息是有序的呢？</strong> 可以从以下三个方面来入手分析：</p>
<h3 id="生产端-Producer"><a href="#生产端-Producer" class="headerlink" title="生产端 Producer"></a><strong>生产端 Producer</strong></h3><p>在第4道题「<strong>生产者有哪些发送模式</strong>」的最后的场景分析里面简单的说明了下, 这里再详细的进行分析下：</p>
<p>首先 Kafka 的 Producer 端发送消息，如果是不对默认参数进行任何设置且网络没有抖动的情况下，消息是可以一批批的按消息发送的顺序被发送到 Kafka Broker 端。但是，一旦有网络波动了，则消息就可能出现乱序。</p>
<p><strong>所以，要严格保证 Kafka 发消息有序，首先要考虑用同步的方式来发送消息, 两种同步发送的方式如下:</strong></p>
<blockquote>
<p>1）<strong>设置消息响应参数 acks = all &amp;  max.in.flight.requests.per.connection = 1：</strong>发送端将会在一条消息发出后，响应必须满足 acks 设置的参数后，才会发送下一条消息。虽然在使用时还是异步发送的方式，其实底层已经是一条接一条的发送了。</p>
<p>2）<strong>Sync发送方式：</strong>当调用 KafkaProducer 的 send() 后，返回的 Future 对象的 get 方式阻塞等待结果。根据返回的结果可以判断是否发送成功, <strong>由于是同步发送会阻塞, 只有当消息通过 get() 返回数据时，才会继续下一条消息的发送</strong>。</p>
<p>通过上面方式还可能出现消息重发和幂等问题:</p>
<p>1）<strong>重发问题：</strong>Kafka 在消息发送出现问题时，通过判断是否可以自动重试恢复，如果是可以自动恢复的问题，设置 retries &gt; 0，让 Kafka 自动重试。</p>
<p>2）<strong>幂等问题：Kafka 1.0 之后的版本，Producer 端引入了幂等特性。设置enable.idempotence = true,  幂等特性可以给消息添加序列号，即每次发送会把序列号递增 1。</strong>开启了 Kafka Producer端的幂等特性后，我们就可以通过设置参数max.in.flight.requests.per.connection = 5 「默认值」, 这样当 Kafka 发消息的时候，由于消息有了序列号当发送消息出现错误的时候，Kafka 底层会通过获取服务器端的最近几条日志的序列号和发送端需要重新发送的消息序列号做对比，如果是连续的，那么就可以继续发送消息，保证消息顺序。</p>
</blockquote>
<h3 id="服务端-Broker"><a href="#服务端-Broker" class="headerlink" title="服务端 Broker"></a><strong>服务端 Broker</strong></h3><p>在 Kafka 中，Topic 只是一个逻辑上的概念，<strong>而组成 Topic 的分区 Partition 才是真正存消息的地方</strong>。</p>
<p>Kafka 只保证单分区内的消息是有序的，<strong>所以如果要保证业务全局严格有序，就要设置 Topic 为单分区的方式</strong>。不过对业务来说一般不需要考虑全局有序的，只需要<strong>保证业务中不同类别的消息有序</strong>即可。</p>
<p><strong>但是这里有个必须要受到重视的问题</strong>，就是当我们对分区 Partition 进行数量改变的时候，由于是简单的 Hash 算法会把以前可能分到相同分区的消息分到别的分区上。这样就不能保证消息顺序了。面对这种情况，<strong>就需要在动态变更分区的时候，考虑对业务的影响。有可能需要根据业务和当前分区需求，重新划分消息类别</strong>。</p>
<h3 id="消费端-Consumer"><a href="#消费端-Consumer" class="headerlink" title="消费端 Consumer"></a><strong>消费端 Consumer</strong></h3><p>在 Consumer 端，<strong>根据 Kafka 的模型，一个 Topic 下的每个分区只能从属于这个 Topic 的消费者组中的某一个消费者</strong>。</p>
<p>当消息被发送分配到同一个 Partition 中，消费者从 Partition 中取出来数据的时候，也一定是有顺序的，没有错乱。</p>
<p>但是消费者可能会有多个线程来并发来消费消息。如果单线程消费数据，吞吐量太低了，而多个线程并发消费的话，顺序可能就乱掉了。</p>
<p><strong>此时可以通过写多个内存队列，将相同 key 的消息都写入同一个队列，然后对于多个线程，每个线程分别消息一个队列即可保证消息顺序</strong>。</p>
<h2 id="Kafka-为什么不支持读写分离呢"><a href="#Kafka-为什么不支持读写分离呢" class="headerlink" title="Kafka 为什么不支持读写分离呢"></a>Kafka 为什么不支持读写分离呢</h2><p>在很多主从模型系统中，是允许从节点可以对外提供读服务的，<strong>只不过 Kafka 当初为了避免数据不一致的问题，而采用了通过主节点来统一提供服务的方式。</strong></p>
<p><strong>不支持读写分离的原因有2点：</strong></p>
<blockquote>
<p>1）<strong>场景不一致：</strong>读写分离架构适用于那种读操作负载很大，但写操作相对不频繁的场景，但是 Kafka 显然不适合这种场景。</p>
<p>2）<strong>延迟问题：</strong>Kafka 通过 PULL 方式来实现数据同步，因此 Leader 副本和 Follower 副本存在数据不一致的情况， 如果允许 Follower 副本提供读服务的话，就会带来消息滞后的问题。</p>
</blockquote>
<h2 id="Kafka-副本有哪两种，作用是什么"><a href="#Kafka-副本有哪两种，作用是什么" class="headerlink" title="Kafka 副本有哪两种，作用是什么"></a>Kafka 副本有哪两种，作用是什么</h2><p>在 Kafka 中，为实现「<strong>数据备份</strong>」的功能，保证集群中的某个节点发生故障时，该节点上的 Partition 数据不丢失，且 Kafka 仍然能够继续工作，<strong>为此 Kafka 提供了副本机制，</strong> <strong>一个 Topic 的每个 Partition 都有若干个副本，一个 Leader 副本和若干个 Follower 副本</strong>。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0953-dFYtYN.png" alt="图片"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0953-0rZ5gK.png" alt="图片"></p>
<blockquote>
<p>1）Leader 主副本负责对外提供读写数据服务。</p>
<p>2）Follower 从副本只负责和 Leader 副本保持数据同步，并不对外提供任何服务。</p>
</blockquote>
<h2 id="Kafka-能否手动删除消息"><a href="#Kafka-能否手动删除消息" class="headerlink" title="Kafka 能否手动删除消息"></a>Kafka 能否手动删除消息</h2><p>首先 Kafka 是支持手动删除消息的， 当然它本身提供了消息留存策略，能够自动删除过期的消息。</p>
<p>Kafka 将消息存储到磁盘中，随着写入数据不断增加，磁盘占用空间越来越大，为了控制占用空间就需要对消息做一定的清理操作。Kafka  存储日志结构分析中每一个分区副本（Replica）都对应一个 Log，而 Log 又可以分为多个日志分段（LogSegment），这样就便于  Kafka 对日志的清理操作。</p>
<blockquote>
<p>1）<strong>普通消息：</strong>我们可以使用 Kafka-delete-records 命令或者通过程序调用 Admin.deleteRecords 方法来删除消息。两者底层都是调用 Admin 的 deleteRecords 的方法，通过将分区的 LEO 值抬高来间接删除消息。</p>
<p>2）<strong>设置key且参数 cleanup.policy=delete/campact 的消息：</strong>可以依靠 Log Cleaner 组件提供的功能删除该 Key 的消息。</p>
<p><strong>日志删除（Log Retention）：</strong>按照一定的保留策略直接删除不符合条件的日志分段（LogSegment）。</p>
<p><strong>日志压缩（Log Compaction）：</strong>针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。</p>
</blockquote>
<h3 id="日志删除"><a href="#日志删除" class="headerlink" title="日志删除"></a><strong>日志删除</strong></h3><p>Kafka 的日志管理器（LogManager）中有一个专门的日志清理任务通过周期性检测和删除不符合条件的日志分段文件（LogSegment），这里我们可以通过设置 Kafka Broker 端的参数「 <strong>log.retention.check.interval.ms</strong>」，默认值为300000，即5分钟。</p>
<p>在 Kafka 中一共有3种保留策略：</p>
<h4 id="基于时间策略"><a href="#基于时间策略" class="headerlink" title="基于时间策略"></a>基于时间策略</h4><p>日志删除任务会周期检查当前日志文件中是否有保留时间超过设定的阈值<strong>(retentionMs)</strong> 来寻找可删除的日志段文件集合(deletableSegments)。</p>
<p>其中 <strong>retentionMs</strong> 可以通过 Kafka Broker 端的这几个参数的大小判断的</p>
<p><code>log.retention.ms &gt; log.retention.minutes &gt; log.retention.hours</code>优先级来设置，<strong>默认情况只会配置 log.retention.hours 参数，值为168即为7天。</strong></p>
<p>这里需要注意：删除过期的日志段文件，并不是简单的根据该日志段文件的修改时间计算的，而是要根据该日志段中最大的时间戳 largestTimeStamp  来计算的，首先要查询该日志分段所对应的时间戳索引文件，查找该时间戳索引文件的最后一条索引数据，如果时间戳值大于0，则取值，否则才会使用最近修改时间（lastModifiedTime）。</p>
<p><strong>【删除步骤】：</strong></p>
<ol>
<li><p>首先从 Log 对象所维护的日志段的跳跃表中移除要删除的日志段，用来确保已经没有线程来读取这些日志段。</p>
</li>
<li><p>将日志段所对应的所有文件，包括索引文件都添加上“.deleted”的后缀。</p>
</li>
<li><p>最后交给一个以“delete-file”命名的延迟任务来删除这些以“ .deleted ”为后缀的文件。默认1分钟执行一次， 可以通过 <code>file.delete.delay.ms</code> 来配置。</p>
</li>
</ol>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0958-azAo2i.png" alt="图片"></p>
<h4 id="基于日志大小策略"><a href="#基于日志大小策略" class="headerlink" title="基于日志大小策略"></a>基于日志大小策略</h4><p>日志删除任务会周期检查当前日志大小是否超过设定的阈值<strong>(retentionSize)</strong> 来寻找可删除的日志段文件集合<strong>(deletableSegments)</strong>。</p>
<p>其中<strong>retentionSize</strong>这里我们可以通过 Kafka Broker 端的参数log.retention.bytes 来设置， 默认值为-1，即无穷大。</p>
<p>这里需要注意的是 log.retention.bytes 设置的是Log中所有日志文件的大小，而不是单个日志段的大小。单个日志段可以通过参数 log.segment.bytes 来设置，默认大小为1G。</p>
<p>【删除步骤】：</p>
<ol>
<li><p>首先计算日志文件的总大小Size和 retentionSize 的差值，即需要删除的日志总大小。</p>
</li>
<li><p>然后从日志文件中的第一个日志段开始进行查找可删除的日志段的文件集合(deletableSegments)</p>
</li>
<li><p>找到后就可以进行删除操作了</p>
</li>
</ol>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/0959-3TFZgh.png" alt="图片"></p>
<h4 id="基于日志起始偏移量"><a href="#基于日志起始偏移量" class="headerlink" title="基于日志起始偏移量"></a>基于日志起始偏移量</h4><p>该策略判断依据是日志段的下一个日志段的起始偏移量 baseOffset 是否小于等于 logStartOffset，如果是，则可以删除此日志分段。</p>
<p><strong>【如下图所示 删除步骤】：</strong></p>
<ol>
<li><p>首先从头开始遍历每个日志段，日志段 1 的下一个日志分段的起始偏移量为20，小于 logStartOffset 的大小，将日志段1加入deletableSegments。</p>
</li>
<li><p>日志段2的下一个日志偏移量的起始偏移量为35，也小于 logStartOffset 的大小，将日志分段2页加入 deletableSegments。</p>
</li>
<li><p>日志段3的下一个日志偏移量的起始偏移量为50，也小于 logStartOffset 的大小，将日志分段3页加入 deletableSegments。</p>
</li>
<li><p>日志段4的下一个日志偏移量通过对比后，在 logStartOffset 的右侧，那么从日志段4开始的所有日志段都不会加入 deletableSegments。</p>
</li>
<li><p>待收集完所有的可删除的日志集合后就可以直接删除了。</p>
</li>
</ol>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1000-4Y1EXb.png" alt="图片"></p>
<h3 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a><strong>日志压缩</strong></h3><p><strong>日志压缩 Log Compaction 对于有相同key的不同value值，只保留最后一个版本。</strong>如果应用只关心 key 对应的最新 value 值，则可以开启 Kafka 相应的日志清理功能，Kafka 会定期将相同 key 的消息进行合并，只保留最新的 value 值。</p>
<p>Log Compaction 可以类比 Redis 中的 RDB 的持久化模式。我们可以想象下，如果每次消息变更都存 Kafka，在某一时刻，  Kafka 异常崩溃后，如果想快速恢复，可以直接使用日志压缩策略， 这样在恢复的时候只需要恢复最新的数据即可，这样可以加快恢复速度。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1001-iEOvMX.png" alt="图片"></p>
<h2 id="Kafka-读写数据这么快是如何做到的"><a href="#Kafka-读写数据这么快是如何做到的" class="headerlink" title="Kafka 读写数据这么快是如何做到的"></a>Kafka 读写数据这么快是如何做到的</h2><h3 id="顺序追加写"><a href="#顺序追加写" class="headerlink" title="顺序追加写"></a><strong>顺序追加写</strong></h3><p>kafka 在写数据的时是以「<strong>磁盘顺序写」</strong>的方式来进行落盘的, 即将数据追加到文件的末尾。对于普通机械磁盘, 如果是随机写的话, 涉及到磁盘寻址的问题, 导致性能极低,  <strong>但是如果只是按照顺序的方式追加文件末尾的话, 这种磁盘顺序写的性能基本可以跟写内存的性能差不多的</strong>。下图所示普通机械磁盘的顺序I/O性能指标是53.2M values/s。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1002-MuNvh7.png" alt="图片"></p>
<h3 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a><strong>Page Cache</strong></h3><p>首先 Kafka 为了保证磁盘写入性能，<strong>通过 mmap 内存映射的方式利用操作系统的 Page Cache 异步写入 。</strong>也可以称为 os cache，意思就是操作系统自己管理的缓存。<strong>那么在写磁盘文件的时候，就可以先直接写入 os cache 中，接下来由操作系统自己决定什么时候把 os cache 里的数据真正刷入到磁盘中, 这样大大提高写入效率和性能</strong>。 如下图所示:</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1002-MQuUfH.png" alt="图片"></p>
<h3 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a><strong>零拷贝技术</strong></h3><p>kafka 为了解决<strong>内核态和用户态数据不必要 Copy</strong> 这个问题, 在读取数据的时候就引入了「<strong>零拷贝技术</strong>」。即让操作系统的 os cache 中的数据<strong>直接发送到</strong>网卡后传出给下游的消费者，中间跳过了两次拷贝数据的步骤，从而减少拷贝的 CPU 开销, 减少用户态内核态的上下文切换次数, 从而优化数据传输的性能, <strong>而Socket缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到Socket缓存</strong>，如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1003-KggNcw.png" alt="图片"></p>
<p>在 Kafka 中主要有以下两个地方使用到了「<strong>零拷贝技术</strong>」<strong>:</strong></p>
<blockquote>
<p>1）<strong>基于 mmap 机制实现的索引文件：</strong>首先索引文件都是<strong>基于 MappedByBuffer 实现</strong>，即让用户态和内核态来共享内核态的数据缓冲区，此时数据不需要 Copy 到用户态空间。虽然 mmap 避免了不必要的 Copy，但是在不同操作系统下， 其创建和销毁成功是不一样的，不一定都能保证高性能。所以在 Kafka 中只有索引文件使用了 mmap。</p>
<p>2）<strong>基于sendfile 机制实现的日志文件读写：</strong>在 Kafka 传输层接口中有个 TransportLayer 接口，它的实现类中有使用了 Java FileChannel 中  transferTo 方法。该方法底层就是使用 sendfile 实现的零拷贝机制， 目前只是在 I/O 通道是普通的 PLAINTEXT  的时候才会使用到零拷贝机制。</p>
</blockquote>
<h3 id="消息批量发送"><a href="#消息批量发送" class="headerlink" title="消息批量发送"></a><strong>消息批量发送</strong></h3><p>Kafka 在发送消息的时候并不是一条条的发送的，而是会<strong>把多条消息合并成一个批次**</strong>Batch<strong> </strong>进行处理发送**，消费消息也是同样，一次拉取一批次的消息进行消费。如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1003-aQzv4L.png" alt="图片"></p>
<h3 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a><strong>数据压缩</strong></h3><p>在 Kafka 中三个端都使用了优化后的压缩算法，<strong>压缩有助于提高吞吐量, 降低延迟并提高磁盘利用率</strong>。Kafka 底层支持多种压缩算法: <strong>lz4, snappy, gzip</strong>, 从Kafka 2.1.0 开始新增了 <strong>ZStandard</strong> 算法, 该算法是 Facebook 开源的压缩算法,  能提供超高的压缩比。</p>
<p>在 Kafka 中, 压缩可能会发生在两个地方: <strong>生产者端和Broker端</strong>。一句话总结下压缩和解压缩, 即 Producer 端压缩, Broker 端保持, Consumer 端解压缩，这样可以节省大量的网络和磁盘开销。</p>
<h2 id="Kafka-消费模型有哪些"><a href="#Kafka-消费模型有哪些" class="headerlink" title="Kafka 消费模型有哪些"></a>Kafka 消费模型有哪些</h2><p>一般情况下消息消费总共有两种模式：「<strong>推模型</strong>」和 「<strong>拉模型</strong>」。在 Kafka 中的消费模型是属于「<strong>拉模型</strong>」，此模式的消息消费方式实现有两种：「<strong>点对点方式</strong>」和 「<strong>发布订阅方式</strong>」。</p>
<h3 id="点对点方式"><a href="#点对点方式" class="headerlink" title="点对点方式"></a><strong>点对点方式</strong></h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1005-qX8nJg.png" alt="图片"></p>
<p><strong>点对点方式:</strong> 假如所有消费者都同属于一个消费组的话，此时所有的消息都会被分配给每一个消费者，<strong>但是消息只会被其中一个消费者进行消费</strong>。</p>
<h3 id="发布订阅方式"><a href="#发布订阅方式" class="headerlink" title="发布订阅方式"></a><strong>发布订阅方式</strong></h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1005-TENKds.png" alt="图片"></p>
<p><strong>发布订阅:</strong> 假如所有消费者属于不同的消费组，此时所有的消息都会被分配给每一个消费者，<strong>每个消费者都会收到该消息</strong>。</p>
<h2 id="什么是消费者组-有什么作用"><a href="#什么是消费者组-有什么作用" class="headerlink" title="什么是消费者组,有什么作用"></a>什么是消费者组,有什么作用</h2><p>首先我来看看什么是「<strong>消费者组</strong>」:</p>
<p>消费者组 Consumer Group，顾名思义就是由多个 Consumer 组成，且拥有一个公共且唯一的 Group ID。组内每个消费者负责消费不同分区的数据，<strong>但一个分区只能由一个组内消费者消费，</strong>消费者组之间互不影响。</p>
<p><strong>为什么 Kafka 要设计 Consumer Group,  只有 Consumer 不可以吗？</strong> </p>
<p>我们知道 Kafka 是一款高吞吐量，低延迟，高并发, 高可扩展的消息队列产品， 那么如果某个 Topic 拥有数百万到数千万的数据量， 仅仅依靠 Consumer 进程消费， 消费速度可想而知， <strong>所以需要一个扩展性较好的机制来保障消费进度， 这个时候 Consumer Group 应运而生， Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制</strong>。</p>
<p>Kafka Consumer Group 特点如下:</p>
<blockquote>
<p>1）每个 Consumer Group 有一个或者多个 Consumer。</p>
<p>2）每个 Consumer Group 拥有一个公共且唯一的 Group ID。</p>
<p>3）Consumer Group 在消费 Topic 的时候，Topic 的每个 Partition 只能分配给组内的某个  Consumer，只要被任何 Consumer 消费一次, 那么这条数据就可以认为被当前 Consumer Group 消费成功。</p>
</blockquote>
<h2 id="Kafka中Offset的作用是什么-如何进行维护"><a href="#Kafka中Offset的作用是什么-如何进行维护" class="headerlink" title="Kafka中Offset的作用是什么,如何进行维护"></a>Kafka中Offset的作用是什么,如何进行维护</h2><p>在 <strong>Kafka</strong> 中每个 <strong>Topic</strong> 分区下面的每条消息都被赋予了一个唯一的<strong>ID</strong>值，用来标识它在分区中的位置。这个<strong>ID</strong>值就被称为位移「<strong>Offset</strong>」或者叫偏移量，一旦消息被写入到日志分区中，它的位移值将不能被修改。</p>
<h3 id="位移-Offset-管理方式"><a href="#位移-Offset-管理方式" class="headerlink" title="位移 Offset 管理方式"></a><strong>位移 Offset 管理方式</strong></h3><p>Kafka 旧版本（0.9版本之前）是把位移保存在 ZooKeeper 中，减少 Broker 端状态存储开销。</p>
<p>鉴于 Zookeeper 不适合频繁写更新，而 Consumer Group 的位移提交又是高频写操作，这样会拖慢 ZooKeeper 集群的性能， 于是在新版 Kafka 中， 社区采用了将位移保存在 Kafka 内部「<strong>Kafka Topic 天然支持高频写且持久化</strong>」，这就是所谓大名鼎鼎的__consumer_offsets。</p>
<p><strong>__consumer_offsets：</strong>用来保存 Kafka Consumer 提交的位移信息，另外它是由 Kafka 自动创建的，和普通的 Topic 相同，它的消息格式也是 Kafka 自己定义的，我们无法进行修改。</p>
<p><strong>__consumer_offsets 有3种消息格式：</strong></p>
<blockquote>
<p>1）用来保存 Consumer Group 信息的消息。</p>
<p>2）用来删除 Group 过期位移甚至是删除 Group 的消息，也可以称为 tombstone 消息，即墓碑消息，它的主要特点是空消息体，一旦某个  Consumer Group 下的所有Consumer 位移数据都已被删除时，Kafka会向 __consumer_offsets  主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。</p>
<p>3）用来保存位移值。</p>
</blockquote>
<p><strong>__consumer_offsets 消息格式分析揭秘：</strong></p>
<blockquote>
<p>1) 消息格式我们可以简单理解为是一个 KV 对。Key 和 Value 分别表示消息的键值和消息体。</p>
<p>2) 那么 Key 存什么呢？既然是存储 Consumer 的位移信息，在 Kafka 中，Consumer  数量会很多，必须有字段来标识位移数据是属于哪个 Consumer 的，怎么来标识 Consumer 字段呢？我们知道 Consumer  Group 会共享一个公共且唯一的 Group ID，那么只保存它就可以了吗？我们知道 Consumer  提交位移是在分区的维度进行的，很显然，key中还应该保存 Consumer 要提交位移的分区。</p>
<p>3) 总结：位移主题的 Key 中应该保存 3 部分内容：&lt;<strong>Group ID，主题名，分区号</strong>&gt;</p>
<p>4) value 可以简单认为存储的是 offset 值，当然底层还存储其他一些元数据，帮助 Kafka 来完成一些其他操作，比如删除过期位移数据等。</p>
</blockquote>
<p><strong>__consumer_offsets 消息格式示意图：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1009-1e9GuY.png" alt="图片"></p>
<h3 id="consumer-offsets-创建"><a href="#consumer-offsets-创建" class="headerlink" title="__consumer_offsets 创建"></a><strong>__consumer_offsets 创建</strong></h3><p><strong>consumer_offsets 是怎么被创建出来的呢？ 当 Kafka 集群中的第一个 Consumer 启动时，Kafka 会自动创建</strong>consumer_offsets。</p>
<p>它就是普通的 Topic，也有对应的分区数，如果由 Kafka 自动创建的，那么分区数又是怎么设置的呢？</p>
<p>这个依赖 Broker 端参数主题分区位移个数即「<strong>offsets.topic.num.partitions</strong>」 默认值是50，因此 Kafka 会自动创建一个有 50 个分区的 __consumer_offsets 。既然有分区数，必然就会有分区对应的副本个数，这个是依赖Broker 端另外一个参数来完成的，即 「<strong>offsets.topic.replication.factor</strong>」默认值为3。</p>
<p>总结一下， __consumer_offsets 由 Kafka 自动创建的，那么该 Topic 的分区数是 50，副本数是 3，而具体 Consumer Group 的消费情况要存储到哪个 Partition ，根据<strong>abs(GroupId.hashCode()) % NumPartitions</strong> 来计算的，这样就可以保证 Consumer Offset 信息与 Consumer Group 对应的 Coordinator 处于同一个 Broker 节点上。如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1010-lBt3Xy.png" alt="图片"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/08/1011-6lXNYd.png" alt="图片"></p>
<hr>
<blockquote>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvOE9BUXpaNWpaWVYyRnZ0ZzBwZlpvUQ==">【建议收藏】Kafka 面试连环炮, 看看你能撑到哪一步?（上）<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/VQ077V.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/VQ077V.html" class="post-title-link" itemprop="url">Innodb的MVCC实现原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-07 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-07T00:00:00+08:00">2022-04-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/" itemprop="url" rel="index"><span itemprop="name">Mysql</span></a>
                </span>
            </span>

          
            <span id="/posts/VQ077V.html" class="post-meta-item leancloud_visitors" data-flag-title="Innodb的MVCC实现原理" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/VQ077V.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/VQ077V.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>理解MVCC之前，我们需要回顾了解一下数据库的一些其他相关知识点</p>
<p>（1）数据库为什么要有事务？</p>
<p>为了保证数据最终的一致性。</p>
<p>（2）事务包括哪几个特性？</p>
<p>原子性、隔离性、一致性、持久性。</p>
<p>（3）事务的并发引起了哪些问题？</p>
<p>事务并发会引起脏读、重复读、幻读问题。</p>
<p>（4）怎么解决事务并发出现的问题？</p>
<p>设置事务隔离级别，读未提交，读提交，重复读，序列化</p>
<p>（5）数据库通过什么方式保证了事务的隔离性？</p>
<p>通过加锁来实现事务的隔离性。 </p>
<p>（6）频繁的加锁会带来什么问题？</p>
<p>读数据的时候没办法修改。修改数据的时候没办法读取，极大的降低了数据库性能。</p>
<p>（7）数据库是如何解决加锁后的性能问题的？</p>
<p>MVCC 多版本控制实现读取数据不用加锁， 可以让读取数据同时修改。修改数据时同时可读取。</p>
<h2 id="一、什么是MVCC？"><a href="#一、什么是MVCC？" class="headerlink" title="一、什么是MVCC？"></a>一、什么是MVCC？</h2><p>MVCC是在并发访问数据库时，通过对数据做多版本管理，避免因为写锁的阻塞而造成读数据的并发阻塞问题。</p>
<p>通俗的讲就是MVCC通过保存数据的历史版本，根据比较版本号来处理数据的是否显示，从而达到读取数据的时候不需要加锁就可以保证事务隔离性的效果</p>
<h2 id="二、Innodb-MVCC实现的核心知识点"><a href="#二、Innodb-MVCC实现的核心知识点" class="headerlink" title="二、Innodb MVCC实现的核心知识点"></a>二、Innodb MVCC实现的核心知识点</h2><p>1、事务版本号</p>
<p>2、表的隐藏列。</p>
<p>3、undo log</p>
<p>4、 read view</p>
<h3 id="2-1、事务版本号"><a href="#2-1、事务版本号" class="headerlink" title="2-1、事务版本号"></a>2-1、事务版本号</h3><p>每次事务开启前都会从数据库获得一个自增长的事务ID，可以从事务ID判断事务的执行先后顺序。</p>
<h3 id="2-2、表格的隐藏列"><a href="#2-2、表格的隐藏列" class="headerlink" title="2-2、表格的隐藏列"></a>2-2、表格的隐藏列</h3><p><strong>DB_TRX_ID:</strong>        记录操作该数据事务的事务ID；</p>
<p><strong>DB_ROLL_PTR：</strong>指向上一个版本数据在undo log 里的位置指针；</p>
<p><strong>DB_ROW_ID:</strong>      隐藏ID ，当创建表没有合适的索引作为聚集索引时，会用该隐藏ID创建聚集索引;</p>
<h3 id="2-3、Undo-log"><a href="#2-3、Undo-log" class="headerlink" title="2-3、Undo log"></a>2-3、Undo log</h3><p>Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log 里，当事务进行回滚时可以通过undo log 里的日志进行数据还原。</p>
<p><strong>Undo log 的用途</strong></p>
<p>（1）保证事务进行rollback时的原子性和一致性，当事务进行回滚的时候可以用undo log的数据进行恢复。</p>
<p> （2）用于MVCC快照读的数据，在MVCC多版本控制中，通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。</p>
<h3 id="2-4、事务版本号、表格的隐藏列、undo-log的关系"><a href="#2-4、事务版本号、表格的隐藏列、undo-log的关系" class="headerlink" title="2-4、事务版本号、表格的隐藏列、undo log的关系"></a>2-4、事务版本号、表格的隐藏列、undo log的关系</h3><p>我们模拟一次数据修改的过程来让我们了解下事务版本号、表格隐藏的列和undo log他们之间的使用关系。</p>
<p><strong>（1）首先准备一张原始原始数据表</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1014-pZjl2q.jpg" alt="1014-F3zJiu"></p>
<p>（2）开启一个事务A： 对user_info表执行 update  user_info set name =“李四”where id=1 会进行如下流程操作</p>
<p>1、首先获得一个事务编号 104</p>
<p>2、把user_info表修改前的数据拷贝到undo log</p>
<p>3、修改user_info表 id=1的数据</p>
<p>4、把修改后的数据事务版本号改成 当前事务版本号，并把DB_ROLL_PTR 地址指向undo log数据地址。</p>
<p>（3）最后执行完结果如图：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1017-gKgh48.jpg" alt="img"></p>
<h3 id="2-5、Read-view"><a href="#2-5、Read-view" class="headerlink" title="2-5、Read view"></a>2-5、Read view</h3><p>在innodb 中每个事务开启后都会得到一个read_view。副本主要保存了当前数据库系统中正处于活跃（没有commit）的事务的ID号，其实简单的说这个副本中保存的是系统中当前不应该被本事务看到的其他事务id列表。</p>
<h3 id="Read-view-的几个重要属性"><a href="#Read-view-的几个重要属性" class="headerlink" title="Read view 的几个重要属性"></a>Read view 的几个重要属性</h3><p><strong>trx_ids:</strong>       当前系统活跃(未提交)事务版本号集合。</p>
<p><strong>low_limit_id:</strong>   创建当前read view 时“当前系统最大<strong>事务版本号</strong>+1”。</p>
<p><strong>up_limit_id:</strong>    创建当前read view 时“系统正处于<strong>活跃事务</strong>最小版本号”</p>
<p><strong>creator_trx_id:</strong>  创建当前read view的事务版本号；</p>
<h3 id="Read-view-匹配条件"><a href="#Read-view-匹配条件" class="headerlink" title="Read view 匹配条件"></a>Read view 匹配条件</h3><p>（1）数据事务ID &lt;up_limit_id 则显示</p>
<p>如果数据事务ID小于read view中的最小活跃事务ID，则可以肯定该数据是在当前事务启之前就已经存在了的,所以可以显示。</p>
<p>（2）数据事务ID&gt;=low_limit_id 则不显示</p>
<p>如果数据事务ID大于read view 中的当前系统的最大事务ID，则说明该数据是在当前read view 创建之后才产生的，所以数据不予显示。</p>
<p>（3） up_limit_id &lt;=<strong>数据事务ID&lt;</strong>low_limit_id  则与活跃事务集合<strong>trx_ids</strong>里匹配</p>
<p>如果数据的事务ID大于最小的活跃事务ID,同时又小于等于系统最大的事务ID，这种情况就说明这个数据有可能是在当前事务开始的时候还没有提交的。</p>
<p>所以这时候我们需要把数据的事务ID与当前read view 中的活跃事务集合trx_ids 匹配:</p>
<p><strong>情况1:</strong>    如果事务ID不存在于trx_ids 集合（则说明read view产生的时候事务已经commit了），这种情况数据则可以显示。</p>
<p><strong>情况2：</strong>  如果事务ID存在trx_ids则说明read view产生的时候数据还没有提交，但是如果数据的事务ID等于creator_trx_id ，那么说明这个数据就是当前事务自己生成的，自己生成的数据自己当然能看见，所以这种情况下此数据也是可以显示的。</p>
<p><strong>情况3：</strong>  如果事务ID既存在trx_ids而且又不等于creator_trx_id那就说明read view产生的时候数据还没有提交，又不是自己生成的，所以这种情况下此数据不能显示。</p>
<p>（4）不满足read view条件时候，从undo log里面获取数据</p>
<p>当数据的事务ID不满足read view条件时候，从undo log里面获取数据的历史版本，然后数据历史版本事务号回头再来和read view 条件匹配 ，直到找到一条满足条件的历史数据，或者找不到则返回空结果；</p>
<h2 id="三、Innodb实现MCC的原理"><a href="#三、Innodb实现MCC的原理" class="headerlink" title="三、Innodb实现MCC的原理"></a>三、Innodb实现MCC的原理</h2><p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1017-C85dvp.jpg" alt="img"></p>
<h3 id="3-1、模拟MVCC实现流程"><a href="#3-1、模拟MVCC实现流程" class="headerlink" title="3-1、模拟MVCC实现流程"></a>3-1、模拟MVCC实现流程</h3><p>下面我们通过开启两个同时进行的事务来模拟MVCC的工作流程。</p>
<p><strong>（1）创建user_info表，插入一条初始化数据</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1017-S1wPS3.jpg" alt="img"></p>
<p><strong>（2）事务A和事务B同时对user_info进行修改和查询操作</strong></p>
<p>事务A：update user_info set name =”李四”</p>
<p>事务B：select * fom user_info where id=1</p>
<p><strong>问题：</strong></p>
<p>先开启事务A ，在事务A修改数据后但未进行commit，此时执行事B。最后返回结果如何。</p>
<p><strong>执行流程如下图：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1018-WDgWpW.jpg" alt="img"></p>
<p><strong>执行流程说明：</strong></p>
<p><strong>（1）事务A：开启事务，首先得到一个事务编号102；</strong></p>
<p><strong>（2）事务B：开启事务，得到事务编号103；</strong></p>
<p><strong>（3）事务A：进行修改操作，首先把原数据拷贝到undolog,然后对数据进行修改，标记事务编号和上一个数据版本在undo log的地址。</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1018-1vklPX.jpg" alt="img"></p>
<p><strong>（4）事务B： 此时事务B获得一个read view ，read view对应的值如下</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1018-O8GlSP.jpg" alt="1018-OSba8r"></p>
<p><strong>（5）事务B： 执行查询语句，此时得到的是事务A修改后的数据</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1019-GRx57G.jpg" alt="img"></p>
<p><strong>（6）事务B： 把数据与read view进行匹配，</strong></p>
<p>数据事务ID为102 等于up_limit_id （这里不小于up_limit_id）</p>
<p>数据事务ID为102  小于low_limit_id</p>
<p>数据事务ID为102存在于  trx_ids，</p>
<p>数据事务ID为102不等于creator_trx_id</p>
<p>发现不满足read view显示条件，所以从undo lo获取历史版本的数据再和read view进行匹配，最后返回数据如下。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1019-YvOauz.jpg" alt="img"></p>
<h2 id="四、补充"><a href="#四、补充" class="headerlink" title="四、补充"></a>四、补充</h2><h3 id="各种事务隔离级别下的Read-view-工作方式"><a href="#各种事务隔离级别下的Read-view-工作方式" class="headerlink" title="各种事务隔离级别下的Read view 工作方式"></a>各种事务隔离级别下的Read view 工作方式</h3><p>RC(read commit) 级别下同一个事务里面的每一次查询都会获得一个新的read view副本。这样就可能造成同一个事务里前后读取数据可能不一致的问题（重复读）</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1019-x1NF8M.jpg" alt="img"></p>
<p>RR(重复读)级别下的一个事务里只会获取一次read view副本，从而保证每次查询的数据都是一样的。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1019-EwbKQo.jpg" alt="img"></p>
<p>READ_UNCOMMITTED 级别的事务不会获取read view 副本。</p>
<h3 id="快照读和当前读"><a href="#快照读和当前读" class="headerlink" title="快照读和当前读"></a>快照读和当前读</h3><p><strong>快照读</strong></p>
<p>快照读是指读取数据时不是读取最新版本的数据，而是基于历史版本读取的一个快照信息（mysql读取undo log历史版本) ，快照读可以使普通的SELECT 读取数据时不用对表数据进行加锁，从而解决了因为对数据库表的加锁而导致的两个如下问题</p>
<p>1、解决了因加锁导致的修改数据时无法对数据读取问题;</p>
<p>2、解决了因加锁导致读取数据时无法对数据进行修改的问题;</p>
<p><strong>当前读</strong></p>
<p>当前读是读取的数据库最新的数据，当前读和快照读不同，因为要读取最新的数据而且要保证事务的隔离性，所以当前读是需要对数据进行加锁的（Update    delete    insert   select ….lock in share mode   select for update 为当前读）</p>
<h2 id="五、讨论"><a href="#五、讨论" class="headerlink" title="五、讨论"></a>五、讨论</h2><h3 id="MVCC是否有解决幻读问题？"><a href="#MVCC是否有解决幻读问题？" class="headerlink" title="MVCC是否有解决幻读问题？"></a>MVCC是否有解决幻读问题？</h3><p>看到有很多网友对这个话题有讨论，这里补充一下和大家理一理这个问题，首先我通过验证得出来的结论是MVCC不存在幻读问题的，但也并不是说MVCC解决了幻读的问题，经过理论的推断和验证得到的结论是在<strong>快照读的情况下可以避免幻读问题，在当前读的情况下则需要使用间隙锁来解决幻读问题的</strong>。</p>
<h3 id="MVCC不存在幻读问题（RR级别的情况下）"><a href="#MVCC不存在幻读问题（RR级别的情况下）" class="headerlink" title="MVCC不存在幻读问题（RR级别的情况下）"></a>MVCC不存在幻读问题（RR级别的情况下）</h3><p>首先确认一点MVCC属于快照读的，在进行快照读的情况下是不会对数据进行加锁，而是基于事务版本号和undo历史版本读取数据，其实上面的文章已经说得很清楚了，我们根据上面的MVCC流程来推导，无论如何在MVCC的情况下都是不会出现幻读的问题的，如下图。</p>
<p>1、开启事务1，获得事务ID为1。</p>
<p>2、事务1执行查询，得到readview。</p>
<p>3、开始事务2。</p>
<p>4、执行insert。</p>
<p>5、提交事务2。</p>
<p>6、执行事务1的第二次查询 (因为这里是RR级别，所以不会再去获得readview,还是使用第一次获得的readview)</p>
<p>7、最后得到的结果是，插入的数据不会显示，因为插入的数据事务ID大于等于 readview里的最大活跃事务ID。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1020-iIrKAA.jpg" alt="img"></p>
<p><strong>实际案例：</strong></p>
<p>首先关闭数据库的自动提交事务功能。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1020-8492ES.jpg" alt="img"></p>
<p> 然后使用手动提交事务的方式，进行一次快照读，但是不提交事务，然后启动插入数据的事务，进行数据插入 commit，结果我发现在使用快照读的时候，数据是可以插入成功的，那这也就说明了一个问题，<strong>快照读的时候就根本没加锁，否则的话数据是不可能插入成功的，而且在插入数据提交成功后，我们执行第二条查询 语句是读取不到中间插入的这条数据的，这也就说明在没有加锁的情况下，基于历史版本的MVCC快照读是可以避免幻读问题的</strong>。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1020-iUMz8J.jpg" alt="1020-gEDxYX"></p>
<h3 id="当前读存的幻读问题解决方案"><a href="#当前读存的幻读问题解决方案" class="headerlink" title="当前读存的幻读问题解决方案"></a>当前读存的幻读问题解决方案</h3><p>上面我们已经论证了在RR级别快照读的情况下，是不存在幻读问题的。  因为会基于历史版本读取数据，但是当前读的话就不同了，当前读每次都会读取最新的数据。所以两次读取中间如果可以插入数据，那么就肯定会造成幻读问题，所以在当前读的情况下就必须通过一种方式来解决幻读问题，而这种方式就是采用加锁来解决。</p>
<p><strong>实际案例：</strong></p>
<p>首先关闭数据库的自动提交事务功能，  使用当前读的方式演示和上面一样的流程，结果发现在当前读的时候没有提交事务之前是根本无法进行数据插入的，所以这也就说明了，使用当前读的时候会对这个范围内的数据进行加锁，所以无法在查询的范围内进行数据插入，这无疑也证明了在当前读的情况下mysql是使用锁的机制来避免出现重复读和幻读问题的。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1021-hFAdty.jpg" alt="img"></p>
<blockquote>
<p>原文： <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81Mjk3Nzg2Mg==">数据库基础（四）Innodb MVCC实现原理 - 知乎<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/2DEMJ1C.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/2DEMJ1C.html" class="post-title-link" itemprop="url">事务持久性与原子性的保障</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-07 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-07T00:00:00+08:00">2022-04-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/" itemprop="url" rel="index"><span itemprop="name">Mysql</span></a>
                </span>
            </span>

          
            <span id="/posts/2DEMJ1C.html" class="post-meta-item leancloud_visitors" data-flag-title="事务持久性与原子性的保障" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/2DEMJ1C.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/2DEMJ1C.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>持久性的意义</strong></p>
<p>所谓持久性就是说在事务成功提交了之后，数据的最终变更操作都会持久化到磁盘上去,不会因为故障导致数据丢失。而在计算机系统里，只有数据保存到了磁盘才能保证数据不会丢失，持久化的问题是所有数据库系统都需要面临的，无法保证持久性的数据库就意味着在数据库、系统、服务器发生故障时无法进行数据恢复。</p>
<p><strong>持久性的难题</strong></p>
<p>保证持久性的意义在于，就算遇到数据库、系统、服务器崩溃，我们依然能对已经损坏的数据进行恢复，用习惯了ACID的数据库，我们潜意识里就以为持久化是自然而然的事情，然而并非这样，我们经典的MyIsam 就不支持这个特性，至于为什么，因为保证持久化的操作本身是有难题需要攻克的，这个难题在于把数据写入磁盘的操作过程并不是原子性的。</p>
<p>因为一次事务会牵扯到多次调用磁盘写数据的操作，而多次磁盘操作相互是独立的，所以一个事务是无法保障多次磁盘读写的原子操作的。这也就意味着，如果事务提交的时候如果发生故障、崩溃，就有可能部分写磁盘操作调用成功，部分写操作调用失败的情况，从而导致产生了脏数据。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1114-VY1lSA.jpg" alt="img"></p>
<p>除了原子性问题之外，为了提升IO的效率， 数据库是允许异步写入数据到磁盘的，数据写入通常会先写内存、再写磁盘。 为了优化写入数据的性能，通常应用也会在内存中加入各种缓冲区，  所以数据最终什么时候写入到磁盘   这个时间是根据具体的策略来决定，简单来说就是应用程序写入数据成功了，但是并不一定代表数据已经持久化到磁盘了。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1115-jg7jSN.jpg" alt="img"></p>
<p><strong>所以综合来看持久化的关键问题在于两方面，：</strong></p>
<p>一方面，应用程序的一次业务操作会牵扯到多次调用磁盘写，而多次写入磁盘的操作并不具备原子性，所以就也会存在部分数据写入成功，部分数据写入失败的情况。</p>
<p>另一方面，数据从内存写入到磁盘的整个过程可以异步进行的，所以导致从程序上来看数据写入成功了，但是数据并不一定已经持久化到磁盘了。 </p>
<h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a><strong>redo log</strong></h3><p>上面我们已经了解到 如果提交事务的过程中发生崩溃、宕机，就有可能会导致数据丢失和损坏，那么如何解决这个问题就在于，在数据丢失和损坏之后我们能通过什么方式对数据进行恢复。</p>
<p>回想到现实世界里，有时候我们在做某件事情的时候，偶尔会遇到脑子突然断片或失忆的情况（好比应用崩溃、服务器宕机），然后断片了之后，回想不起来断片之前自己在做什么，也不知道事情做到了哪一步，而这个时候我们往往会想着要是在做事情之前把这些记录在笔记本里面就好了，按着记事本里面的记录就知道自己应该做什么事情，还有哪些事情没有做了，然后把没做的事情继续做完就行了。</p>
<p>在现实世界我们用记事本的方式解决脑子失忆、断片的问题，在计算机里我们用记日志的方式来解决数据崩溃恢复问题，而Mysql里这个日志就是redo log。 redo  log的功能就是事务提交之前首先会把本次事务需要变更的数据，包括修改磁盘那块扇区、修改哪些数据等，通通都记录下来。所以只要保证成功记录了redo log  ，那么就算事务提交之后发生了崩溃、宕机，此时内存的数据即便没有即时写入磁盘，又或则只写入了一部分数据到磁盘，我们只需要通过找到事务对应的redo log，再对数据进行对比恢复即可。</p>
<p><strong>加入redo log后，事务执行过程如下：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1115-40zR4M.jpg" alt="img"></p>
<h3 id="原子性保障"><a href="#原子性保障" class="headerlink" title="原子性保障"></a><strong>原子性保障</strong></h3><p>所谓原子性就是说，在事务中进行的一系列操作，要么全部执行成功，要么全部执行失败，不存在部分执行部分不执行的情况。</p>
<p>首先事务的操作<strong>“要么全部成功”</strong>，这个是指事务提交后必须保证数据全部修改成功，在正常情况下事务提交后数据是肯定能修改成功的，所以这里需要考虑的是异常情况下能否保证数据全部修改成功 (比如在数据库崩溃、宕机等故障的情况)，所以保证原子性操作全部成功的前提就得必须保证持久性，这这部分的功能在上面我们已经知道是通过redo  log 来解决了。</p>
<p>然后原子性中还有一个特性<strong>“要么全部失败”，</strong>，这个是指事务可以在任何阶段进行回滚了，并且在执行回滚操作后，必须保证事务所变更的数据恢复到修改之前的样子。  比如上面的流程中，在修改数据后业务不具备事务提交的条件，那么此时就需要对事务进行回滚，可是需要注意的是，此时已经变更的数据有可能已经写入到磁盘了，所以如果需要进行事务回滚，那么就必然需要对已经修改的数据进行还原，所以此时我们就需要有一个记录的历史数据快照的日志，这个日志的作用在于如果事务需要进行回滚，那么通过该日志考记录的历史快照可以还原已经变更的数据信息，在Mysql 里这个快照日志就是undo log。</p>
<h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a><strong>undo log</strong></h3><p>在Mysql里每次修改数据前，首先会把修改之前的数据作为历史保存一份到undo log里面的，数据里面会记录操作该数据的事务ID，在事务需要进行回滚的时候，通过对比undo log日志把已经修改的数据进行还原。</p>
<p><strong>加入redo log后，事务执行过程如下：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1115-BoH8vP.jpg" alt="img"></p>
<p><strong>总结：</strong></p>
<p>事务持久性的难题在于，一个事务会牵扯到多次磁盘IO操作，多次IO之间操作相互独立，所以在发生故障和意外情况会出现部分数据写入成功，部分数据写入失败的情况，为了保障数据最终都能成功写入到磁盘，所以在修改数据之前，通过redo log提前记录一份最终需要完成修改的数据记录，如果在事务提交的的过程中发生故障、宕机的意外导致数据写入不成功，从而在意外发生后通过redo  log来将未成功写入的数据重新写入，最终把需要修改的数据全部写入磁盘，从而保障了事务的持久性。</p>
<p>原子性的难题在于，当修改数据后如果需要对事务进行回滚，这个过程中内存中修改的数据可能持久化到磁盘，导致脏数据，所以必须通过undo  log提前记录一份历史数据的快照，在事务需要进行回滚的时候，通过历史数据的快照来将已经变更的数据恢复如初，从而保障事务回滚后就像什么都没发生过一样，配合redo log 保障了事务原子性要么全部成功，要么全部失败的原子特性。</p>
<blockquote>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80MjA2MjI0NzI=">数据库基础（五）事务持久性与原子性的保障 - 知乎<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/VB6XWR.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/VB6XWR.html" class="post-title-link" itemprop="url">Mysql索引原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-07 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-07T00:00:00+08:00">2022-04-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/" itemprop="url" rel="index"><span itemprop="name">Mysql</span></a>
                </span>
            </span>

          
            <span id="/posts/VB6XWR.html" class="post-meta-item leancloud_visitors" data-flag-title="Mysql索引原理" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/VB6XWR.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/VB6XWR.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>什么是索引<br>索引是一种利用某种规则的数据结构与实际数据的关系加快数据查找的功能；索引数据节点中有着实际文件的位置，因为索引是根据特定的规则和算法构建的,在查找的时候遵循索引的规则可以快速查找到对应数据的节点，从而达到快速查找数据的效果；其实宏观来说索引其实是一种概念而不是具体的某项技术，只是我们在某个技术中运用得比较广泛和鲜明（比如说数据库）渐渐的有了特定领域的标签，其实在生活中索引的使用无处不在，比如说：书本里的目录；读书时的座位号，考试编号都有类似索引的功能;</p>
<p>总结来所有通过某规则数据结构和实际目标关联，根据特定规则算法快速寻址的功能都可以称之为索引；</p>
<h2 id="二、为什么要用索引"><a href="#二、为什么要用索引" class="headerlink" title="二、为什么要用索引"></a>二、为什么要用索引</h2><p>首先我们看下在没有索引的情况下是怎么查找数据的：</p>
<p>我们用一个例子来解释比较直观</p>
<p>（1）没有索引的情况下访问数据：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1300-vn2lXu.jpg" alt="1300-9A9kOW"></p>
<p>（2）使用平衡二叉树结构作为索引的情况下访问数据：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1300-0sjTWg.jpg" alt="1300-EQ6HD3">  </p>
<p>第一张图没有使用索引我们会进行顺序查找，依照数据顺序逐个进行匹配，进行了5次寻址才查询出所需数据，第二张图用了一个简单的平衡二叉树索引之后我们只用了3次，这还是数据量小的情况下，数据量大了效果更明显，所以总结来说创建索引就是为了加快数据查找速度；</p>
<h2 id="三、Innodb-的索引选择"><a href="#三、Innodb-的索引选择" class="headerlink" title="三、Innodb 的索引选择"></a>三、Innodb 的索引选择</h2><p>Mysql 的默认存储引擎innodb使用B+树作为索引的存储结构，为了让我们能更深入理解B+树，所以我们会对B+树的衍生过程做一些了解。</p>
<h3 id="1、数组和链表的选择"><a href="#1、数组和链表的选择" class="headerlink" title="1、数组和链表的选择"></a><strong>1、数组和链表的选择</strong></h3><p>作为最基础的数据存储结构数组和链表，是选用数组还是选择链表来作为索引存储的基本结构呢？首先我们需要从索引和两种数据结构的特性来分析。</p>
<p><strong>数组的特性：</strong> 查找快、但是插入、修改数据慢。</p>
<p><strong>链表的特性：</strong> 查找慢、插入、修改快。</p>
<p>在数据库的业务场景里插入、修改、查询都是比较频繁的操作，选链表还是数组好像都不完美。既然都不完美，那么我们只能退而求其次，看谁比较容易去完善。从完善的角度来看，那么我们就会从数组里发现一个致命的问题，数组的修改和移动都会导致数组大量的元素迁移，而且在迁移的过程中是不能查找数据的，数组元素迁移没有完成查询出来的数据就可能是错的，这样就导致数组在频繁插入和修改的过程中不仅仅是修改和插入本身慢，而且因为这个而导致查询也用不了，显然这个问题对于修改和插入频繁的数据库来说是无法忍受的。所以我们只能把链表作为索引的基础结构了，那么剩下的就是如何解决链表查询小笼包慢的问题了。</p>
<h3 id="2、从链表到二叉树"><a href="#2、从链表到二叉树" class="headerlink" title="2、从链表到二叉树"></a><strong>2、从链表到二叉树</strong></h3><p>如果使用链表来存储数据，那么必须要解决的一个问题就是要解决链表的查询效率问题，我们必须通过一种算法来解决链表查找数据慢的问题，而这里这里就用到了二分查找法，利用二分法思维把链表拆成N个对半分的节点，然后形成了一个数据结构叫二叉查找树，使用了二分法思维衍生出来的树大大提升了查找的性能。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1301-cjA5NX.jpg" alt="1301-Bnp6DL"></p>
<h3 id="3、从二叉查树到平衡二叉树"><a href="#3、从二叉查树到平衡二叉树" class="headerlink" title="3、从二叉查树到平衡二叉树"></a><strong>3、从二叉查树到平衡二叉树</strong></h3><p>二叉查找树极大的提升了链表查找数据的效率，不过我们又发现了一个问题，就是二叉查找树的“高度”不可控，一旦树的节点插入变成向下图一样的结构。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1301-vTHEoc.jpg" alt="1301-4hsdTc">  </p>
<p>如果树的节点不可控编程变成线性结构，那么就会极大的降低我们的查询效率，所以我们就又需要一种算法来保证二叉树节点的平衡，让树的节点高度差不会太大，这个时候就衍生了一些平衡算法，最终我们的二叉树就有像AVL树和红黑树这些新产品，我们也称这些新产品为平衡二叉树，，平衡二叉树通常会保证树的左右两边的节点层级相差不会大于2。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1301-2pzIIa.jpg" alt="1301-I8F42Y"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1302-j9YcaM.jpg" alt=""></p>
<h3 id="4、从平衡二叉树到B树"><a href="#4、从平衡二叉树到B树" class="headerlink" title="4、从平衡二叉树到B树"></a><strong>4、从平衡二叉树到B树</strong></h3><p>平衡二叉树的出现好像很接近于我们的理想状态了，但好像还有什么优化的空间，我们通过上面两个树的演化过程发现，影响这棵树的查询效率的决定性因素就是树的高度，只要树的层级越少，那么树的查询效率就越高，本着这个原则我们就思考每个节点能不能多存点 数据，只要每个数节点的数据保存的越多，那么我们树的层级就会越少，</p>
<p>B树相对平衡二叉树最大的一个改变，就是B树的每个节点可存储的关键字增多了，特别是在B树应用到数据库中的时候，节点存储关键字的数量充分利用了磁盘块IO的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来），B树只要把节点大小限制在磁盘快大小范围，这样就可以只需要一次IO就读取到节点所有数据，节点存储了更多的关键字，但是并不会影响IO的次数。B树树相对于之前节点可以存储更多的关键字，所以树的层级会比原来少很多，树的层级减少了，那么检索的效率就会大大提升。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1302-U1Ng5z.jpg" alt="1302-0YutJJ"></p>
<h3 id="5、从B树到B-树"><a href="#5、从B树到B-树" class="headerlink" title="5、从B树到B+树"></a><strong>5、从B树到B+树</strong></h3><p><strong>其实B树已经接近我们的理想预期了，但是还是能从B树的上面找到可以优化的地方，比如以下几个方面：</strong></p>
<p>1、B树的节点同时保存了索引的key和数据值（如果节点只保存索引key不保存值，那么是不是会把索引树的层层级更进一步的减少）。</p>
<p>2、因为每个节点保存了数据值，这样的话查询不同的数据效率就会显得不稳定，有些在树的第一层匹配成功就返回，有些则可能需要匹配到树的最后一层才返回。</p>
<p>3、如果要查询所有数据，那么就必须遍历整个B树的每个节点。</p>
<p><strong>B+树在B树的基础上 又做了一些优化，B+树主要做了下面几点的优化。</strong></p>
<p>1、B+跟B树不同，B+树的非叶子节点不保存实际的数据，只保存索引key，所有的数据都会保存到叶子节点。</p>
<p><strong>树层级变少：</strong>如果非叶子节点不保存实际的数据值，而只保存索引key，那么相对于B树来说B+树的每个<strong>非叶子</strong>节点存储的索引key会更多，所以树的层级也会更少，那么查询效率也会更快。</p>
<p><strong>查询更稳定：</strong>因为B+所有数据值都是存在<strong>叶子</strong>节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定；</p>
<p><strong>遍历整个树更快：</strong>B+树遍历整棵树只需要遍历所有的<strong>叶子</strong>节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。</p>
<p>2、B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。</p>
<p><strong>排序和范围查询更方便</strong>：B+树所有的叶子节点数据构成了一个有序链表，这样在进行数据排序和询范围大小查询数据的时候更方便，数据紧密性也更高。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1302-rYU3bq.jpg" alt="1302-WFyIHT">  </p>
<p><strong>（百度百科算法结构示意图）</strong></p>
<p>总结来说，从平衡二叉树、B树、B+树，总体来看它们的贯彻的思想是相同的，在链表的基础上，如何采用二分法和数据平衡策略来提升查找数据的速度。不同点是他们一个一个在演变的过程中通过IO从磁盘读取数据的原理进行一步步的演变，每一次演变都是为了让节点的空间更合理的运用起来，从而使树的层级减少达到快速查找数据的目的，在这个基础上，B+树的查找速度快、性能稳定、排序快、扫表快等诸多特点也就让Mysql选择了B+树来作为索引的存储结构。</p>
<h2 id="四、补充"><a href="#四、补充" class="headerlink" title="四、补充"></a>四、补充</h2><h3 id="为什么说Mysql的索引树一般都在1-3层的结构？"><a href="#为什么说Mysql的索引树一般都在1-3层的结构？" class="headerlink" title="为什么说Mysql的索引树一般都在1-3层的结构？"></a><strong>为什么说Mysql的索引树一般都在1-3层的结构？</strong></h3><p>经常听到别人说Mysql的索引树一般会在3层，这个是有什么依据？ 其实这个的确是有数据计算支撑的，我们可以根据B+树的原理进行一下数据推算，因为磁盘每页数据为4K，而Mysql的B+树对此又进行了一次调整，在Mysql也有自己的页概念，Mysql里的每一页数据等于磁盘4个页的大小，所以在Mysql里面的一页数据其实是16K，那么也就意味着Mysql里B+树的非叶子节点可存储16K的数据。</p>
<p>然后我们按照一个索引大小，如果字段类型为varchar，长度为10，字符类型为utf8mb4，在不考虑其他因素的影响下，一个索引的大小等于 10 _3+2=32字节，我们按照每个非叶子节点的16K来计算，Mysql索引树每个节点能容纳(16_1024)/32=512个索引key。</p>
<p><strong>索引树的第一层：</strong>第一层是树的根节点，所以索引树的第一层保存索引Key的数量为512个；</p>
<p><strong>索引树的第二层：</strong>B+树根节点可保存512个索引key，也就是当前B+树有512个分叉，那么第二层索引树节点个数为512个，保存索引Key的数量=512*512=262144。</p>
<p><strong>索引树的第三层：</strong>第二层key数量为262144，那么第三层的树节点数量也就是262144，那么第三层索引树节点个数为512个，保存索引Key的数量=262144*512=134217728。</p>
<p>根据一个计算我们可以基本得出，类型varchar，长度为10，字符类型为utf8mb4的索引字段，数据在512条之内树结构只有一层。数据在262144之内树只有两层，数据在134217728之内，索引树都会保持在3层之内，而我们的表数据一般而言都保持在千万级以内，所以说Mysql的索引树一般都在1-3层。</p>
<blockquote>
<p><a href="https://xuemingde.com/JavaNotes/数据库/20220407-Mysql索引原理">20220407-Mysql索引原理</a><br>本文转自 <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yMTM3NzIwNDI=">https://zhuanlan.zhihu.com/p/213772042<i class="fa fa-external-link-alt"></i></span>，如有侵权，请联系删除。</p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/3K8NATX.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/3K8NATX.html" class="post-title-link" itemprop="url">Mysql里的锁</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-06 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-06T00:00:00+08:00">2022-04-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/" itemprop="url" rel="index"><span itemprop="name">Mysql</span></a>
                </span>
            </span>

          
            <span id="/posts/3K8NATX.html" class="post-meta-item leancloud_visitors" data-flag-title="Mysql里的锁" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/3K8NATX.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/3K8NATX.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>加锁的目的是什么</strong></p>
<p>在了解数据库锁之前，首先我们必须要明白加锁的是为了解决什么问题，如果你还不清楚的话，那么从现在开始你就知道了，对数据加锁是为了解决事务的隔离性问题，让事务之间相互不影响，每个事务进行操作的时候都必须先对数据加上一把锁，防止其他事务同时操作数据。如果你想一个人静一静，不被别人打扰，那么请在你的房门上加上一把锁。</p>
<h2 id="锁实是基于什么实现的"><a href="#锁实是基于什么实现的" class="headerlink" title="锁实是基于什么实现的?"></a><strong>锁实是基于什么实现的?</strong></h2><p>为了后面大家后面对锁理解的更透彻，所以必须要先解决这个问题，现实生活中家里的锁是锁在门上的，那么数据库的锁又是加在了哪里呢？我在这里可以告诉你，数据库里面的锁是基于索引实现的，在Innodb中我们的锁都是作用在索引上面的，当我们的SQL命中索引时，那么锁住的就是命中条件内的索引节点(行锁)，如果没有命中索引的话，那我们锁的就是整个索引树（表锁），如下图一下锁住的是整棵树还是某几个节点，完全取决于你的条件是否有命中到对应的索引节点。</p>
<p><strong>innodb索引结构图(B+ tree):</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1029-UQSDtz.jpg" alt="img"></p>
<h2 id="锁的分类。"><a href="#锁的分类。" class="headerlink" title="锁的分类。"></a><strong>锁的分类。</strong></h2><p>数据库里有的锁有很多种，为了方面理解，所以我根据其相关性”人为”的对锁进行了一个分类，分别如下</p>
<p>基于锁的属性分类：共享锁、排他锁。</p>
<p>基于锁的粒度分类：表锁、行锁、记录锁、间隙锁、临键锁。</p>
<p>基于锁的状态分类：意向共享锁、意向排它锁。</p>
<h2 id="属性锁"><a href="#属性锁" class="headerlink" title="属性锁"></a><strong>属性锁</strong></h2><h3 id="共享锁-Share-Lock"><a href="#共享锁-Share-Lock" class="headerlink" title="共享锁(Share Lock)"></a><strong>共享锁(Share Lock)</strong></h3><p>共享锁又称读锁，简称S锁。当一个事务对数据加上读锁之后，其他事务只能对该数据加读锁，而无法对数据加写锁，直到所有的读锁释放之后其他事务才能对其进行加持写锁。  加了共享锁之后，无法再加排它锁，这也就可以避免读取数据的时候会被其它事务修改，从而导致重复读问题。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1029-C3JaXH.jpg" alt="img"></p>
<h3 id="排他锁（eXclusive-Lock）"><a href="#排他锁（eXclusive-Lock）" class="headerlink" title="排他锁（eXclusive Lock）"></a><strong>排他锁（eXclusive Lock）</strong></h3><p>排他锁又称写锁，简称X锁；当一个事务对数据加上写锁之后，其他事务将不能再为数据加任何锁，直到该锁释放之后，其他事务才能对数据进行加锁。加了排他锁之后，其它事务就无法再对数进行读取和修改，所以也就出现脏写和脏读的问题。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1030-7folzQ.jpg" alt="img"></p>
<h2 id="粒度锁"><a href="#粒度锁" class="headerlink" title="粒度锁"></a><strong>粒度锁</strong></h2><h2 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a><strong>表锁</strong></h2><p>表锁是指上锁的时候锁住的是整个表，当下一个事务访问该表的时候，必须等前一个事务释放了锁才能进行对表进行访问；</p>
<p>特点： 粒度大，加锁简单，容易冲突；</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1030-PJKzGs.jpg" alt="img"></p>
<h2 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a><strong>行锁</strong></h2><p>行锁是对所有行级别锁的一个统称，比如下面说的记录锁、间隙锁、临键锁都是属于行锁，  行锁是指加锁的时候锁住的是表的某一行或多行记录，多个事务访问同一张表时，只有被锁住的记录不能访问，其他的记录可正常访问；</p>
<p>特点：粒度小，加锁比表锁麻烦，不容易冲突，相比表锁支持的并发要高；</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1031-BPV25T.jpg" alt="img"></p>
<h2 id="记录锁-Record-Lock"><a href="#记录锁-Record-Lock" class="headerlink" title="记录锁(Record Lock)"></a><strong>记录锁(Record Lock)</strong></h2><p>记录锁属于行锁中的一种，记录锁的范围只是表中的某一条记录，记录锁是说事务在加锁后锁住的只是表的某一条记录。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1031-a3WNay.jpg" alt="img"></p>
<p><strong>触发条件：</strong>精准条件命中，并且命中索引；</p>
<p><strong>例如：</strong><code>update  user_info  set name=’张三’  where id=1</code> ,这里的id是索引。</p>
<p><strong>记录锁的作用：</strong>加了记录锁之后数据可以避免数据在查询的时候被修改的重复读问题，也避免了在修改的事务未提交前被其他事务读取的脏读问题。</p>
<h2 id="间隙锁-Gap-Lock"><a href="#间隙锁-Gap-Lock" class="headerlink" title="间隙锁(Gap Lock)"></a><strong>间隙锁(Gap Lock)</strong></h2><p>间隙锁属于行锁中的一种，间隙锁是在事务加锁后其锁住的是表记录的某一个区间，当表的相邻ID之间出现空隙则会形成一个区间，遵循左开右闭原则。</p>
<p>比如下面的表里面的数据ID 为 1,4,5,7,10 ,那么会形成以下几个间隙区间，-n-1区间，1-4区间，7-10区间，10-n区间 （-n代表负无穷大，n代表正无穷大）</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1032-pesciR.jpg" alt="img"></p>
<p><strong>触发条件：</strong>范围查询，查询条件必须命中索引、间隙锁只会出现在REPEATABLE_READ（重复读)的事务级别中。</p>
<p><strong>例如</strong>：对应上图的表执行<code>select * from  user_info   where id&gt;1 and id&lt;4</code>(这里的id是唯一索引) ，这个SQL查询不到对应的记录，那么此时会使用间隙锁。  </p>
<p><strong>间隙锁作用</strong>：防止幻读问题，事务并发的时候，如果没有间隙锁，就会发生如下图的问题，在同一个事务里，A事务的两次查询出的结果会不一样。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1032-RaUbEx.jpg" alt="img"></p>
<h2 id="临键锁-Next-Key-Lock"><a href="#临键锁-Next-Key-Lock" class="headerlink" title="临键锁(Next-Key Lock)"></a><strong>临键锁(Next-Key Lock)</strong></h2><p>临键锁也属于行锁的一种，并且它是INNODB的行锁默认算法，总结来说它就是记录锁和间隙锁的组合，临键锁会把查询出来的记录锁住，同时也会把该范围查询内的所有间隙空间也会锁住，再之它会把相邻的下一个区间也会锁住。</p>
<p><strong>例如：</strong>下面表的数据执行 <code>select * from user_info where id&gt;1 and id&lt;=13 for update ;</code></p>
<p>会锁住ID为5,10的记录；同时会锁住，1至5,5至10,10至15的区间。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1033-cQMHbj.jpg" alt="img"></p>
<p><strong>触发条件：</strong>范围查询，条件命中了索引。</p>
<p><strong>临键锁的作用：</strong>结合记录锁和间隙锁的特性，临键锁避免了在范围查询时出现脏读、重复读、幻读问题。加了临键锁之后，在范围区间内数据不允许被修改和插入。</p>
<h2 id="状态锁"><a href="#状态锁" class="headerlink" title="状态锁"></a><strong>状态锁</strong></h2><p>状态锁包括意向共享锁和意向排它锁，把他们区分为状态锁的一个核心逻辑，是因为这两个锁都是都是描述是否可以对某一个表进行加表锁的状态。</p>
<p><strong>意向锁的解释</strong>：当一个事务试图对<strong>整个表</strong>进行加锁（共享锁或排它锁）之前，首先需要获得对应类型的意向锁（意向共享锁或意向共享锁） </p>
<h3 id="意向共享锁"><a href="#意向共享锁" class="headerlink" title="意向共享锁"></a><strong>意向共享锁</strong></h3><p>当一个事务试图对<strong>整个表</strong>进行加共享锁之前，首先需要获得这个表的意向共享锁。</p>
<h3 id="意向排他锁"><a href="#意向排他锁" class="headerlink" title="意向排他锁"></a><strong>意向排他锁</strong></h3><p>当一个事务试图对<strong>整个表</strong>进行加排它锁之前，首先需要获得这个表的意向排它锁。</p>
<h3 id="为什么我们需要意向锁？"><a href="#为什么我们需要意向锁？" class="headerlink" title="为什么我们需要意向锁？"></a><strong>为什么我们需要意向锁？</strong></h3><p>意向锁光从概念上可能有点难理解，所以我们有必要从一个案例来分析其作用，这里首先我们先要有一个概念那就是innodb加锁的方式是基于索引，并且加锁粒度是行锁，然后我们来看下面的案例。</p>
<p><strong>第一步：</strong></p>
<p>事务A对user_info表执行一个SQL:update user_info set name =”张三” where id=6  加锁情况如下图;</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/07/1034-ec6pp9.jpg" alt="img"></p>
<p><strong>第二步：</strong></p>
<p>与此同时数据库又接收到事务B修改数据的请求：SQL: update user_info set name =”李四”；</p>
<p>1、因为事务B是对整个表进行修改操作，那么此SQL是需要对整个表进行加排它锁的（update加锁类型为排他锁）；</p>
<p>2、我们首先做的第一件事是先检查这个表有没有被别的事务锁住，只要有事务对表里的任何一行数据加了共享锁或排他锁我们就无法对整个表加锁（<strong>排他锁不能与任何属性的锁兼容</strong>）<strong>。</strong></p>
<p>3、因为INNODB锁的机制是基于行锁，那么这个时候我们会对整个索引每个节点一个个检查，我们需要检查每个节点是否被别的事务加了共享锁或排它锁。</p>
<p>4、最后检查到索引ID为6的节点被事务A锁住了，最后导致事务B只能等待事务A锁的释放才能进行加锁操作。</p>
<p><strong>思考：</strong></p>
<p>在A事务的操作过程中，后面的每个需要对user_info加持表锁的事务都需要遍历整个索引树才能知道自己是否能够进行加锁，这种方式是不是太浪费时间和损耗数据库性能了？ </p>
<p><strong>所以就有了意向锁的概念：</strong>如果当事务A加锁成功之后就设置一个状态告诉后面的人，已经有人对表里的行加了一个排他锁了，你们不能对整个表加共享锁或排它锁了，那么后面需要对整个表加锁的人只需要获取这个状态就知道自己是不是可以对表加锁，避免了对整个索引树的每个节点扫描是否加锁，而这个状态就是我们的意向锁。</p>
<p><strong>在测试锁的实操过程中需要注意的问题。</strong></p>
<p>看了这么多理论，相信很多人都会去实际操作一下，一是验证逻辑，而是加深自己的理解，为了避免大家少踩坑，在这里提醒几个需要注意的地方。</p>
<p>1、关闭自动提交事务功能，自己手动begin   commit  rollback。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;autocommit&#x27;</span></span><br><span class="line"><span class="keyword">Set</span> autocommit <span class="operator">=</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">begin</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb_user</span><br><span class="line"></span><br><span class="line"><span class="keyword">commit</span></span><br></pre></td></tr></table></figure>
<p>2、查看当前会话隔离级别是否为REPEATABLE-READ（一般默认都是此级别）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@tx</span>_isolation</span><br></pre></td></tr></table></figure>
<p>3、最重要的一点，查询数据的时候要使用当前读（因为Mysql 有MVCC的机制所以很多情况下都不会进行加锁，使用当前读就不会使用MVCC） 比如使用下面这个 for update 就是使用当前读。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb_user <span class="keyword">where</span> id<span class="operator">&gt;</span><span class="number">3</span> <span class="keyword">and</span> id<span class="operator">&lt;</span><span class="number">10</span> <span class="keyword">for</span> update</span><br><span class="line"></span><br><span class="line"><span class="keyword">COMMIT</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81MjMxMjM3Ng==">数据库基础（三）Mysql里的锁 - 知乎<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/13/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><a class="extend next" rel="next" href="/page/15/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



           </div>
          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

          
        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="meadel"
      src="/images/touxiang.jpeg">
  <p class="site-author-name" itemprop="name">meadel</p>
  <div class="site-description" itemprop="description">我的愿望，世界和平</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">154</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uY24vdXNlci80MDE5NDcwMjQ0MjU4NTUyL3Bvc3Rz" title="掘金 → https:&#x2F;&#x2F;juejin.cn&#x2F;user&#x2F;4019470244258552&#x2F;posts"><i class="fa fa-share-alt fa-fw"></i>掘金</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1ZV9taW5k" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;xue_mind"><i class="fa fa-th-list fa-fw"></i>CSDN</span>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-star"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">meadel</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">846k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">12:49</span>
</div>
  <div class="powered-by">这个世界会好吗？我是那么热爱这个世界。  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="js/canvas-ribbon.js"></script>
  <script src="//lib.baomitu.com/animejs/3.2.1/anime.min.js"></script>
  <script src="//lib.baomitu.com/next-theme-pjax/0.5.0/pjax.min.js"></script>
  <script src="//lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script>
  <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"></script>
  <script src="//lib.baomitu.com/medium-zoom/1.0.6/medium-zoom.min.js"></script>
  <script src="https://lib.baomitu.com/lozad.js/1.16.0/lozad.min.js"></script>
  <script src="https://lib.baomitu.com/pangu/4.0.7/pangu.min.js"></script>
  <script src="//lib.baomitu.com/velocity/1.5.2/velocity.min.js"></script>
  <script src="//lib.baomitu.com/velocity/1.5.2/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>


  <script defer src="js/three.min.js"></script>


  
  <script data-pjax>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>



  <script data-pjax>
  if (CONFIG.page.isPost) {
    wpac_init = window.wpac_init || [];
    wpac_init.push({
      widget: 'Rating',
      id    : 34163,
      el    : 'wpac-rating',
      color : 'fc6423'
    });
    (function() {
      if ('WIDGETPACK_LOADED' in window) return;
      WIDGETPACK_LOADED = true;
      var mc = document.createElement('script');
      mc.type = 'text/javascript';
      mc.async = true;
      mc.src = '//embed.widgetpack.com/widget.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
    })();
  }
  </script>

  
<script src="/js/local-search.js"></script>









<script data-pjax>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




    <div id="pjax">
  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//lib.baomitu.com/valine/1.4.17/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'xOnoKG9QyBMz9vYupNusn9fn-gzGzoHsz',
      appKey     : 'RfiNClAkp7Ewe9rlzrjAQEXC',
      placeholder: "吐槽一下...",
      avatar     : 'monsterid',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : '',
      requiredFields : ['nick','mail']
    });
  }, window.Valine);
});
</script>

    </div>
  <link rel="stylesheet" href="/dist/APlayer.min.css">
  <div id="aplayer"></div>
  <script type="text/javascript" src="/dist/APlayer.min.js"></script>
  <script type="text/javascript" src="/dist/music.js"></script>
</body>
</html>
