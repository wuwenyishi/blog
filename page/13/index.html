<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://cdn.baomitu.com/index/fonts/css?family=Ma Shan Zheng:300,300italic,400,400italic,700,700italic|Noto Sans Simplified Chinese:300,300italic,400,400italic,700,700italic|Noto Serif SC:300,300italic,400,400italic,700,700italic|Monaco:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="//lib.baomitu.com/font-awesome/5.15.4/css/all.min.css">
  <link rel="stylesheet" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
  <link rel="stylesheet" href="//lib.baomitu.com/pace/1.0.2/themes/blue/pace-theme-minimal.min.css">
  <script src="//lib.baomitu.com/pace/1.0.2/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"xuemingde.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":true,"sidebar":{"position":"left","width":300,"display":"always","padding":18,"offset":10,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="我的愿望，世界和平">
<meta property="og:type" content="website">
<meta property="og:title" content="Middle&#39;s blog">
<meta property="og:url" content="https://xuemingde.com/page/13/index.html">
<meta property="og:site_name" content="Middle&#39;s blog">
<meta property="og:description" content="我的愿望，世界和平">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="meadel">
<meta property="article:tag" content="meadel">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://xuemingde.com/page/13/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Middle's blog - 一位程序员的成长之路</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Middle's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">一位程序员的成长之路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-notepad">

    <a href="/notepad/" rel="section"><i class="fa fa-book fa-fw"></i>备忘录</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源库</a>

  </li>
        <li class="menu-item menu-item-collect">

    <a href="/collect/" rel="section"><i class="fa fa-star fa-fw"></i>收藏夹</a>

  </li>
        <li class="menu-item menu-item-links">

    <a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>友链</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

           <div id="container-1">
            <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/3N8921N.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/3N8921N.html" class="post-title-link" itemprop="url">彻底讲透Elasticsearch</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-11 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-11T00:00:00+08:00">2022-04-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2/" itemprop="url" rel="index"><span itemprop="name">搜索</span></a>
                </span>
            </span>

          
            <span id="/posts/3N8921N.html" class="post-meta-item leancloud_visitors" data-flag-title="彻底讲透Elasticsearch" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/3N8921N.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/3N8921N.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>17k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>16 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>原文： <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vamFqaWFuL3AvMTEyMjM5OTIuaHRtbA==">Elasticsearch 技术分析（九）：全文搜索引擎Elasticsearch，这篇文章给讲透了！ - JaJian - 博客园<i class="fa fa-external-link-alt"></i></span>  </p>
</blockquote>
<p>由于近期在公司内部做了一次 Elasticsearch 的分享，所以本篇主要是做一个总结，希望通过这篇文章能让读者大致了解 Elasticsearch 是做什么的以及它的使用和基本原理。</p>
<h2 id="生活中的数据"><a href="#生活中的数据" class="headerlink" title="生活中的数据"></a>生活中的数据</h2><p>搜索引擎是对数据的检索，所以我们先从生活中的数据说起。我们生活中的数据总体分为两种：</p>
<blockquote>
<ul>
<li>结构化数据</li>
<li>非结构化数据</li>
</ul>
</blockquote>
<p><strong>结构化数据：</strong> 也称作行数据，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。指具有固定格式或有限长度的数据，如数据库，元数据等。</p>
<p><strong>非结构化数据：</strong> 又可称为全文数据，不定长或无固定格式，不适于由数据库二维表来表现，包括所有格式的办公文档、XML、HTML、Word 文档，邮件，各类报表、图片和咅频、视频信息等。</p>
<p>说明：如果要更细致的区分的话，XML、HTML 可划分为半结构化数据。因为它们也具有自己特定的标签格式，所以既可以根据需要按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。</p>
<p>根据两种数据分类，搜索也相应的分为两种：</p>
<blockquote>
<ul>
<li>结构化数据搜索</li>
<li>非结构化数据搜索</li>
</ul>
</blockquote>
<p>对于结构化数据，因为它们具有特定的结构，所以我们一般都是可以通过关系型数据库（MySQL，Oracle 等）的二维表（Table）的方式存储和搜索，也可以建立索引。</p>
<p>对于非结构化数据，也即对全文数据的搜索主要有两种方法：</p>
<blockquote>
<ul>
<li>顺序扫描</li>
<li>全文检索</li>
</ul>
</blockquote>
<p><strong>顺序扫描：</strong> <code>通过文字名称也可了解到它的大概搜索方式，即按照顺序扫描的方式查询特定的关键字</code>。</p>
<p>例如给你一张报纸，让你找到该报纸中“平安”的文字在哪些地方出现过。你肯定需要从头到尾把报纸阅读扫描一遍然后标记出关键字在哪些版块出现过以及它的出现位置。</p>
<p>这种方式无疑是最耗时的最低效的，如果报纸排版字体小，而且版块较多甚至有多份报纸，等你扫描完你的眼睛也差不多了。</p>
<p><strong>全文搜索：</strong> 对非结构化数据顺序扫描很慢，我们是否可以进行优化？把我们的非结构化数据想办法弄得有一定结构不就行了吗？</p>
<p>将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。</p>
<p>这种方式就构成了全文检索的基本思路。这部分从非结构化数据中提取出的然后重新组织的信息，我们称之为索引。</p>
<p>这种方式的主要工作量在前期索引的创建，但是对于后期搜索却是快速高效的。</p>
<h2 id="先说说-Lucene"><a href="#先说说-Lucene" class="headerlink" title="先说说 Lucene"></a>先说说 Lucene</h2><p>通过对生活中数据的类型作了一个简短了解之后，我们知道关系型数据库的 SQL 检索是处理不了这种非结构化数据的。</p>
<p>这种非结构化数据的处理需要依赖全文搜索，而目前市场上开放源代码的最好全文检索引擎工具包就属于 Apache 的 Lucene了。</p>
<p>但是 Lucene 只是一个工具包，它不是一个完整的全文检索引擎。Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。</p>
<p>目前以 Lucene 为基础建立的开源可用全文搜索引擎主要是 Solr 和 Elasticsearch。</p>
<p>Solr 和 Elasticsearch 都是比较成熟的全文搜索引擎，能完成的功能和性能也基本一样。</p>
<p>但是 ES 本身就具有分布式的特性和易安装使用的特点，而 Solr 的分布式需要借助第三方来实现，例如通过使用 ZooKeeper 来达到分布式协调管理。</p>
<p>不管是 Solr 还是 Elasticsearch 底层都是依赖于 Lucene，而 Lucene 能实现全文搜索主要是因为它实现了倒排索引的查询结构。</p>
<p>如何理解倒排索引呢？ 假如现有三份数据文档，文档的内容如下分别是：</p>
<blockquote>
<ul>
<li>Java is the best programming language.</li>
<li>PHP is the best programming language.</li>
<li>Javascript is the best programming language.</li>
</ul>
</blockquote>
<p>为了创建倒排索引，我们通过分词器将每个文档的内容域拆分成单独的词（我们称它为词条或 Term），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。</p>
<p>结果如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Term          Doc_1    Doc_2   Doc_3  </span><br><span class="line"></span><br><span class="line">Java        |   X   |        |  </span><br><span class="line">is          |   X   |   X    |   X  </span><br><span class="line">the         |   X   |   X    |   X  </span><br><span class="line">best        |   X   |   X    |   X  </span><br><span class="line">programming |   x   |   X    |   X  </span><br><span class="line">language    |   X   |   X    |   X  </span><br><span class="line">PHP         |       |   X    |  </span><br><span class="line">Javascript  |       |        |   X  </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这种结构由文档中所有不重复词的列表构成，对于其中每个词都有一个文档列表与之关联。</p>
<p>这种由属性值来确定记录的位置的结构就是倒排索引。带有倒排索引的文件我们称为倒排文件。</p>
<p>我们将上面的内容转换为图的形式来说明倒排索引的结构信息，如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1024-IMR8gD.png" alt="图片"></p>
<p>其中主要有如下几个核心术语需要理解：</p>
<blockquote>
<ul>
<li><strong>词条（Term）：</strong> 索引里面最小的存储和查询单元，对于英文来说是一个单词，对于中文来说一般指分词后的一个词。</li>
<li><strong>词典（Term Dictionary）：</strong> 或字典，是词条 Term 的集合。搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。</li>
<li><strong>倒排表（Post list）：</strong> 一个文档通常由多个词组成，倒排表记录的是某个词在哪些文档里出现过以及出现的位置。每条记录称为一个倒排项（Posting）。倒排表记录的不单是文档编号，还存储了词频等信息。</li>
<li><strong>倒排文件（Inverted File）：</strong> 所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件被称之为倒排文件，倒排文件是存储倒排索引的物理文件。</li>
</ul>
</blockquote>
<p>从上图我们可以了解到倒排索引主要由两个部分组成：</p>
<blockquote>
<ul>
<li>词典</li>
<li>倒排文件</li>
</ul>
</blockquote>
<p>词典和倒排表是 Lucene 中很重要的两种数据结构，是实现快速检索的重要基石。词典和倒排文件是分两部分存储的，词典在内存中而倒排文件存储在磁盘上。</p>
<h2 id="ES-核心概念"><a href="#ES-核心概念" class="headerlink" title="ES 核心概念"></a>ES 核心概念</h2><p>一些基础知识的铺垫之后我们正式进入今天的主角 Elasticsearch 的介绍。</p>
<p>ES 是使用 Java 编写的一种开源搜索引擎，它在内部使用 Lucene 做索引与搜索，通过对 Lucene 的封装，隐藏了 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。</p>
<p>然而，Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。</p>
<p>它可以被下面这样准确的形容：</p>
<blockquote>
<ul>
<li>一个分布式的实时文档存储，每个字段可以被索引与搜索。</li>
<li>一个分布式实时分析搜索引擎。</li>
<li>能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据。</li>
</ul>
</blockquote>
<p>官网对 Elasticsearch 的介绍是 Elasticsearch 是一个分布式、可扩展、近实时的搜索与数据分析引擎。</p>
<p>我们通过一些核心概念来看下 Elasticsearch 是如何做到分布式，可扩展和近实时搜索的。</p>
<h3 id="集群（Cluster）"><a href="#集群（Cluster）" class="headerlink" title="集群（Cluster）"></a>集群（Cluster）</h3><p>ES 的集群搭建很简单，不需要依赖第三方协调管理组件，自身内部就实现了集群的管理功能。</p>
<p>ES 集群由一个或多个 Elasticsearch 节点组成，每个节点配置相同的 cluster.name 即可加入集群，默认值为 “elasticsearch”。</p>
<p>确保不同的环境中使用不同的集群名称，否则最终会导致节点加入错误的集群。</p>
<p>一个 Elasticsearch 服务启动实例就是一个节点（Node）。节点通过 node.name 来设置节点名称，如果不设置则在启动时给节点分配一个随机通用唯一标识符作为名称。</p>
<h4 id="①发现机制"><a href="#①发现机制" class="headerlink" title="①发现机制"></a>①发现机制</h4><p>那么有一个问题，ES 内部是如何通过一个相同的设置 cluster.name 就能将不同的节点连接到同一个集群的？答案是 Zen Discovery。</p>
<p>Zen Discovery 是 Elasticsearch 的内置默认发现模块（发现模块的职责是发现集群中的节点以及选举 Master 节点）。</p>
<p>它提供单播和基于文件的发现，并且可以扩展为通过插件支持云环境和其他形式的发现。</p>
<p>Zen Discovery 与其他模块集成，例如，节点之间的所有通信都使用 Transport 模块完成。节点使用发现机制通过 Ping 的方式查找其他节点。</p>
<p>Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。</p>
<p>如果集群的节点运行在不同的机器上，使用单播，你可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表。</p>
<p>当一个节点联系到单播列表中的成员时，它就会得到整个集群所有节点的状态，然后它会联系 Master 节点，并加入集群。</p>
<p>这意味着单播列表不需要包含集群中的所有节点， 它只是需要足够的节点，当一个新节点联系上其中一个并且说上话就可以了。</p>
<p>如果你使用 Master 候选节点作为单播列表，你只要列出三个就可以了。这个配置在 elasticsearch.yml 文件中：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">discovery<span class="selector-class">.zen</span><span class="selector-class">.ping</span><span class="selector-class">.unicast</span><span class="selector-class">.hosts</span>: <span class="selector-attr">[<span class="string">&quot;host1&quot;</span>, <span class="string">&quot;host2:port&quot;</span>]</span>  </span><br></pre></td></tr></table></figure>
<p>节点启动后先 Ping ，如果 <code>discovery.zen.ping.unicast.hosts</code> 有设置，则 Ping 设置中的 Host ，否则尝试 ping localhost 的几个端口。</p>
<p>Elasticsearch 支持同一个主机启动多个节点，Ping 的 Response 会包含该节点的基本信息以及该节点认为的 Master 节点。</p>
<p>选举开始，先从各节点认为的 Master 中选，规则很简单，按照 ID 的字典序排序，取第一个。如果各节点都没有认为的 Master ，则从所有节点中选择，规则同上。</p>
<p>这里有个限制条件就是 <code>discovery.zen.minimum_master_nodes</code> ，如果节点数达不到最小值的限制，则循环上述过程，直到节点数足够可以开始选举。</p>
<p>最后选举结果是肯定能选举出一个 Master ，如果只有一个 Local 节点那就选出的是自己。</p>
<p>如果当前节点是 Master ，则开始等待节点数达到 <code>discovery.zen.minimum_master_nodes</code>，然后提供服务。</p>
<p>如果当前节点不是 Master ，则尝试加入 Master 。Elasticsearch 将以上服务发现以及选主的流程叫做 Zen Discovery 。</p>
<p>由于它支持任意数目的集群（ 1- N ），所以不能像 Zookeeper 那样限制节点必须是奇数，也就无法用投票的机制来选主，而是通过一个规则。</p>
<p>只要所有的节点都遵循同样的规则，得到的信息都是对等的，选出来的主节点肯定是一致的。</p>
<p>但分布式系统的问题就出在信息不对等的情况，这时候很容易出现脑裂（Split-Brain）的问题。</p>
<p>大多数解决方案就是设置一个 Quorum 值，要求可用节点必须大于 Quorum（一般是超过半数节点），才能对外提供服务。</p>
<p>而 Elasticsearch 中，这个 Quorum 的配置就是 <code>discovery.zen.minimum_master_nodes</code> 。</p>
<h4 id="②节点的角色"><a href="#②节点的角色" class="headerlink" title="②节点的角色"></a>②节点的角色</h4><p>每个节点既可以是候选主节点也可以是数据节点，通过在配置文件 ../config/elasticsearch.yml 中设置即可，默认都为 true。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node.master: <span class="literal">true</span>  <span class="comment">//是否候选主节点  </span></span><br><span class="line">node.<span class="keyword">data</span>: <span class="literal">true</span>    <span class="comment">//是否数据节点  </span></span><br></pre></td></tr></table></figure>
<p>数据节点负责数据的存储和相关的操作，例如对数据进行增、删、改、查和聚合等操作，所以数据节点（Data 节点）对机器配置要求比较高，对 CPU、内存和 I/O 的消耗很大。</p>
<p>通常随着集群的扩大，需要增加更多的数据节点来提高性能和可用性。</p>
<p>候选主节点可以被选举为主节点（Master 节点），集群中只有候选主节点才有选举权和被选举权，其他节点不参与选举的工作。</p>
<p>主节点负责创建索引、删除索引、跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点、追踪集群中节点的状态等，稳定的主节点对集群的健康是非常重要的。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1100-aOqGch.jpeg" alt="图片"></p>
<p>一个节点既可以是候选主节点也可以是数据节点，但是由于数据节点对 CPU、内存核 I/O 消耗都很大。</p>
<p>所以如果某个节点既是数据节点又是主节点，那么可能会对主节点产生影响从而对整个集群的状态产生影响。</p>
<p>因此为了提高集群的健康性，我们应该对 Elasticsearch 集群中的节点做好角色上的划分和隔离。可以使用几个配置较低的机器群作为候选主节点群。</p>
<p>主节点和其他节点之间通过 Ping 的方式互检查，主节点负责 Ping 所有其他节点，判断是否有节点已经挂掉。其他节点也通过 Ping 的方式判断主节点是否处于可用状态。</p>
<p>虽然对节点做了角色区分，但是用户的请求可以发往任何一个节点，并由该节点负责分发请求、收集结果等操作，而不需要主节点转发。</p>
<p>这种节点可称之为协调节点，协调节点是不需要指定和配置的，集群中的任何节点都可以充当协调节点的角色。</p>
<h4 id="③脑裂现象"><a href="#③脑裂现象" class="headerlink" title="③脑裂现象"></a>③脑裂现象</h4><p>同时如果由于网络或其他原因导致集群中选举出多个 Master 节点，使得数据更新时出现不一致，这种现象称之为脑裂，即集群中不同的节点对于 Master 的选择出现了分歧，出现了多个 Master 竞争。</p>
<p>“脑裂”问题可能有以下几个原因造成：</p>
<ul>
<li><strong>网络问题：</strong> 集群间的网络延迟导致一些节点访问不到 Master，认为 Master 挂掉了从而选举出新的 Master，并对 Master 上的分片和副本标红，分配新的主分片。</li>
<li><strong>节点负载：</strong> 主节点的角色既为 Master 又为 Data，访问量较大时可能会导致 ES 停止响应（假死状态）造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。</li>
<li><strong>内存回收：</strong> 主节点的角色既为 Master 又为 Data，当 Data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收，造成 ES 进程失去响应。</li>
</ul>
<p>为了避免脑裂现象的发生，我们可以从原因着手通过以下几个方面来做出优化措施：</p>
<ul>
<li><strong>适当调大响应时间，减少误判。</strong> 通过参数 discovery.zen.ping_timeout 设置节点状态的响应时间，默认为 3s，可以适当调大。</li>
</ul>
<p>如果 Master 在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如 6s，<code>discovery.zen.ping_timeout:6</code>），可适当减少误判。</p>
<ul>
<li><strong>选举触发。</strong> 我们需要在候选集群中的节点的配置文件中设置参数 <code>discovery.zen.munimum_master_nodes</code> 的值。</li>
</ul>
<p>这个参数表示在选举主节点时需要参与选举的候选主节点的节点数，默认值是 1，官方建议取值(<code>master_eligibel_nodes2)+1</code>，其中 <code>master_eligibel_nodes</code> 为候选主节点的个数。</p>
<p>这样做既能防止脑裂现象的发生，也能最大限度地提升集群的高可用性，因为只要不少于 <code>discovery.zen.munimum_master_nodes</code> 个候选节点存活，选举工作就能正常进行。</p>
<p>当小于这个值的时候，无法触发选举行为，集群无法使用，不会造成分片混乱的情况。</p>
<ul>
<li><strong>角色分离。</strong> 即是上面我们提到的候选主节点和数据节点进行角色分离，这样可以减轻主节点的负担，防止主节点的假死状态发生，减少对主节点“已死”的误判。</li>
</ul>
<h3 id="分片（Shards）"><a href="#分片（Shards）" class="headerlink" title="分片（Shards）"></a>分片（Shards）</h3><p>ES 支持 PB 级全文搜索，当索引上的数据量太大的时候，ES 通过水平拆分的方式将一个索引上的数据拆分出来分配到不同的数据块上，拆分出来的数据库块称之为一个分片。</p>
<p>这类似于 MySQL 的分库分表，只不过 MySQL 分库分表需要借助第三方组件而 ES 内部自身实现了此功能。</p>
<p>在一个多分片的索引中写入数据时，通过路由来确定具体写入哪一个分片中，所以在创建索引的时候需要指定分片的数量，并且分片的数量一旦确定就不能修改。</p>
<p>分片的数量和下面介绍的副本数量都是可以通过创建索引时的 Settings 来配置，ES 默认为一个索引创建 5 个主分片, 并分别为每个分片创建一个副本。</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PUT /myIndex  </span><br><span class="line">&#123;  </span><br><span class="line">   <span class="string">&quot;settings&quot;</span> : &#123;  </span><br><span class="line">      <span class="string">&quot;number_of_shards&quot;</span> : 5,  </span><br><span class="line">      <span class="string">&quot;number_of_replicas&quot;</span> : 1  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>ES 通过分片的功能使得索引在规模上和性能上都得到提升，每个分片都是 Lucene 中的一个索引文件，每个分片必须有一个主分片和零到多个副本。</p>
<h3 id="副本（Replicas）"><a href="#副本（Replicas）" class="headerlink" title="副本（Replicas）"></a>副本（Replicas）</h3><p>副本就是对分片的 Copy，每个主分片都有一个或多个副本分片，当主分片异常时，副本可以提供数据的查询等操作。</p>
<p>主分片和对应的副本分片是不会在同一个节点上的，所以副本分片数的最大值是 N-1（其中 N 为节点数）。</p>
<p>对文档的新建、索引和删除请求都是写操作，必须在主分片上面完成之后才能被复制到相关的副本分片。</p>
<p>ES 为了提高写入的能力这个过程是并发写的，同时为了解决并发写的过程中数据冲突的问题，ES 通过乐观锁的方式控制，每个文档都有一个<code>_version</code> （版本）号，当文档被修改时版本号递增。</p>
<p>一旦所有的副本分片都报告写成功才会向协调节点报告成功，协调节点向客户端报告成功。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1101-yqpKgY.png" alt="图片"></p>
<p>从上图可以看出为了达到高可用，Master 节点会避免将主分片和副本分片放在同一个节点上。</p>
<p>假设这时节点 Node1 服务宕机了或者网络不可用了，那么主节点上主分片 S0 也就不可用了。</p>
<p>幸运的是还存在另外两个节点能正常工作，这时 ES 会重新选举新的主节点，而且这两个节点上存在我们所需要的 S0 的所有数据。</p>
<p>我们会将 S0 的副本分片提升为主分片，这个提升主分片的过程是瞬间发生的。此时集群的状态将会为  Yellow。</p>
<p>为什么我们集群状态是 Yellow 而不是 Green 呢？虽然我们拥有所有的 2 个主分片，但是同时设置了每个主分片需要对应两份副本分片，而此时只存在一份副本分片。所以集群不能为 Green 的状态。</p>
<p>如果我们同样关闭了 Node2 ，我们的程序依然可以保持在不丢失任何数据的情况下运行，因为 Node3 为每一个分片都保留着一份副本。</p>
<p>如果我们重新启动 Node1 ，集群可以将缺失的副本分片再次进行分配，那么集群的状态又将恢复到原来的正常状态。</p>
<p>如果 Node1 依然拥有着之前的分片，它将尝试去重用它们，只不过这时 Node1 节点上的分片不再是主分片而是副本分片了，如果期间有更改的数据只需要从主分片上复制修改的数据文件即可。</p>
<h4 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h4><ul>
<li>将数据分片是为了提高可处理数据的容量和易于进行水平扩展，为分片做副本是为了提高集群的稳定性和提高并发量。</li>
<li>副本是乘法，越多消耗越大，但也越保险。分片是除法，分片越多，单分片数据就越少也越分散。</li>
<li>副本越多，集群的可用性就越高，但是由于每个分片都相当于一个 Lucene 的索引文件，会占用一定的文件句柄、内存及 CPU。并且分片间的数据同步也会占用一定的网络带宽，所以索引的分片数和副本数也不是越多越好。</li>
</ul>
<h3 id="映射（Mapping）"><a href="#映射（Mapping）" class="headerlink" title="映射（Mapping）"></a>映射（Mapping）</h3><p>映射是用于定义 ES 对索引中字段的存储类型、分词方式和是否存储等信息，就像数据库中的 Schema ，描述了文档可能具有的字段或属性、每个字段的数据类型。</p>
<p>只不过关系型数据库建表时必须指定字段类型，而 ES 对于字段类型可以不指定然后动态对字段类型猜测，也可以在创建索引时具体指定字段的类型。</p>
<p>对字段类型根据数据格式自动识别的映射称之为动态映射（Dynamic Mapping），我们创建索引时具体定义字段类型的映射称之为静态映射或显示映射（Explicit Mapping）。</p>
<p>在讲解动态映射和静态映射的使用前，我们先来了解下 ES 中的数据有哪些字段类型？之后我们再讲解为什么我们创建索引时需要建立静态映射而不使用动态映射。</p>
<p>ES（v6.8）中字段数据类型主要有以下几类：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1101-aQjEet.png" alt="图片"></p>
<p>Text 用于索引全文值的字段，例如电子邮件正文或产品说明。这些字段是被分词的，它们通过分词器传递 ，以在被索引之前将字符串转换为单个术语的列表。</p>
<p>分析过程允许 Elasticsearch 搜索单个单词中每个完整的文本字段。文本字段不用于排序，很少用于聚合。</p>
<p>Keyword 用于索引结构化内容的字段，例如电子邮件地址，主机名，状态代码，邮政编码或标签。它们通常用于过滤，排序，和聚合。Keyword 字段只能按其确切值进行搜索。</p>
<p>通过对字段类型的了解我们知道有些字段需要明确定义的，例如某个字段是 Text 类型还是 Keyword 类型差别是很大的，时间字段也许我们需要指定它的时间格式，还有一些字段我们需要指定特定的分词器等等。</p>
<p>如果采用动态映射是不能精确做到这些的，自动识别常常会与我们期望的有些差异。</p>
<p>所以创建索引的时候一个完整的格式应该是指定分片和副本数以及 Mapping 的定义，如下：</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index   </span><br><span class="line">&#123;  </span><br><span class="line">   <span class="string">&quot;settings&quot;</span> : &#123;  </span><br><span class="line">      <span class="string">&quot;number_of_shards&quot;</span> : 5,  </span><br><span class="line">      <span class="string">&quot;number_of_replicas&quot;</span> : 1  </span><br><span class="line">   &#125;  </span><br><span class="line">  <span class="string">&quot;mappings&quot;</span>: &#123;  </span><br><span class="line">    <span class="string">&quot;_doc&quot;</span>: &#123;   </span><br><span class="line">      <span class="string">&quot;properties&quot;</span>: &#123;   </span><br><span class="line">        <span class="string">&quot;title&quot;</span>:    &#123; <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>  &#125;,   </span><br><span class="line">        <span class="string">&quot;name&quot;</span>:     &#123; <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>  &#125;,   </span><br><span class="line">        <span class="string">&quot;age&quot;</span>:      &#123; <span class="string">&quot;type&quot;</span>: <span class="string">&quot;integer&quot;</span> &#125;,    </span><br><span class="line">        <span class="string">&quot;created&quot;</span>:  &#123;  </span><br><span class="line">          <span class="string">&quot;type&quot;</span>:   <span class="string">&quot;date&quot;</span>,   </span><br><span class="line">          <span class="string">&quot;format&quot;</span>: <span class="string">&quot;strict_date_optional_time||epoch_millis&quot;</span>  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<h2 id="ES-的基本使用"><a href="#ES-的基本使用" class="headerlink" title="ES 的基本使用"></a>ES 的基本使用</h2><p>在决定使用 Elasticsearch 的时候首先要考虑的是版本问题，Elasticsearch （排除 0.x 和 1.x）目前有如下常用的稳定的主版本：2.x，5.x，6.x，7.x（current）。</p>
<p>你可能会发现没有 3.x 和 4.x，ES 从 2.4.6 直接跳到了 5.0.0。其实是为了 ELK（ElasticSearch，Logstash，Kibana）技术栈的版本统一，免的给用户带来混乱。</p>
<p>在 Elasticsearch 是 2.x （2.x 的最后一版 2.4.6 的发布时间是 July 25, 2017） 的情况下，Kibana 已经是 4.x（Kibana 4.6.5 的发布时间是 July 25, 2017）。</p>
<p>那么在 Kibana 的下一主版本肯定是 5.x 了，所以 Elasticsearch 直接将自己的主版本发布为 5.0.0 了。</p>
<p>统一之后，我们选版本就不会犹豫困惑了，我们选定 Elasticsearch 的版本后再选择相同版本的 Kibana 就行了，不用担忧版本不兼容的问题。</p>
<p>Elasticsearch 是使用 Java 构建，所以除了注意 ELK 技术的版本统一，我们在选择 Elasticsearch 的版本的时候还需要注意 JDK 的版本。</p>
<p>因为每个大版本所依赖的 JDK 版本也不同，目前 7.2 版本已经可以支持 JDK11。</p>
<h3 id="安装使用"><a href="#安装使用" class="headerlink" title="安装使用"></a>安装使用</h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1103-zUwx70.png" alt="图片"></p>
<p>①下载和解压 Elasticsearch，无需安装解压后即可用，解压后目录如上图：</p>
<blockquote>
<ul>
<li><code>bin</code>：二进制系统指令目录，包含启动命令和安装插件命令等。</li>
<li><code>config</code>：配置文件目录。</li>
<li><code>data</code>：数据存储目录。</li>
<li><code>lib</code>：依赖包目录。</li>
<li><code>logs</code>：日志文件目录。</li>
<li><code>modules</code>：模块库，例如 x-pack 的模块。</li>
<li><code>plugins</code>：插件目录。</li>
</ul>
</blockquote>
<p>②安装目录下运行 <code>bin/elasticsearch</code> 来启动 ES。</p>
<p>③默认在 9200 端口运行，请求 curl <span class="exturl" data-url="aHR0cDovL2xvY2FsaG9zdDo5MjAwLw==">http://localhost:9200/<i class="fa fa-external-link-alt"></i></span> 或者浏览器输入 <span class="exturl" data-url="aHR0cDovL2xvY2FsaG9zdDo5MjAw77yM5b6X5Yiw5LiA5Liq">http://localhost:9200，得到一个<i class="fa fa-external-link-alt"></i></span> JSON 对象，其中包含当前节点、集群、版本等信息。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;  </span><br><span class="line">  <span class="attr">&quot;name&quot;</span> : <span class="string">&quot;U7fp3O9&quot;</span>,  </span><br><span class="line">  <span class="attr">&quot;cluster_name&quot;</span> : <span class="string">&quot;elasticsearch&quot;</span>,  </span><br><span class="line">  <span class="attr">&quot;cluster_uuid&quot;</span> : <span class="string">&quot;-Rj8jGQvRIelGd9ckicUOA&quot;</span>,  </span><br><span class="line">  <span class="attr">&quot;version&quot;</span> : &#123;  </span><br><span class="line">    <span class="attr">&quot;number&quot;</span> : <span class="string">&quot;6.8.1&quot;</span>,  </span><br><span class="line">    <span class="attr">&quot;build_flavor&quot;</span> : <span class="string">&quot;default&quot;</span>,  </span><br><span class="line">    <span class="attr">&quot;build_type&quot;</span> : <span class="string">&quot;zip&quot;</span>,  </span><br><span class="line">    <span class="attr">&quot;build_hash&quot;</span> : <span class="string">&quot;1fad4e1&quot;</span>,  </span><br><span class="line">    <span class="attr">&quot;build_date&quot;</span> : <span class="string">&quot;2019-06-18T13:16:52.517138Z&quot;</span>,  </span><br><span class="line">    <span class="attr">&quot;build_snapshot&quot;</span> : <span class="literal">false</span>,  </span><br><span class="line">    <span class="attr">&quot;lucene_version&quot;</span> : <span class="string">&quot;7.7.0&quot;</span>,  </span><br><span class="line">    <span class="attr">&quot;minimum_wire_compatibility_version&quot;</span> : <span class="string">&quot;5.6.0&quot;</span>,  </span><br><span class="line">    <span class="attr">&quot;minimum_index_compatibility_version&quot;</span> : <span class="string">&quot;5.0.0&quot;</span>  </span><br><span class="line">  &#125;,  </span><br><span class="line">  <span class="attr">&quot;tagline&quot;</span> : <span class="string">&quot;You Know, for Search&quot;</span>  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<h3 id="集群健康状态"><a href="#集群健康状态" class="headerlink" title="集群健康状态"></a>集群健康状态</h3><p>要检查群集运行状况，我们可以在 Kibana 控制台中运行以下命令 GET /_cluster/health，得到如下信息：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;  </span><br><span class="line">  <span class="attr">&quot;cluster_name&quot;</span> : <span class="string">&quot;wujiajian&quot;</span>,  </span><br><span class="line">  <span class="attr">&quot;status&quot;</span> : <span class="string">&quot;yellow&quot;</span>,  </span><br><span class="line">  <span class="attr">&quot;timed_out&quot;</span> : <span class="literal">false</span>,  </span><br><span class="line">  <span class="attr">&quot;number_of_nodes&quot;</span> : <span class="number">1</span>,  </span><br><span class="line">  <span class="attr">&quot;number_of_data_nodes&quot;</span> : <span class="number">1</span>,  </span><br><span class="line">  <span class="attr">&quot;active_primary_shards&quot;</span> : <span class="number">9</span>,  </span><br><span class="line">  <span class="attr">&quot;active_shards&quot;</span> : <span class="number">9</span>,  </span><br><span class="line">  <span class="attr">&quot;relocating_shards&quot;</span> : <span class="number">0</span>,  </span><br><span class="line">  <span class="attr">&quot;initializing_shards&quot;</span> : <span class="number">0</span>,  </span><br><span class="line">  <span class="attr">&quot;unassigned_shards&quot;</span> : <span class="number">5</span>,  </span><br><span class="line">  <span class="attr">&quot;delayed_unassigned_shards&quot;</span> : <span class="number">0</span>,  </span><br><span class="line">  <span class="attr">&quot;number_of_pending_tasks&quot;</span> : <span class="number">0</span>,  </span><br><span class="line">  <span class="attr">&quot;number_of_in_flight_fetch&quot;</span> : <span class="number">0</span>,  </span><br><span class="line">  <span class="attr">&quot;task_max_waiting_in_queue_millis&quot;</span> : <span class="number">0</span>,  </span><br><span class="line">  <span class="attr">&quot;active_shards_percent_as_number&quot;</span> : <span class="number">64.28571428571429</span>  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>集群状态通过 绿，黄，红 来标识：</p>
<blockquote>
<ul>
<li>绿色：集群健康完好，一切功能齐全正常，所有分片和副本都可以正常工作。</li>
<li>黄色：预警状态，所有主分片功能正常，但至少有一个副本是不能正常工作的。此时集群是可以正常工作的，但是高可用性在某种程度上会受影响。</li>
<li>红色：集群不可正常使用。某个或某些分片及其副本异常不可用，这时集群的查询操作还能执行，但是返回的结果会不准确。对于分配到这个分片的写入请求将会报错，最终会导致数据的丢失。</li>
</ul>
</blockquote>
<p>当集群状态为红色时，它将会继续从可用的分片提供搜索请求服务，但是你需要尽快修复那些未分配的分片。</p>
<h2 id="ES-机制原理"><a href="#ES-机制原理" class="headerlink" title="ES 机制原理"></a>ES 机制原理</h2><p>ES 的基本概念和基本操作介绍完了之后，我们可能还有很多疑惑：</p>
<blockquote>
<ul>
<li>它们内部是如何运行的？</li>
<li>主分片和副本分片是如何同步的？</li>
<li>创建索引的流程是什么样的？</li>
<li>ES 如何将索引数据分配到不同的分片上的？以及这些索引数据是如何存储的？</li>
<li>为什么说 ES 是近实时搜索引擎而文档的 CRUD (创建-读取-更新-删除) 操作是实时的？</li>
<li>以及 Elasticsearch 是怎样保证更新被持久化在断电时也不丢失数据？</li>
<li>还有为什么删除文档不会立刻释放空间？</li>
</ul>
</blockquote>
<p>带着这些疑问我们进入接下来的内容。</p>
<h3 id="写索引原理"><a href="#写索引原理" class="headerlink" title="写索引原理"></a>写索引原理</h3><p>下图描述了 3 个节点的集群，共拥有 12 个分片，其中有 4 个主分片（S0、S1、S2、S3）和 8 个副本分片（R0、R1、R2、R3），每个主分片对应两个副本分片，节点 1 是主节点（Master 节点）负责整个集群的状态。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1104-dX9QIi.png" alt="图片"></p>
<p>写索引是只能写在主分片上，然后同步到副本分片。这里有四个主分片，一条数据 ES 是根据什么规则写到特定分片上的呢？</p>
<p>这条索引数据为什么被写到 S0 上而不写到 S1 或 S2 上？那条数据为什么又被写到 S3 上而不写到 S0 上了？</p>
<p>首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。</p>
<p>实际上，这个过程是根据下面这个公式决定的：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">shard</span> = hash(routing) % number_of_primary_shards  </span><br></pre></td></tr></table></figure>
<p>Routing 是一个可变值，默认是文档的<code>_id</code> ，也可以设置成一个自定义的值。</p>
<p>Routing 通过 Hash 函数生成一个数字，然后这个数字再除以 <code>number_of_primary_shards</code> （主分片的数量）后得到余数。</p>
<p>这个在 0 到 <code>number_of_primary_shards-1</code> 之间的余数，就是我们所寻求的文档所在分片的位置。</p>
<p>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。</p>
<p>由于在 ES 集群中每个节点通过上面的计算公式都知道集群中的文档的存放位置，所以每个节点都有处理读写请求的能力。</p>
<p>在一个写请求被发送到某个节点后，该节点即为前面说过的协调节点，协调节点会根据路由公式计算出需要写到哪个分片上，再将请求转发到该分片的主分片节点上。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1104-FD6fKO.jpeg" alt="图片"></p>
<p>假如此时数据通过路由计算公式取余后得到的值是 <code>shard=hash(routing)%4=0</code>。</p>
<p>则具体流程如下：</p>
<blockquote>
<ul>
<li>客户端向 ES1 节点（协调节点）发送写请求，通过路由计算公式得到值为 0，则当前数据应被写到主分片 S0 上。</li>
<li>ES1 节点将请求转发到 S0 主分片所在的节点 ES3，ES3 接受请求并写入到磁盘。</li>
<li>并发将数据复制到两个副本分片 R0 上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点 ES3 将向协调节点报告成功，协调节点向客户端报告成功。</li>
</ul>
</blockquote>
<h3 id="存储原理"><a href="#存储原理" class="headerlink" title="存储原理"></a>存储原理</h3><p>上面介绍了在 ES 内部索引的写处理流程，这个流程是在 ES 的内存中执行的，数据被分配到特定的分片和副本上之后，最终是存储到磁盘上的，这样在断电的时候就不会丢失数据。</p>
<p>具体的存储路径可在配置文件 <code>../config/elasticsearch.yml</code>中进行设置，默认存储在安装目录的 Data 文件夹下。</p>
<p>建议不要使用默认值，因为若 ES 进行了升级，则有可能导致数据全部丢失：</p>
<figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">path</span>.<span class="keyword">data</span>: /<span class="built_in">path</span>/to/<span class="keyword">data</span>  <span class="comment">//索引数据  </span></span><br><span class="line"><span class="built_in">path</span>.logs: /<span class="built_in">path</span>/to/logs  <span class="comment">//日志记录  </span></span><br></pre></td></tr></table></figure>
<h4 id="①分段存储"><a href="#①分段存储" class="headerlink" title="①分段存储"></a>①分段存储</h4><p>索引文档以段的形式存储在磁盘上，何为段？索引文件被拆分为多个子文件，则每个子文件叫作段，每一个段本身都是一个倒排索引，并且段具有不变性，一旦索引的数据被写入硬盘，就不可再修改。</p>
<p>在底层采用了分段的存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。</p>
<p>段被写入到磁盘后会生成一个提交点，提交点是一个用来记录所有提交后段信息的文件。</p>
<p>一个段一旦拥有了提交点，就说明这个段只有读的权限，失去了写的权限。相反，当段在内存中时，就只有写的权限，而不具备读数据的权限，意味着不能被检索。</p>
<p>段的概念提出主要是因为：在早期全文检索中为整个文档集合建立了一个很大的倒排索引，并将其写入磁盘中。</p>
<p>如果索引有更新，就需要重新全量创建一个索引来替换原来的索引。这种方式在数据量很大时效率很低，并且由于创建一次索引的成本很高，所以对数据的更新不能过于频繁，也就不能保证时效性。</p>
<p>索引文件分段存储并且不可修改，那么新增、更新和删除如何处理呢？</p>
<blockquote>
<ul>
<li>新增，新增很好处理，由于数据是新的，所以只需要对当前文档新增一个段就可以了。</li>
<li>删除，由于不可修改，所以对于删除操作，不会把文档从旧的段中移除而是通过新增一个 .del 文件，文件中会列出这些被删除文档的段信息。这个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。</li>
<li>更新，不能修改旧的段来进行反映文档的更新，其实更新相当于是删除和新增这两个动作组成。会将旧的文档在 .del 文件中标记删除，然后文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就会被移除。</li>
</ul>
</blockquote>
<p>段被设定为不可修改具有一定的优势也有一定的缺点，优势主要表现在：</p>
<blockquote>
<ul>
<li>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。</li>
<li>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</li>
<li>其它缓存(像 Filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</li>
<li>写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和需要被缓存到内存的索引的使用量。</li>
</ul>
</blockquote>
<p>段的不变性的缺点如下：</p>
<blockquote>
<ul>
<li>当对旧数据进行删除时，旧数据不会马上被删除，而是在 .del 文件中被标记为删除。而旧数据只能等到段更新时才能被移除，这样会造成大量的空间浪费。</li>
<li>若有一条数据频繁的更新，每次更新都是新增新的标记旧的，则会有大量的空间浪费。</li>
<li>每次新增数据时都需要新增一个段来存储数据。当段的数量太多时，对服务器的资源例如文件句柄的消耗会非常大。</li>
<li>在查询的结果中包含所有的结果集，需要排除被标记删除的旧数据，这增加了查询的负担。</li>
</ul>
</blockquote>
<h4 id="②延迟写策略"><a href="#②延迟写策略" class="headerlink" title="②延迟写策略"></a>②延迟写策略</h4><p>介绍完了存储的形式，那么索引写入到磁盘的过程是怎样的？是否是直接调 Fsync 物理性地写入磁盘？</p>
<p>答案是显而易见的，如果是直接写入到磁盘上，磁盘的 I/O 消耗上会严重影响性能。</p>
<p>那么当写数据量大的时候会造成 ES 停顿卡死，查询也无法做到快速响应。如果真是这样 ES 也就不会称之为近实时全文搜索引擎了。</p>
<p>为了提升写的性能，ES 并没有每新增一条数据就增加一个段到磁盘上，而是采用延迟写的策略。</p>
<p>每当有新增的数据时，就将其先写入到内存中，在内存和磁盘之间是文件系统缓存。</p>
<p>当达到默认的时间（1 秒钟）或者内存的数据达到一定量时，会触发一次刷新（Refresh），将内存中的数据生成到一个新的段上并缓存到文件缓存系统 上，稍后再被刷新到磁盘中并生成提交点。</p>
<p>这里的内存使用的是 ES 的 JVM 内存，而文件缓存系统使用的是操作系统的内存。</p>
<p>新的数据会继续的被写入内存，但内存中的数据并不是以段的形式存储的，因此不能提供检索功能。</p>
<p>由内存刷新到文件缓存系统的时候会生成新的段，并将段打开以供搜索使用，而不需要等到被刷新到磁盘。</p>
<p>在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 Refresh （即内存刷新到文件缓存系统）。</p>
<p>默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索，因为文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。</p>
<p>我们也可以手动触发 Refresh，<code>POST /_refresh</code> 刷新所有索引，<code>POST /nba/_refresh</code> 刷新指定的索引。</p>
<p>Tips：尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候， 手动刷新很有用，但是不要在生产&gt;环境下每次索引一个文档都去手动刷新。而且并不是所有的情况都需要每秒刷新。</p>
<p>可能你正在使用 Elasticsearch 索引大量的日志文件， 你可能想优化索引速度而不是&gt;近实时搜索。</p>
<p>这时可以在创建索引时在 Settings 中通过调大 <code>refresh_interval = &quot;30s&quot;</code>的值 ， 降低每个索引的刷新频率，设值时需要注意后面带上时间单位，否则默认是毫秒。当 <code>refresh_interval=-1</code> 时表示关闭索引的自动刷新。</p>
<p>虽然通过延时写的策略可以减少数据往磁盘上写的次数提升了整体的写入能力，但是我们知道文件缓存系统也是内存空间，属于操作系统的内存，只要是内存都存在断电或异常情况下丢失数据的危险。</p>
<p>为了避免丢失数据，Elasticsearch 添加了事务日志（Translog），事务日志记录了所有还没有持久化到磁盘的数据。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1105-gr8og8.jpeg" alt="图片"></p>
<p>添加了事务日志后整个写索引的流程如上图所示：</p>
<blockquote>
<ul>
<li><p>一个新文档被索引之后，先被写入到内存中，但是为了防止数据的丢失，会追加一份数据到事务日志中。</p>
<p>不断有新的文档被写入到内存，同时也都会记录到事务日志中。这时新数据还不能被检索和查询。</p>
</li>
<li><p>当达到默认的刷新时间或内存中的数据达到一定量后，会触发一次  Refresh，将内存中的数据以一个新段形式刷新到文件缓存系统中并清空内存。这时虽然新段未被提交到磁盘，但是可以提供文档的检索功能且不能被修改。</p>
</li>
<li><p>随着新文档索引不断被写入，当日志数据大小超过 512M 或者时间超过 30 分钟时，会触发一次 Flush。</p>
<p>内存中的数据被写入到一个新段同时被写入到文件缓存系统，文件系统缓存中数据通过 Fsync 刷新到磁盘中，生成提交点，日志文件被删除，创建一个空的新日志。</p>
</li>
</ul>
</blockquote>
<p>通过这种方式当断电或需要重启时，ES 不仅要根据提交点去加载已经持久化过的段，还需要工具 Translog 里的记录，把未持久化的数据重新持久化到磁盘上，避免了数据丢失的可能。</p>
<p>③段合并</p>
<p>由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。</p>
<p>每一个段都会消耗文件句柄、内存和 CPU 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段然后合并查询结果，所以段越多，搜索也就越慢。</p>
<p>Elasticsearch 通过在后台定期进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p>
<p>段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档不会被拷贝到新的大段中。合并的过程中不会中断索引和搜索。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1105-VeGjfe.png" alt="图片">图片</p>
<p>段合并在进行索引和搜索时会自动进行，合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中，这些段既可以是未提交的也可以是已提交的。</p>
<p>合并结束后老的段会被删除，新的段被 Flush 到磁盘，同时写入一个包含新段且排除旧的和较小的段的新提交点，新的段被打开可以用来搜索。</p>
<p>段合并的计算量庞大， 而且还要吃掉大量磁盘 I/O，段合并会拖累写入速率，如果任其发展会影响搜索性能。</p>
<p>Elasticsearch 在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。</p>
<h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><h3 id="存储设备"><a href="#存储设备" class="headerlink" title="存储设备"></a>存储设备</h3><p>磁盘在现代服务器上通常都是瓶颈。Elasticsearch 重度使用磁盘，你的磁盘能处理的吞吐量越大，你的节点就越稳定。</p>
<p>这里有一些优化磁盘 I/O 的技巧：</p>
<blockquote>
<ul>
<li>使用 SSD。就像其他地方提过的， 他们比机械磁盘优秀多了。</li>
<li>使用 RAID 0。条带化 RAID 会提高磁盘 I/O，代价显然就是当一块硬盘故障时整个就故障了。不要使用镜像或者奇偶校验 RAID 因为副本已经提供了这个功能。</li>
<li>另外，使用多块硬盘，并允许 Elasticsearch 通过多个 path.data 目录配置把数据条带化分配到它们上面。</li>
<li>不要使用远程挂载的存储，比如 NFS 或者 SMB/CIFS。这个引入的延迟对性能来说完全是背道而驰的。</li>
<li>如果你用的是 EC2，当心 EBS。即便是基于 SSD 的 EBS，通常也比本地实例的存储要慢。</li>
</ul>
</blockquote>
<h3 id="内部索引优化"><a href="#内部索引优化" class="headerlink" title="内部索引优化"></a>内部索引优化</h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1106-4LKvYu.jpeg" alt="图片">图片</p>
<p>Elasticsearch 为了能快速找到某个 Term，先将所有的 Term 排个序，然后根据二分法查找 Term，时间复杂度为 logN，就像通过字典查找一样，这就是 Term Dictionary。</p>
<p>现在再看起来，似乎和传统数据库通过 B-Tree 的方式类似。但是如果 Term 太多，Term Dictionary 也会很大，放内存不现实，于是有了 Term Index。</p>
<p>就像字典里的索引页一样，A 开头的有哪些 Term，分别在哪页，可以理解 Term Index是一棵树。</p>
<p>这棵树不会包含所有的 Term，它包含的是 Term 的一些前缀。通过 Term Index 可以快速地定位到 Term Dictionary 的某个 Offset，然后从这个位置再往后顺序查找。</p>
<p>在内存中用 FST 方式压缩 Term Index，FST 以字节的方式存储所有的 Term，这种压缩方式可以有效的缩减存储空间，使得 Term Index 足以放进内存，但这种方式也会导致查找时需要更多的 CPU 资源。</p>
<p>对于存储在磁盘上的倒排表同样也采用了压缩技术减少存储所占用的空间。</p>
<h3 id="调整配置参数"><a href="#调整配置参数" class="headerlink" title="调整配置参数"></a>调整配置参数</h3><p>调整配置参数建议如下：</p>
<blockquote>
<ul>
<li><p>给每个文档指定有序的具有压缩良好的序列模式 ID，避免随机的 UUID-4 这样的 ID，这样的 ID 压缩比很低，会明显拖慢 Lucene。</p>
</li>
<li><p>对于那些不需要聚合和排序的索引字段禁用 Doc values。Doc Values 是有序的基于 <code>document=&gt;field value</code> 的映射列表。</p>
</li>
<li><p>不需要做模糊检索的字段使用 Keyword 类型代替 Text 类型，这样可以避免在建立索引前对这些文本进行分词。</p>
</li>
<li><p>如果你的搜索结果不需要近实时的准确度，考虑把每个索引的 <code>index.refresh_interval</code> 改到 30s 。</p>
<p>如果你是在做大批量导入，导入期间你可以通过设置这个值为 -1 关掉刷新，还可以通过设置 <code>index.number_of_replicas: 0</code> 关闭副本。别忘记在完工的时候重新开启它。</p>
</li>
<li><p>避免深度分页查询建议使用 Scroll 进行分页查询。普通分页查询时，会创建一个 <code>from+size</code> 的空优先队列，每个分片会返回 <code>from+size</code> 条数据，默认只包含文档 ID 和得分 Score 给协调节点。</p>
<p>如果有 N 个分片，则协调节点再对（from+size）×n 条数据进行二次排序，然后选择需要被取回的文档。当 from 很大时，排序过程会变得很沉重，占用 CPU 资源严重。</p>
</li>
<li><p>减少映射字段，只提供需要检索，聚合或排序的字段。其他字段可存在其他存储设备上，例如 Hbase，在 ES 中得到结果后再去 Hbase 查询这些字段。</p>
</li>
<li><p>创建索引和查询时指定路由 Routing 值，这样可以精确到具体的分片查询，提升查询效率。路由的选择需要注意数据的分布均衡。</p>
</li>
</ul>
</blockquote>
<h3 id="JVM-调优"><a href="#JVM-调优" class="headerlink" title="JVM 调优"></a>JVM 调优</h3><p>JVM 调优建议如下：</p>
<blockquote>
<ul>
<li>确保堆内存最小值（ Xms ）与最大值（ Xmx ）的大小是相同的，防止程序在运行时改变堆内存大小。Elasticsearch 默认安装后设置的堆内存是 1GB。可通过<code>../config/jvm.option</code> 文件进行配置，但是最好不要超过物理内存的50%和超过 32GB。</li>
<li>GC 默认采用 CMS 的方式，并发但是有 STW 的问题，可以考虑使用 G1 收集器。</li>
<li>ES 非常依赖文件系统缓存（Filesystem Cache），快速搜索。一般来说，应该至少确保物理上有一半的可用内存分配到文件系统缓存。</li>
</ul>
</blockquote>
<hr>
<blockquote>
<p>备份链接：<a href="https://xuemingde.com/JavaNotes/中间件-搜索/20220411-彻底讲透Elasticsearch">20220411-彻底讲透Elasticsearch</a>  </p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/2P9AR21.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/2P9AR21.html" class="post-title-link" itemprop="url">Kafka面试连环炮-下</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-10 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-10T00:00:00+08:00">2022-04-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" itemprop="url" rel="index"><span itemprop="name">消息队列</span></a>
                </span>
            </span>

          
            <span id="/posts/2P9AR21.html" class="post-meta-item leancloud_visitors" data-flag-title="Kafka面试连环炮-下" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/2P9AR21.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/2P9AR21.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvSGtzUXRsaFlHMmhSSE1LRDg1a3Rudw==">【建议收藏】Kafka 面试连环炮, 看看你能撑到哪一步?（下）<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<p>我们知道 Kafka 网络通信架构使用到了 Java NIO 以及 Reactor 设计模式。我们先从整体上看一下完整的网络通信层架构，如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/0957-7aENgd.png" alt="图片"></p>
<blockquote>
<p>1）从上图中我们可以看出，Kafka 网络通信架构中用到的组件主要由两大部分构成：<code>SocketServer 和 RequestHandlerPool</code>。</p>
<p>2）<code>SocketServer 组件是 Kafka 超高并发网络通信层中最重要的子模块</code>。它包含 Acceptor 线程、Processor 线程和 RequestChannel 等对象，都是网络通信的重要组成部分。</p>
<p>3）<strong>RequestHandlerPool 组件</strong>就是我们常说的 I/O 工作线程池，里面定义了若干个 I/O 线程，<code>主要用来执行真实的请求处理逻辑</code>。</p>
</blockquote>
<h3 id="Accept-线程"><a href="#Accept-线程" class="headerlink" title="Accept 线程"></a>Accept 线程</h3><p>在经典的 Reactor 设计模式有个「<strong>Dispatcher</strong>」的角色，<code>主要用来接收外部请求并分发给下面的实际处理线程</code>。在 Kafka 网络架构设计中，这个 Dispatcher 就是「<strong>Acceptor 线程</strong>」, 用来接收和创建外部 TCP 连接的线程。在 Broker 端每个 SocketServer 实例只会创建一个 Acceptor 线程。<code>它的主要功能就是创建连接，并将接收到的 Request 请求传递给下游的 Processor 线程处理</code>。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/0958-SHDgkB.png" alt="图片"></p>
<blockquote>
<p>1）我们可以看出 Acceptor 线程主要使用了 Java NIO 的 Selector 以及 SocketChannel 的方式循环的轮询准备就绪的 I/O 事件。</p>
<p>2）将 ServerSocketChannel 通道注册到nioSelector 上，并关注网络连接创事件：SelectionKey.OP_ACCEPT。</p>
<p>3）事件注册好后，一旦后续接收到连接请求后，Acceptor 线程就会指定一个 Processor 线程，并将该请求交给它并创建网络连接用于后续处理。</p>
</blockquote>
<h3 id="Processor-线程"><a href="#Processor-线程" class="headerlink" title="Processor 线程"></a>Processor 线程</h3><p>Acceptor 只是做了请求入口连接处理的，那么，<code>真正创建网络连接以及分发网络请求是由 Processor 线程来完成的</code>。而每个 Processor 线程在创建时都会创建 3 个队列。</p>
<blockquote>
<p>1）<strong>newConnections 队列:</strong> 它主要是用来保存要创建的新连接信息，也就是SocketChannel 对象，<strong>目前是硬编码队列长度大小为20</strong>。每当 Processor 线程接收到新的连接请求时，都会将对应的 SocketChannel 对象放入队列，等到后面创建连接时，从该队列中获取 SocketChannel，然后注册新的连接。</p>
<p>2）<strong>inflightResponse 队列：</strong>它是一个临时的 Response 队列，当 Processor 线程将 Repsonse 返回给 Client 之后，要将 Response 放入该队列。它存在的意义：<code>由于有些 Response 回调逻辑要在 Response 被发送回 Request 发送方后，才能执行，因此需要暂存到临时队列</code>。</p>
<p>3）<strong>ResponseQueue 队列：</strong>它主要是存放需要返回给Request 发送方的所有 Response 对象。每个 Processor 线程都会维护自己的 Response 队列。</p>
</blockquote>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1000-Vza3z2.png" alt="图片"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1000-x5A3wg.png" alt="图片"></p>
<h3 id="RequestHandlerPool-线程池"><a href="#RequestHandlerPool-线程池" class="headerlink" title="RequestHandlerPool 线程池"></a>RequestHandlerPool 线程池</h3><p>Acceptor 线程和 Processor 线程只是请求和响应的「<strong>搬运工</strong>」，而「<strong>真正处理 Kafka 请求</strong>」是 <code>KafkaRequestHandlerPool</code> 线程池，在上面网络超高并发通信架构图，有两个参数跟整个流程有关系，分别是「<code>num.network.threads</code>」、「<code>num.io.threads</code>」。其中 num.io.threads 就是 I/O 工作线程池的大小配置。</p>
<p>​        <img data-src="https://xuemingde.com/pages/image/2022/04/10/1001-NqZsqB.png" alt="图片"></p>
<p>下面我们结合 Kafka 超高并发网络架构图来讲解下一个完整请求处理核心流程：</p>
<blockquote>
<p>1）Clients 发送请求给 Acceptor 线程。</p>
<p>2）Acceptor 线程会创建 NIO Selector 对象，并创建 ServerSocketChannel 通道实例，然后将 Channel 和 OP_ACCEPT 事件绑定到 Selector 多路复用器上。</p>
<p>3）Acceptor 线程默认创建3个Processor 线程参数：num.network.threads, 并轮询的将请求对象 SocketChannel 放入到连接队列中。</p>
<p>4）这时候连接队列就源源不断有请求数据了，然后不停地执行 NIO Poll, 获取对应 SocketChannel 上已经准备就绪的 I/O 事件。</p>
<p>5）Processor 线程向 SocketChannel 注册了 OP_READ/OP_WRITE 事件，这样 客户端发过来的请求就会被该 SocketChannel 对象获取到，具体就是 processCompleteReceives 方法。</p>
<p>6）这个时候客户端就可以源源不断进行请求发送了，服务端通过 Selector NIO Poll 不停的获取准备就绪的 I/O 事件。</p>
<p>7）然后根据Channel中获取已经完成的 Receive 对象，构建 Request 对象，并将其存入到 Requestchannel 的 RequestQueue 请求队列中 。</p>
<p>8）这个时候就该 I/O 线程池上场了，KafkaRequestHandler 线程循环地从请求队列RequestQueue 中获取 Request 实例，然后交由KafkaApis 的 handle 方法，执行真正的请求处理逻辑，并最终将数据存储到磁盘中。</p>
<p>9）待处理完请求后，KafkaRequestHandler 线程会将 Response 对象放入 Processor 线程的 Response 队列。</p>
<p>10）然后 Processor 线程通过 Request 中的 ProcessorID 不停地从 Response 队列中来定位并取出 Response 对象，返还给 Request 发送方。</p>
</blockquote>
<h2 id="了解Kafka高吞吐日志存储架构是如何设计吗"><a href="#了解Kafka高吞吐日志存储架构是如何设计吗" class="headerlink" title="了解Kafka高吞吐日志存储架构是如何设计吗"></a>了解Kafka高吞吐日志存储架构是如何设计吗</h2><p>对于 Kafka 来说， 它主要用来处理海量数据流，这个场景的特点主要包括：</p>
<blockquote>
<p>1) <strong>写操作：</strong>写并发要求非常高，基本得达到百万级 TPS，顺序追加写日志即可，无需考虑更新操作。</p>
<ol>
<li><strong>读操作：</strong>相对写操作来说，比较简单，只要能按照一定规则高效查询即可,支持（offset或者时间戳）读取。</li>
</ol>
</blockquote>
<p>根据上面两点分析，对于写操作来说，直接采用「<strong>顺序追加写日志</strong>」的方式就可以满足 Kafka 对于百万TPS写入效率要求。</p>
<p>如何解决高效查询这些日志呢？我们可以设想把消息的 Offset 设计成一个有序的字段，这样消息在日志文件中也就有序存放了，也不需要<strong>额外引入哈希表结构</strong>，可以直接将消息划分成若干个块，<code>对于每个块我们只需要索引当前块的第一条消息的 Offset ，这个是不是有点二分查找算法的意思</code>。即先根据 Offset 大小找到对应的块， 然后再从块中顺序查找。如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1003-2UplC7.png" alt="图片"></p>
<p>这样就可以快速定位到要查找的消息的位置了，在 Kafka 中，我们将这种索引结构叫做「<strong>稀疏哈希索引</strong>」。</p>
<p>上面得出了 Kafka 最终的存储实现方案， 即<code>基于顺序追加写日志 + 稀疏哈希索引</code>。</p>
<p>接下来我们来看看 Kafka 日志存储结构：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1004-DqnnDS.png" alt="图片"></p>
<p>从上图看出来，Kafka 是基于「<code>主题 + 分区 + 副本 + 分段 + 索引</code>」的结构进行日志存储的。</p>
<p>了解了整体的日志存储架构，我们来看下 Kafka 日志格式，Kafka 日志格式也经历了多个版本迭代，这里我们主要看下V2版本的日志格式：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1004-2KZQhv.png" alt="图片"></p>
<p>通过上图可以得出：<code>V2 版本日志格式主要是通过可变长度提高了消息格式的空间使用率</code>，并将某些字段抽取到消息批次（RecordBatch）中，同时消息批次可以存放多条消息，从而在批量发送消息时，可以大幅度地节省了磁盘空间。</p>
<p>接下来我们来看看日志消息写入磁盘的整体过程如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1005-Tad6Ll.png" alt="图片"></p>
<h2 id="针对-Kafka-线上集群部署方案-你是怎么做的"><a href="#针对-Kafka-线上集群部署方案-你是怎么做的" class="headerlink" title="针对 Kafka 线上集群部署方案, 你是怎么做的"></a>针对 Kafka 线上集群部署方案, 你是怎么做的</h2><p>这里我们从架构师必备能力出发， 以电商平台为例讲述了 Kafka 生产级容量评估方案该如何做？如何让公司领导以及运维部门得到认可， 获准你的方案。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1005-ikMfte.png" alt="图片"></p>
<p>详细可以深读：<a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;mid=2247488846&amp;idx=1&amp;sn=1d77a05c7e94abd8044502c433d9aeee&amp;chksm=cefb3c7ff98cb569910c99de953ecce956a454a3d8e63be9e3a2b7639f633848ba4bb989bb87&amp;scene=21#wechat_redirect"><strong>八大步骤带你深度剖析Kafka生产级容量评估方案</strong></a></p>
<h2 id="针对-Kafka-线上系统-你是如何进行监控的"><a href="#针对-Kafka-线上系统-你是如何进行监控的" class="headerlink" title="针对 Kafka 线上系统, 你是如何进行监控的"></a>针对 Kafka 线上系统, 你是如何进行监控的</h2><p>Kafka 作为大型系统架构中重要的一环，有着举足轻重的作用，因此 Kafka 集群的稳定性尤为重要，我们要对生产的 Kafka 集群进行全方位的监控， 一般线上系统可以从以下五个维度进行监控：</p>
<h3 id="主机节点监控"><a href="#主机节点监控" class="headerlink" title="主机节点监控"></a>主机节点监控</h3><p>所谓主机节点监控就是监控 Kafka 集群 Broker 所在节点机器的性能。主机节点监控对于 Kafka 来说是最重要的，因为很多线上环境问题首先就是由于主机的某些性能出现了问题。</p>
<p>因此对于 Kafka 来说，主机监控通常是发现问题的第一步，主要性能指标如下：</p>
<p>「<strong>机器负载（Load）</strong>」、「<strong>CPU 使用率</strong>」、「<strong>内存使用率</strong>」、「<strong>磁盘 I/O 使用率</strong>」、「<strong>网络 I/O 使用率</strong>」、「<strong>TCP 连接数</strong>」、「<strong>打开文件数</strong>」、「<strong>inode 使用情况</strong>」。</p>
<p>如果想要更好的监控主机性能的话，有以下两个教程可以学习和参考：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1006-p36iiv.png" alt="图片"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1006-X46ebB.png" alt="图片"></p>
<h3 id="JVM-监控"><a href="#JVM-监控" class="headerlink" title="JVM 监控"></a>JVM 监控</h3><p>另一个重要的监控维度就是 JVM 监控。<code>监控 JVM 进程主要是为了让你全面地了解Kafka Broker 进程</code>。</p>
<p>要监控 JVM 进程，需要关注 3 个指标：</p>
<p>「<code>监控 Full GC 发生频率和时长</code>」、「<code>监控堆上活跃对象大小</code>」、「<code>监控应用线程总数</code>」</p>
<h3 id="Kafka-集群监控"><a href="#Kafka-集群监控" class="headerlink" title="Kafka 集群监控"></a>Kafka 集群监控</h3><p>另外一个重要监控维度就是 Kafka Broker 集群和各类客户端的监控，主要有3个方法：</p>
<blockquote>
<p>1）<strong>查看 Broker 端重要日志：</strong>主要包括 Broker 端服务器日志 server.log，控制器日志 controller.log 以及主题分区状态变更日志  state-change.log。其中，server.log 是最重要的，如果你的 Kafka 集群出现了故障，你要第一时间查看  server.log，定位故障原因。</p>
<p>2）<strong>查看 Broker 端关键线程运行状态，例如:</strong> </p>
<p>Log Compaction 线程：日志压缩清理。一旦它挂掉了，所有 Compaction 操作都会中断，但用户对此通常是无感知的。</p>
<p>副本拉取消息的线程：主要执行 Follower 副本向 Leader 副本拉取消息的逻辑。如果它们挂掉了，系统会表现为 Follower 副本延迟 Leader 副本越来越大 。</p>
<p>3）<strong>查看 Broker 端关键的 JMX 性能指标:</strong> 主要有BytesIn/BytesOut、NetworkProcessorAvgIdlePercent、RequestHandlerAvgIdlePercent、UnderReplicatedPartitions、ISRShrink/ISRExpand、ActiveControllerCount 这几个指标 。</p>
</blockquote>
<h3 id="Kafka-客户端监控"><a href="#Kafka-客户端监控" class="headerlink" title="Kafka 客户端监控"></a>Kafka 客户端监控</h3><p>客户端监控主要是生产者和消费者的监控，生产者往 Kafka 发送消息，此时我们要了解客户端机器与 Broker 机器之间的往返时延 RTT 是多少，对于跨数据中心或者异地集群来说，RTT 会更大，很难支撑很大的 TPS。</p>
<p><strong>Producer角度:</strong> request-latency 是需要重点关注的JMX指标，即消息生产请求的延时；另外 Sender 线程的运行状态也是非常重要的， 如果 Sender 线程挂了，对于用户是无感知的，表象只是 Producer 端消息发送失败。</p>
<p><strong>Consumer角度:</strong> 对于 Consumer Group，需要重点关注 join rate 和 sync rate 指标，它表示 Rebalance 的频繁程度。另外还包括消息消费偏移量、消息堆积数量等。</p>
<h3 id="Broker-之间的监控"><a href="#Broker-之间的监控" class="headerlink" title="Broker 之间的监控"></a>Broker 之间的监控</h3><p>最后一个监控维度就是 Broker 之间的监控，主要指副本拉取的性能。Follower 副本实时拉取 Leader 副本的数据，此时我们希望拉取过程越快越好。Kafka 提供了一个特别重要的 JMX 指标，叫做「<code>under replicated partitions</code>」，意思就是比如我们规定这条消息，应该在两个 Broker 上面保存，假设只有一个 Broker 上保存该消息，那么这条消息所在的分区就叫 under replicated partitions，这种情况是特别关注的，因为有可能造成数据的丢失。</p>
<p>另外还有一个比较重要的指标是「<code>active controllor count</code>」。在整个 Kafka  集群中应该确保只能有一台机器的指标是1，其他全应该是0，如果发现有一台机器大于1，一定是出现脑裂了，此时应该去检查下是否出现了网络分区。Kafka本身是不能对抗脑裂的，完全依靠 Zookeeper 来做，但是如果真正出现网络分区的话，也是没有办法处理的，应该让其快速失败重启。</p>
<h2 id="针对-Kafka-线上系统-你是如何进行调优的"><a href="#针对-Kafka-线上系统-你是如何进行调优的" class="headerlink" title="针对 Kafka 线上系统, 你是如何进行调优的"></a>针对 Kafka 线上系统, 你是如何进行调优的</h2><p>对 Kafka 来说，「<strong>吞吐量</strong>」和「<strong>延时</strong>」是非常重要的优化指标。</p>
<p><strong>吞吐量 TPS：</strong>是指 Broker 端或 Client 端每秒能处理的消息数，越大越好。</p>
<p><strong>延时：</strong>表示从 Producer 端发送消息到 Broker 端持久化完成到 Consumer 端成功消费之间的时间间隔。与吞吐量 TPS 相反，延时越短越好。</p>
<p>总之，<code>高吞吐量、低延时是我们调优 Kafka 集群的主要目标</code>。</p>
<h3 id="提升吞吐量"><a href="#提升吞吐量" class="headerlink" title="提升吞吐量"></a>提升吞吐量</h3><p>首先是提升吞吐量参数和措施：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1011-xiyY76.png" alt="image-20220410101150338"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1012-TlxxM5.png" alt="image-20220410101218929"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/10/1012-nCB2xr.png" alt="image-20220410101239687"></p>
<h3 id="降低延时"><a href="#降低延时" class="headerlink" title="降低延时"></a>降低延时</h3><p>降低延时的目的就是尽量减少端到端的延时。</p>
<p>对比上面提升吞吐量的参数，我们只能调整 Producer 端和 Consumer 端的参数配置。</p>
<p>对于 Producer 端，此时我们希望可以快速的将消息发送出去，必须设置 linger.ms=0，同时关闭压缩，另外设置 acks = 1，减少副本同步时间。</p>
<p>而对于 Consumer 端我们只保持 fetch.min.bytes=1 ，即 Broker 端只要有能返回的数据，就立即返回给 Consumer，减少延时。</p>
<h3 id="合理设置分区数"><a href="#合理设置分区数" class="headerlink" title="合理设置分区数"></a>合理设置分区数</h3><p>分区数不是越多越好，也不是越少越好，需要搭建完集群，进行压测，再灵活调整分区个数。 </p>
<p>这里可以用 Kafka 官方自带的脚本，对 Kafka 进行压测。</p>
<blockquote>
<p><strong>1）生产者压测：</strong>kafka-producer-perf-test.sh</p>
<p><strong>2）消费者压测：</strong>kafka-consumer-perf-test.sh </p>
</blockquote>
<hr>
<blockquote>
<p>备份链接：<a href="https://xuemingde.com/JavaNotes/消息队列/20220410-Kafka面试连环炮-下">20220410-Kafka面试连环炮-下</a>   </p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/12P0DCH.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/12P0DCH.html" class="post-title-link" itemprop="url">RocketMQ 消息积压了，增加消费者有用吗</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-10 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-10T00:00:00+08:00">2022-04-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" itemprop="url" rel="index"><span itemprop="name">消息队列</span></a>
                </span>
            </span>

          
            <span id="/posts/12P0DCH.html" class="post-meta-item leancloud_visitors" data-flag-title="RocketMQ 消息积压了，增加消费者有用吗" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/12P0DCH.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/12P0DCH.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>面试官</strong>：RocketMQ 消息积压了，增加消费者有用吗？</p>
<p><strong>我</strong>：这个要看具体的场景，不同的场景下情况是不一样的。</p>
<p><strong>面试官</strong>：可以详细说一下吗？</p>
<p><strong>我</strong>：如果消费者的数量小于 MessageQueue 的数量，增加消费者可以加快消息消费速度，减少消息积压。比如一个 Topic 有 4 个 MessageQueue，2 个消费者进行消费，如果增加一个消费者，明细可以加快拉取消息的频率。如下图：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/11/1057-EAQoGV.png" alt="图片"></p>
<p>如果消费者的数量大于等于 MessageQueue 的数量，增加消费者是没有用的。比如一个 Topic 有 4 个 MessageQueue，并且有 4 个消费者进行消费。如下图</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/11/1057-Uu40Ny.png" alt="图片"></p>
<p><strong>面试官</strong>：你说的第一种情况，增加消费者一定能加快消息消费的速度吗？</p>
<p><strong>我</strong>：这…，一般情况下是可以的。</p>
<p><strong>面试官</strong>：有特殊的情况吗？</p>
<p><strong>我</strong>：当然有。消费者消息拉取的速度也取决于本地消息的消费速度，如果本地消息消费的慢，就会延迟一段时间后再去拉取。</p>
<p><strong>面试官</strong>：在什么情况下消费者会延迟一段时间后后再去拉取呢？</p>
<p><strong>我</strong>：消费者拉取的消息存在 ProcessQueue，消费者是有流量控制的，如果出现下面三种情况，就不会主动去拉取：</p>
<ul>
<li>ProcessQueue 保存的消息数量超过阈值（默认 1000，可以配置）；</li>
<li>ProcessQueue 保存的消息大小超过阈值（默认 100M，可以配置）；</li>
<li>对于非顺序消费的场景，ProcessQueue 中保存的最后一条和第一条消息偏移量之差超过阈值（默认 2000，可以配置）。</li>
</ul>
<blockquote>
<p>这部分源码请参考类：<code>org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl</code>。</p>
</blockquote>
<p><strong>面试官</strong>：还有其他情况吗？</p>
<p><strong>我</strong>：对于顺序消费的场景，ProcessQueue 加锁失败，也会延迟拉取，这个延迟时间是 3s。消费者消费慢，可是能下面的原因：</p>
<ul>
<li>消费者处理的业务逻辑复杂，耗时很长；</li>
<li>消费者有慢查询，或者数据库负载高导致响应慢；</li>
<li>缓存等中间件响应慢，比如 Redis 响应慢；</li>
<li>调用外部服务接口响应慢。</li>
</ul>
<p><strong>面试官</strong>：对于外部接口响应慢的情况，有什么应对措施吗？</p>
<p><strong>我</strong>：这个要分情况讨论。</p>
<p>如果调用外部系统<code>只是一个通知，或者调用外部接口的结果并不处理</code>，可以采用异步的方式，异步逻辑里采用重试的方式保证接口调成功。</p>
<p>如果外部接口返回结果必须要处理，可以考虑接口返回的结果是否可以缓存默认值（要考虑业务可行），在调用失败后采用快速降级的方式，使用默认值替代返回接口返回值。</p>
<p>如果这个接口返回结果必须要处理，并且不能缓存，可以把拉取到的消息存入本地然后给 Broker 直接返回 CONSUME_SUCCESS。等外部系统恢复正常后再从本地取出来进行处理。</p>
<p><strong>面试官</strong>：如果消费者数小于 MessageQueue 数量，并且外部系统响应正常，为了快速消费积压消息而增加消费者，有什么需要考虑的吗？</p>
<p><strong>我</strong>：外部系统虽然响应正常，但是增加多个消费者后，外部系统的接口调用量会突增，如果达到吞吐量上限，外部系统会响应变慢，甚至被打挂。</p>
<p>同时也要考虑本地数据库、缓存的压力，如果数据库响应变慢，处理消息的速度就会变慢，起不到缓解消息积压的作用。</p>
<p><strong>面试官</strong>：新增加了消费者后，怎么给它分配 MessageQueue 呢？</p>
<p><strong>我</strong>：Consumer 在拉取消息之前，需要对 MessageQueue 进行负载操作。RocketMQ 使用一个定时器来完成负载操作，默认每间隔 20s 重新负载一次。</p>
<p><strong>面试官</strong>：能详细说一下都有哪些负载策略吗？</p>
<p><strong>我</strong>：RocketMQ 提供了 6 种负载策略，依次来看一下。</p>
<p><strong>平均负载策略：</strong></p>
<ol>
<li>把消费者进行排序；</li>
<li>计算每个消费者可以平均分配的 MessageQueue 数量；</li>
<li>如果消费者数量大于 MessageQueue 数量，多出的消费者就分不到；</li>
<li>如果不可以平分，就使用 MessageQueue 总数量对消费者数量求余数 mod；</li>
<li>对前 mod 数量消费者，每个消费者加一个，这样就获取到了每个消费者分配的 MessageQueue 数量。</li>
</ol>
<p>比如 4 个 MessageQueue 和 3 个消费者的情况：</p>
<p><strong>面试官</strong>：消费者延迟拉取消息，一般可能是什么原因导致的呢？</p>
<p><strong>我</strong>：其实延迟拉取的<code>本质就是消费者消费慢</code>，导致下次去拉取的时候 ProcessQueue 中积压的消息超过阈值。以下面这张架构图为例：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/11/1059-yKOaQS.png" alt="图片"></p>
<p>消费者消费慢，可是能下面的原因：</p>
<ul>
<li>消费者处理的业务逻辑复杂，耗时很长；</li>
<li>消费者有慢查询，或者数据库负载高导致响应慢；</li>
<li>缓存等中间件响应慢，比如 Redis 响应慢；</li>
<li>调用外部服务接口响应慢。</li>
</ul>
<p><strong>面试官</strong>：对于外部接口响应慢的情况，有什么应对措施吗？</p>
<p><strong>我</strong>：这个要分情况讨论。</p>
<p>如果调用外部系统<strong>只是一个通知，或者调用外部接口的结果并不处理</strong>，可以采用异步的方式，异步逻辑里采用重试的方式保证接口调成功。</p>
<p>如果外部接口返回结果必须要处理，可以考虑接口返回的结果是否可以缓存默认值（要考虑业务可行），在调用失败后采用快速降级的方式，使用默认值替代返回接口返回值。</p>
<p>如果这个接口返回结果必须要处理，并且不能缓存，可以把拉取到的消息存入本地然后给 Broker 直接返回 CONSUME_SUCCESS。等外部系统恢复正常后再从本地取出来进行处理。</p>
<p><strong>面试官</strong>：如果消费者数小于 MessageQueue 数量，并且外部系统响应正常，为了快速消费积压消息而增加消费者，有什么需要考虑的吗？</p>
<p><strong>我</strong>：外部系统虽然响应正常，但是增加多个消费者后，外部系统的接口调用量会突增，如果达到吞吐量上限，外部系统会响应变慢，甚至被打挂。</p>
<p>同时也要考虑本地数据库、缓存的压力，如果数据库响应变慢，处理消息的速度就会变慢，起不到缓解消息积压的作用。</p>
<p><strong>面试官</strong>：新增加了消费者后，怎么给它分配 MessageQueue 呢？</p>
<p><strong>我</strong>：Consumer 在拉取消息之前，需要对 MessageQueue 进行负载操作。RocketMQ 使用一个定时器来完成负载操作，默认每间隔 20s 重新负载一次。</p>
<p><strong>面试官</strong>：能详细说一下都有哪些负载策略吗？</p>
<p><strong>我</strong>：RocketMQ 提供了 6 种负载策略，依次来看一下。</p>
<p><strong>平均负载策略：</strong></p>
<ol>
<li>把消费者进行排序；</li>
<li>计算每个消费者可以平均分配的 MessageQueue 数量；</li>
<li>如果消费者数量大于 MessageQueue 数量，多出的消费者就分不到；</li>
<li>如果不可以平分，就使用 MessageQueue 总数量对消费者数量求余数 mod；</li>
<li>对前 mod 数量消费者，每个消费者加一个，这样就获取到了每个消费者分配的 MessageQueue 数量。</li>
</ol>
<p>比如 4 个 MessageQueue 和 3 个消费者的情况：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/11/1103-dHKsfY.png" alt="图片"></p>
<p>源代码的逻辑非常简单，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// AllocateMessageQueueAveragely 这个类</span></span><br><span class="line"><span class="comment">// 4 个 MessageQueue 和 3 个消费者的情况，假如第一个，index = 0</span></span><br><span class="line"><span class="keyword">int</span> index = cidAll.indexOf(currentCID);</span><br><span class="line"><span class="comment">// mod = 1</span></span><br><span class="line"><span class="keyword">int</span> mod = mqAll.size() % cidAll.size();</span><br><span class="line"><span class="comment">// averageSize = 2</span></span><br><span class="line"><span class="keyword">int</span> averageSize =</span><br><span class="line">    mqAll.size() &lt;= cidAll.size() ? <span class="number">1</span> : (mod &gt; <span class="number">0</span> &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size()</span><br><span class="line">                                         + <span class="number">1</span> : mqAll.size() / cidAll.size());</span><br><span class="line"><span class="comment">// startIndex = 0</span></span><br><span class="line"><span class="keyword">int</span> startIndex = (mod &gt; <span class="number">0</span> &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod;</span><br><span class="line"><span class="comment">// range = 2,所以第一个消费者分配到了2个</span></span><br><span class="line"><span class="keyword">int</span> range = Math.min(averageSize, mqAll.size() - startIndex);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; range; i++) &#123;</span><br><span class="line">    result.add(mqAll.get((startIndex + i) % mqAll.size()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>循环分配策略:</strong></p>
<p>这个很容易理解，遍历消费者，把 MessageQueue 分一个给遍历到的消费者，如果 MessageQueue 数量比消费者多，需要进行多次遍历，遍历次数等于  （MessageQueue 数量/消费者数量），还是以 4 个 MessageQueue 和 3 个消费者的情况，如下图：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/11/1103-4fvcvc.png" alt="图片"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//AllocateMessageQueueAveragelyByCircle 这个类</span></span><br><span class="line"><span class="comment">//4 个 MessageQueue 和 3 个消费者的情况，假如第一个，index = 0</span></span><br><span class="line"><span class="keyword">int</span> index = cidAll.indexOf(currentCID);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = index; i &lt; mqAll.size(); i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (i % cidAll.size() == index) &#123;</span><br><span class="line">        <span class="comment">//i == 0 或者 i == 3 都会走到这里</span></span><br><span class="line">        result.add(mqAll.get(i));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>自定义分配策略：</strong></p>
<p>这种策略在消费者启动的时候可以指定消费哪些 MessageQueue。可以参考下面代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">AllocateMessageQueueByConfig allocateMessageQueueByConfig = <span class="keyword">new</span> AllocateMessageQueueByConfig();</span><br><span class="line"><span class="comment">//绑定消费 messageQueue1</span></span><br><span class="line">allocateMessageQueueByConfig.setMessageQueueList(Arrays.asList(<span class="keyword">new</span> MessageQueue(<span class="string">&quot;messageQueue1&quot;</span>,<span class="string">&quot;broker1&quot;</span>,<span class="number">0</span>)));</span><br><span class="line">consumer.setAllocateMessageQueueStrategy(allocateMessageQueueByConfig);</span><br><span class="line">consumer.start();</span><br></pre></td></tr></table></figure>
<p><strong>按照机房分配策略：</strong></p>
<p>这种方式 Consumer 只消费指定机房的 MessageQueue，如下图：Consumer0、Consumer1、Consumer2 绑定 room1 和 room2 这两个机房，而 room3 这个机房没有消费者。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/11/1104-xQcBq5.png" alt="图片"></p>
<p>Consumer 启动的时候需要绑定机房名称。可以参考下面代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">AllocateMessageQueueByMachineRoom allocateMessageQueueByMachineRoom = <span class="keyword">new</span> AllocateMessageQueueByMachineRoom();</span><br><span class="line"><span class="comment">//绑定消费 room1 和 room2 这两个机房</span></span><br><span class="line">allocateMessageQueueByMachineRoom.setConsumeridcs(<span class="keyword">new</span> HashSet&lt;&gt;(Arrays.asList(<span class="string">&quot;room1&quot;</span>,<span class="string">&quot;room2&quot;</span>)));</span><br><span class="line">consumer.setAllocateMessageQueueStrategy(allocateMessageQueueByMachineRoom);</span><br><span class="line">consumer.start();</span><br></pre></td></tr></table></figure>
<p>这种策略 broker 的命名必须按照格式：机房名@brokerName，因为消费者分配队列的时候，首先按照机房名称过滤出所有的 MessageQueue，然后<code>再按照平均分配策略进行分配</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//AllocateMessageQueueByMachineRoom 这个类</span></span><br><span class="line">List&lt;MessageQueue&gt; premqAll = <span class="keyword">new</span> ArrayList&lt;MessageQueue&gt;();</span><br><span class="line"><span class="keyword">for</span> (MessageQueue mq : mqAll) &#123;</span><br><span class="line">    String[] temp = mq.getBrokerName().split(<span class="string">&quot;@&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (temp.length == <span class="number">2</span> &amp;&amp; consumeridcs.contains(temp[<span class="number">0</span>])) &#123;</span><br><span class="line">        premqAll.add(mq);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//上面按照机房名称过滤出所有的 MessageQueue 放入premqAll，后面就是平均分配策略</span></span><br></pre></td></tr></table></figure>
<p><strong>按照机房就近分配：</strong></p>
<p>跟按照机房分配原则相比，就近分配的好处是可以对没有消费者的机房进行分配。如下图，机房 3 的 MessageQueue 也分配到了消费者：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/11/1105-GcF8UO.png" alt="图片"></p>
<p>如果一个机房没有消费者，则会把这个机房的 MessageQueue 分配给集群中所有的消费者。</p>
<blockquote>
<p>源码所在类：<code>AllocateMachineRoomNearby</code>。</p>
</blockquote>
<p><strong>一致性 Hash 算法策略：</strong></p>
<p>把所有的消费者经过 Hash 计算分布到 Hash 环上，对所有的 MessageQueue  进行 Hash  计算，找到顺时针方向最近的消费者节点进行绑定。如下图：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/11/1105-5VDzq8.png" alt="图片"></p>
<p>源代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//所在类 AllocateMessageQueueConsistentHash</span></span><br><span class="line">Collection&lt;ClientNode&gt; cidNodes = <span class="keyword">new</span> ArrayList&lt;ClientNode&gt;();</span><br><span class="line"><span class="keyword">for</span> (String cid : cidAll) &#123;</span><br><span class="line">    cidNodes.add(<span class="keyword">new</span> ClientNode(cid));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//使用消费者构建 Hash 环，把消费者分布在 Hash 环节点上</span></span><br><span class="line"><span class="keyword">final</span> ConsistentHashRouter&lt;ClientNode&gt; router; <span class="comment">//for building hash ring</span></span><br><span class="line"><span class="keyword">if</span> (customHashFunction != <span class="keyword">null</span>) &#123;</span><br><span class="line">    router = <span class="keyword">new</span> ConsistentHashRouter&lt;ClientNode&gt;(cidNodes, virtualNodeCnt, customHashFunction);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    router = <span class="keyword">new</span> ConsistentHashRouter&lt;ClientNode&gt;(cidNodes, virtualNodeCnt);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//对 MessageQueue 做 Hash 运算，找到环上距离最近的消费者</span></span><br><span class="line">List&lt;MessageQueue&gt; results = <span class="keyword">new</span> ArrayList&lt;MessageQueue&gt;();</span><br><span class="line"><span class="keyword">for</span> (MessageQueue mq : mqAll) &#123;</span><br><span class="line">    ClientNode clientNode = router.routeNode(mq.toString());</span><br><span class="line">    <span class="keyword">if</span> (clientNode != <span class="keyword">null</span> &amp;&amp; currentCID.equals(clientNode.getKey())) &#123;</span><br><span class="line">        results.add(mq);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>面试官</strong>：恭喜你，通过了。</p>
<hr>
<blockquote>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvVXF5MTNFOXFZQU9ONDNoM1hGVW4zZw==">RocketMQ 消息积压了，增加消费者有用吗？<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/357C6XC.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/357C6XC.html" class="post-title-link" itemprop="url">Java8中的Stream轻松遍历树形结构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-09 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-09T00:00:00+08:00">2022-04-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9B%86%E5%90%88%E6%95%B0%E7%BB%84/" itemprop="url" rel="index"><span itemprop="name">集合数组</span></a>
                </span>
            </span>

          
            <span id="/posts/357C6XC.html" class="post-meta-item leancloud_visitors" data-flag-title="Java8中的Stream轻松遍历树形结构" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/357C6XC.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/357C6XC.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE5MjQ0OTI3L2FydGljbGUvZGV0YWlscy8xMDY0ODE3Nzc=">Java 8 中的 Stream 轻松遍历树形结构，是真的牛逼！<i class="fa fa-external-link-alt"></i></span> </p>
</blockquote>
<p>可能平常会遇到一些需求，比如构建菜单，构建树形结构，数据库一般就使用父id来表示，为了降低数据库的查询压力，我们可以使用Java8中的Stream流一次性把数据查出来，然后通过流式处理，我们一起来看看，代码实现为了实现简单，就模拟查看数据库所有数据到List里面。<br>实体类：Menu.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Menu</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> lcry</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Menu</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * id</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> Integer id;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 名称</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> String name;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 父id ，根节点为0</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> Integer parentId;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 子节点信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> List&lt;Menu&gt; childList;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Menu</span><span class="params">(Integer id, String name, Integer parentId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.parentId = parentId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Menu</span><span class="params">(Integer id, String name, Integer parentId, List&lt;Menu&gt; childList)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.parentId = parentId;</span><br><span class="line">        <span class="keyword">this</span>.childList = childList;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>递归组装树形结构</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testtree</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">//模拟从数据库查询出来，公众号Java精选，有惊喜！</span></span><br><span class="line">    List&lt;Menu&gt; menus = Arrays.asList(</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">1</span>,<span class="string">&quot;根节点&quot;</span>,<span class="number">0</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">2</span>,<span class="string">&quot;子节点1&quot;</span>,<span class="number">1</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">3</span>,<span class="string">&quot;子节点1.1&quot;</span>,<span class="number">2</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">4</span>,<span class="string">&quot;子节点1.2&quot;</span>,<span class="number">2</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">5</span>,<span class="string">&quot;根节点1.3&quot;</span>,<span class="number">2</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">6</span>,<span class="string">&quot;根节点2&quot;</span>,<span class="number">1</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">7</span>,<span class="string">&quot;根节点2.1&quot;</span>,<span class="number">6</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">8</span>,<span class="string">&quot;根节点2.2&quot;</span>,<span class="number">6</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">9</span>,<span class="string">&quot;根节点2.2.1&quot;</span>,<span class="number">7</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">10</span>,<span class="string">&quot;根节点2.2.2&quot;</span>,<span class="number">7</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">11</span>,<span class="string">&quot;根节点3&quot;</span>,<span class="number">1</span>),</span><br><span class="line">            <span class="keyword">new</span> Menu(<span class="number">12</span>,<span class="string">&quot;根节点3.1&quot;</span>,<span class="number">11</span>)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取父节点</span></span><br><span class="line">    List&lt;Menu&gt; collect = menus.stream().filter(m -&gt; m.getParentId() == <span class="number">0</span>).map(</span><br><span class="line">            (m) -&gt; &#123;</span><br><span class="line">                m.setChildList(getChildrens(m, menus));</span><br><span class="line">                <span class="keyword">return</span> m;</span><br><span class="line">            &#125;</span><br><span class="line">    ).collect(Collectors.toList());</span><br><span class="line">    System.out.println(<span class="string">&quot;-------转json输出结果-------&quot;</span>);</span><br><span class="line">    System.out.println(JSON.toJSON(collect));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 递归查询子节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> root  根节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> all   所有节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 根节点信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> List&lt;Menu&gt; <span class="title">getChildrens</span><span class="params">(Menu root, List&lt;Menu&gt; all)</span> </span>&#123;</span><br><span class="line">    List&lt;Menu&gt; children = all.stream().filter(m -&gt; &#123;</span><br><span class="line">        <span class="keyword">return</span> Objects.equals(m.getParentId(), root.getId());</span><br><span class="line">    &#125;).map(</span><br><span class="line">            (m) -&gt; &#123;</span><br><span class="line">                m.setChildList(getChildrens(m, all));</span><br><span class="line">                <span class="keyword">return</span> m;</span><br><span class="line">            &#125;</span><br><span class="line">    ).collect(Collectors.toList());</span><br><span class="line">    <span class="keyword">return</span> children;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>格式化打印结果:  </p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/13/1045-YbMIJ3.jpg" alt="1045-YbMIJ3"></p>
<hr>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xuemingde.com/posts/1Z9HSDW.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpeg">
      <meta itemprop="name" content="meadel">
      <meta itemprop="description" content="我的愿望，世界和平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Middle's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/1Z9HSDW.html" class="post-title-link" itemprop="url">Kafka面试连环炮-中</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-09 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-09T00:00:00+08:00">2022-04-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 16:46:48" itemprop="dateModified" datetime="2022-08-13T16:46:48+08:00">2022-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" itemprop="url" rel="index"><span itemprop="name">消息队列</span></a>
                </span>
            </span>

          
            <span id="/posts/1Z9HSDW.html" class="post-meta-item leancloud_visitors" data-flag-title="Kafka面试连环炮-中" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/1Z9HSDW.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/1Z9HSDW.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>16k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>15 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="谈谈你对-kafka-的集群架构是如何理解的"><a href="#谈谈你对-kafka-的集群架构是如何理解的" class="headerlink" title="谈谈你对 kafka 的集群架构是如何理解的"></a>谈谈你对 kafka 的集群架构是如何理解的</h2><h3 id="Kafka-整体架构图"><a href="#Kafka-整体架构图" class="headerlink" title="Kafka 整体架构图"></a>Kafka 整体架构图</h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1102-jB6bMF.png" alt="图片"></p>
<p>一个典型的 Kafka 集群中包含若干 Producer，若干 Broker「<code>Kafka支持水平扩展，一般 Broker 数量越多，集群吞吐率越高</code>」，若干 Consumer Group，以及一个 Zookeeper集群。</p>
<p>Kafka 通过 Zookeeper 管理集群配置，选举 Leader，以及在 Consumer Group 发生变化时进行  Rebalance。Producer 使用 push 模式将消息发布到 Broker，Consumer使用 pull 模式从 Broker  订阅并消费消息。</p>
<h3 id="Kafka-存储机制"><a href="#Kafka-存储机制" class="headerlink" title="Kafka 存储机制"></a>Kafka 存储机制</h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1104-3TFhEL.png" alt="图片"></p>
<p>Producer 端生产的消息会不断追加到 log 文件末尾，这样文件就会越来越大, 为了防止 log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制。</p>
<p>它将每个 Partition 分为多个 Segment每个 Segment 对应3个文件：</p>
<blockquote>
<p>1）.index 索引文件</p>
<p>2）.log 数据文件</p>
<p>3）.timeindex 时间索引文件</p>
</blockquote>
<p>这些文件都位于同一文件夹下面，该文件夹的命名规则为：<code>topic 名称-分区号</code>。</p>
<h3 id="Kafka-副本机制"><a href="#Kafka-副本机制" class="headerlink" title="Kafka 副本机制"></a>Kafka 副本机制</h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1106-LIXgWy.png" alt="图片"></p>
<p>Kafka中的 Partition 为了保证数据安全，每个 Partition 可以设置多个副本。此时我们对分区0,1,2分别设置3个副本。而且每个副本都是有「<code>角色</code>」之分的，<code>它们会选取一个副本作为 Leader 副本，而其他的作为 Follower 副本</code>，我们的 Producer 端在发送数据的时候，只能发送到Leader Partition 里面 ，然后 Follower Partition 会去  Leader Partition 自行同步数据, Consumer 消费数据的时候，也只能从 Leader 副本那去消费数据的。</p>
<h3 id="Kafka-网络模型"><a href="#Kafka-网络模型" class="headerlink" title="Kafka 网络模型"></a>Kafka 网络模型</h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1108-cuVayj.png" alt="图片"></p>
<p>Kafka 采用多路复用方案，Reactor 设计模式，并引用 Java NIO 的方式更好的解决网络超高并发请求问题。</p>
<h2 id="谈谈Kafka客户端如何巧妙解决JVM-GC问题"><a href="#谈谈Kafka客户端如何巧妙解决JVM-GC问题" class="headerlink" title="谈谈Kafka客户端如何巧妙解决JVM GC问题"></a>谈谈Kafka客户端如何巧妙解决JVM GC问题</h2><h3 id="Kafka-客户端缓冲机制"><a href="#Kafka-客户端缓冲机制" class="headerlink" title="Kafka 客户端缓冲机制"></a>Kafka 客户端缓冲机制</h3><p>首先，大家知道的就是在客户端发送消息给 Kafka 服务端的时候，存在一个「<code>内存缓冲池机制</code>」 的。即消息会先写入一个内存缓冲池中，然后直到多条消息组成了一个 Batch，达到一定条件才会一次网络通信把 Batch 发送过去。</p>
<p>整个发送过程图如下所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1109-hKDJ5D.png" alt="图片"></p>
<p><strong>Kafka Producer 发送消息流程如下</strong>：</p>
<blockquote>
<p>1）进行 Producer 初始化，加载配置参数，开启网络线程。</p>
<p>2）执行拦截器逻辑，预处理消息, 封装 Producer Record。</p>
<p>3）调用 Serializer.serialize() 方法进行消息的 key/value 序列化。</p>
<p>4）调用 partition() 选择合适的分区策略，给消息体 Producer Record 分配要发送的 Topic 分区号。</p>
<p>5）从 Kafka Broker 集群获取集群元数据 metadata。</p>
<p>6）将消息缓存到 RecordAccumulator 收集器中, 最后判断是否要发送。这个加入消息收集器，首先得从 Deque<RecordBatch> 里找到自己的目标分区，如果没有就新建一个 Batch 消息 Deque 加进入。</p>
<p>7）当达到发送阈值，唤醒 Sender 线程，实例化 NetWorkClient 将 batch record 转换成 request client 的发送消息体, 并将待发送的数据按 【Broker Id &lt;=&gt; List】的数据进行归类。</p>
<p>8）与服务端不同的 Broker 建立网络连接，将对应 Broker 待发送的消息 List 发送出去。</p>
<p>9）批次发送的条件为: 缓冲区数据大小达到 batch.size 或者 linger.ms 达到上限，哪个先达到就算哪个。</p>
</blockquote>
<h3 id="内存缓冲造成的频繁GC问题"><a href="#内存缓冲造成的频繁GC问题" class="headerlink" title="内存缓冲造成的频繁GC问题"></a>内存缓冲造成的频繁GC问题</h3><p>内存缓冲机制说白了，其实就是<code>把多条消息组成一个Batch，一次网络请求就是一个Batch 或者多个 Batch</code>。这样避免了一条消息一次网络请求，从而提升了吞吐量。</p>
<p>那么问题来了，试想一下一个 Batch 中的数据取出来封装到网络包里，通过网络发送到达 Kafka 服务端。<strong>此时**</strong>这个 Batch 里的数据都发送过去了，里面的数据该怎么处理？**这些 Batch 里的数据还存在客户端的 JVM 的内存里！那么一定要避免任何变量去引用 Batch 对应的数据，然后尝试触发 JVM 自动回收掉这些内存垃圾。这样不断的让 JVM 进行垃圾回收，就可以不断的腾出来新的内存空间让后面新的数据来使用。</p>
<p>想法是挺好，但<code>实际生产运行的时候最大的问题，就是 JVM Full GC 问题</code>。JVM GC 在回收内存垃圾的时候，会有一个「<code>Stop the World</code>」的过程，即垃圾回收线程运行的时候，会导致其他工作线程短暂的停顿，这样可以踏踏实实的回收内存垃圾。</p>
<p><code>试想一下，在回收内存垃圾的时候，工作线程还在不断的往内存里写数据，那如何让JVM 回收垃圾呢？</code>我们看看下面这张图就更加清楚了：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1112-t0PQaN.png" alt="图片"></p>
<p>虽然现在 JVM GC 演进越来越先进，从 CMS 垃圾回收器到 G1 垃圾回收器，<code>核心的目标之一就是不断的缩减垃圾回收的时候，导致其他工作线程停顿的时间</code>。但是再先进的垃圾回收器这个停顿的时间还是存在的。</p>
<p>因此，如何尽可能在设计上避免 JVM 频繁的 Full GC 就是一个非常考验其设计水平了。</p>
<h3 id="Kafka-实现的缓冲机制"><a href="#Kafka-实现的缓冲机制" class="headerlink" title="Kafka 实现的缓冲机制"></a>Kafka 实现的缓冲机制</h3><p>在 Kafka 客户端内部，针对这个问题实现了一个非常优秀的机制，就是「<code>缓冲池机制</code>」。即每个 Batch 底层都对应一块内存空间，这个内存空间就是专门用来存放写进去的消息。</p>
<p>当一个 Batch 数据被发送到了 kafka 服务端，这个 Batch 的内存空间不再使用了。<code>此时这个 Batch 底层的内存空间先不交给 JVM 去垃圾回收，而是把这块内存空间给放入一个缓冲池里</code>。</p>
<p>这个缓冲池里存放了很多块内存空间，下次如果有一个新的 Batch 数据了，那么直接从缓冲池获取一块内存空间是不是就可以了？然后如果一个 Batch 数据发送出去了之后，再把内存空间还回来是不是就可以了？以此类推，循环往复。</p>
<p>我们看看下面这张图就更加清楚了：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1116-5yWo2x.png" alt="图片"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1117-j0gteO.png" alt="图片"></p>
<p>一旦使用了这个缓冲池机制之后，就不涉及到频繁的大量内存的 GC 问题了。</p>
<p><code>初始化分配固定的内存，即32MB。然后把 32MB 划分为 N 多个内存块，一个内存块默认是16KB，这样缓冲池里就会有很多的内存块</code>。然后如果需要创建一个新的 Batch，就从缓冲池里取一个 16KB 的内存块就可以了。</p>
<p>接着如果 Batch 数据被发送到 Kafka 服务端了，此时 Batch  底层的内存块就直接还回缓冲池就可以了。这样循环往复就可以利用有限的内存，那么就不涉及到垃圾回收了。没有频繁的垃圾回收，自然就避免了频繁导致的工作线程的停顿了，JVM Full GC 问题是不是就得到了大幅度的优化？</p>
<p><code>没错，正是这个设计思想让 Kafka 客户端的性能和吞吐量都非常的高，这里蕴含了大量的优秀的机制</code><strong>。</strong></p>
<h2 id="谈谈你对-Kafka-消息语义是如何理解的"><a href="#谈谈你对-Kafka-消息语义是如何理解的" class="headerlink" title="谈谈你对 Kafka 消息语义是如何理解的"></a>谈谈你对 Kafka 消息语义是如何理解的</h2><p>对于 Kafka 来说，当消息从 Producer 到 Consumer，有许多因素来影响消息的消费，因此「<code>消息传递语义</code>」就是 Kafka 提供的 Producer 和 Consumer 之间的消息传递过程中消息传递的保证性。主要分为三种， 如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1118-eogRgs.jpeg" alt="图片"></p>
<p>对于这三种语义，我们来看一下可能出现的场景：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1118-2W86JT.png" alt="图片"></p>
<h3 id="Producer端"><a href="#Producer端" class="headerlink" title="Producer端"></a>Producer端</h3><p><strong>生产者发送语义</strong>：首先当 Producer 向 Broker 发送数据后，会进行消息提交，如果成功消息不会丢失。因此发送一条消息后，可能会有几种情况发生：</p>
<blockquote>
<p>1）遇到网络问题造成通信中断， 导致 Producer 端无法收到 ack，Producer 无法准确判断该消息是否已经被提交， 又重新发送消息，这就可能造成 「<strong>at least once</strong>」语义。</p>
<p>2）在 Kafka 0.11之前的版本，会导致消息在 Broker 上重复写入（保证至少一次语义），但在0.11版本开始，通过引入「<strong>PID及Sequence Number</strong>」支持幂等性，保证精确一次「<strong>exactly once</strong>」语义。</p>
<p><strong>其中启用幂等传递的方法配置</strong>：enable.idempotence = true。<strong>启用事务支持的方法配置</strong>：设置属性 transcational.id = “指定值”。</p>
<p>3）可以根据 Producer 端 request.required.acks 的配置来取值。</p>
<p><strong>acks = 0</strong>：由于发送后就自认为发送成功，这时如果发生网络抖动， Producer 端并不会校验 ACK 自然也就丢了，且无法重试。</p>
<p><strong>acks = 1</strong>：消息发送 Leader Parition 接收成功就表示发送成功，这时只要 Leader Partition 不 Crash 掉，就可以保证 Leader Partition 不丢数据，保证 「<strong>at least once</strong>」语义。</p>
<p><strong>acks = -1 或者 all</strong>： 消息发送需要等待 ISR 中 Leader Partition 和 所有的 Follower Partition 都确认收到消息才算发送成功, 可靠性最高, 但也不能保证不丢数据,比如当 ISR 中只剩下 Leader Partition 了, 这样就变成 acks = 1 的情况了，保证 「<strong>at least once</strong>」语义。 </p>
</blockquote>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1121-kMQFze.png" alt="图片"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1121-jOqsh8.png" alt="图片"></p>
<h3 id="Consumer端"><a href="#Consumer端" class="headerlink" title="Consumer端"></a>Consumer端</h3><p><strong>消费者接收语义</strong>：从 Consumer 角度来剖析，我们知道 Offset 是由 Consumer 自己来维护的。</p>
<p>Consumer 消费消息时，有以下2种选择:</p>
<blockquote>
<p>1）<strong>读取消息 -&gt; 提交offset -&gt; 处理消息</strong>: 如果此时保存 offset 成功，但处理消息失败，Consumer 又挂了，会发生 Reblance，新接管的 Consumer 将从上次保存的 offset 的下一条继续消费，导致消息丢失，保证「<strong>at most once</strong>」语义。</p>
<p>2）<strong>读取消息 -&gt; 处理消息 -&gt; 提交offset：</strong>如果此时消息处理成功，但保存 offset 失败，Consumer 又挂了，导致刚才消费的 offset 没有被成功提交，会发生 Reblance，新接管的 Consumer 将从上次保存的 offset 的下一条继续消费，导致消息重复消费，保证「<strong>at least once</strong>」语义。</p>
</blockquote>
<p><strong>总结</strong>：默认 Kafka 提供 「<strong>at least once</strong>」语义的消息传递，允许用户通过在处理消息之前保存 Offset 的方式提供 「<strong>at most once</strong>」 语义。如果我们可以自己实现消费幂等，理想情况下这个系统的消息传递就是严格的「<strong>exactly once</strong>」, 也就是保证不丢失、且只会被精确的处理一次，但是这样是很难做到的。</p>
<h2 id="谈谈你对-Kafka-副本机制是如何理解的"><a href="#谈谈你对-Kafka-副本机制是如何理解的" class="headerlink" title="谈谈你对 Kafka 副本机制是如何理解的"></a>谈谈你对 Kafka 副本机制是如何理解的</h2><p>在上篇中，我们简单的分析了 Kafka 副本机制，这里我们再详细分析下 Kafka 的副本机制，说白了就是一个「<strong>数据备份机制</strong>」。</p>
<p>保证集群中的某个节点发生故障时，该节点上的 Partition 数据不丢失，且 Kafka 仍然能够继续工作，提高了系统可用性和数据持久性。</p>
<p><strong>同一个分区下的所有副本保存相同的消息数据，这些副本分散保存在不同的 Broker 上，保证了 Broker 的整体可用性</strong>。</p>
<p>如下图所示：一个由 3 台 Broker 组成的 Kafka 集群上的副本分布情况。从这张图中，我们可以看到，主题 1 分区 1 的 3 个副本分散在 3 台 Broker 上，其他主题分区的副本也都散落在不同的 Broker 上，从而实现数据冗余。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1123-92qV6d.png" alt="图片"></p>
<h3 id="副本同步机制"><a href="#副本同步机制" class="headerlink" title="副本同步机制"></a>副本同步机制</h3><p>既然所有副本的消息内容相同，我们该如何保证副本中所有的数据都是一致的呢？当 Producer 发送消息到某个 Topic 后，消息是如何同步到对应的所有副本 Replica 中的呢？Kafka 中 只有 Leader  副本才能对外进行读写服务，所以解决同步问题，Kafka 是采用基于 <strong>Leader</strong> 的副本机制来完成的。</p>
<blockquote>
<p>1）在 Kafka 中，一个 Topic 的每个 Partition 都有若干个副本，<strong>副本分成两类：领导者副本「Leader Replica」和追随者副本「Follower Replica」</strong>。每个分区在创建时都要选举一个副本作为领导者副本，其余的副本作为追随者副本。</p>
<p>2）在 Kafka 中，Follower 副本是不对外提供服务的。也就是说，任何一个Follower 副本都不能响应客户端的读写请求。<strong>所有的读写请求都必须先发往 Leader 副本所在的 Broker，由该 Broker 负责处理。Follower 副本不处理客户端请求，它唯一的任务就是从 Leader 副本异步拉取消息，并写入到自己的提交日志中，从而实现与 Leader 副本的同步</strong>。</p>
<p>3）在 Kafka 2.X 版本中，当 Leader 副本 所在的 Broker 宕机时，ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的 Leader 选举，从 ISR 副本集合中 Follower 副本中选一个作为新的 Leader ，当旧的 Leader 副本重启回来后，只能作为 Follower 副本加入到集群中。3.x 的选举后续会有单篇去介绍。</p>
</blockquote>
<h3 id="副本管理"><a href="#副本管理" class="headerlink" title="副本管理"></a>副本管理</h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1125-A7BEEJ.png" alt="图片"></p>
<blockquote>
<p>1）<strong>AR 副本集合</strong>: 分区 Partition 中的所有 Replica 组成 AR 副本集合。</p>
<p>2）<strong>ISR 副本集合</strong>: 所有与 Leader 副本能保持一定程度同步的 Replica 组成 ISR 副本集合， 其中也包括 Leader 副本。</p>
<p>3）<strong>OSR 副本集合</strong>: 与 Leader 副本同步滞后过多的 Replica 组成 OSR 副本集合。</p>
</blockquote>
<p>这里我们重点来分析下 <strong>ISR 副本集合。</strong></p>
<h3 id="ISR-副本集合"><a href="#ISR-副本集合" class="headerlink" title="ISR 副本集合"></a>ISR 副本集合</h3><p>上面强调过，Follower 副本不提供服务，只是定期地异步拉取 Leader 副本中的数据。既然是异步的，就一定会存在不能与 Leader 实时同步的情况出现。</p>
<p>Kafka 为了解决这个问题， 引入了「 <strong>In-sync Replicas</strong>」机制，即 ISR 副本集合。要求 ISR 副本集合中的 Follower 副本都是与 Leader 同步的副本。</p>
<p><strong>那么，到底什么样的副本能够进入到 ISR 副本集合中呢？</strong></p>
<p>首先要明确的，Leader 副本天然就在 ISR 副本集合中。也就是说，ISR 不只是有 Follower 副本集合，它必然包括 Leader 副本。另外，能够进入到 ISR 副本集合的 Follower 副本要满足一定的条件。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1126-mBDiIQ.png" alt="图片"></p>
<p>图中有 3 个副本：1 个 Leader 副本和 2 个 Follower 副本。Leader 副本当前写入了 6 条消息，Follower1  副本同步了其中的 4 条消息，而 Follower2 副本只同步了其中的 3 条消息。那么，对于这 2 个 Follower 副本，你觉得哪个  Follower 副本与 Leader 不同步？</p>
<p>事实上，这2个 Follower 副本都有可能与 Leader 副本同步，但也可能不与 Leader 副本同步，这个完全依赖于<strong>Broker 端参数 replica.lag.time.max.ms 参数值</strong>。</p>
<p>这个参数是指 <strong>Follower 副本能够落后 Leader 副本的最长时间间隔，当前默认值是 10 秒，从 2.5 版本开始，默认值从 10 秒增加到 30 秒</strong>。即只要一个 Follower 副本落后Leader 副本的时间不连续超过 30 秒，Kafka 就认为该 Follower 副本与 Leader 是同步的，即使 Follower 副本中保存的消息明显少于 Leader 副本中的消息。</p>
<p>此时如果这个副本同步过程的速度持续慢于 Leader 副本的消息写入速度的时候，那么在 replica.lag.time.max.ms 时间后，该 Follower 副本就会被认为与 Leader 副本是不同步的，因此 Kafka 会自动收缩，将其踢出 ISR 副本集合中。后续如果该副本追上了 Leader 副本的进度的话，那么它是能够重新被加回 ISR副本集合的。</p>
<p>在默认情况下，当 Leader 副本发生故障时，只有在 ISR 副本集合中的 Follower 副本才有资格被选举为新Leader，而 OSR 中副本集合的副本是没有机会的（可以通过<strong>unclean.leader.election.enable</strong> 进行配置执行脏选举）。</p>
<p><strong>总结：ISR 副本集合是一个动态调整的集合。</strong></p>
<h2 id="谈谈你对Kafka-Leader选举机制是如何理解"><a href="#谈谈你对Kafka-Leader选举机制是如何理解" class="headerlink" title="谈谈你对Kafka Leader选举机制是如何理解"></a>谈谈你对Kafka Leader选举机制是如何理解</h2><p>这里所说的 Leader 选举是指分区 Leader 副本的选举，<strong>它是由 Kafka Controller 负责具体执行的，当创建分区或分区副本上线的时候都需要执行 Leader 的选举动作</strong>。</p>
<p>有以下场景可能会触发选举：</p>
<p>1）当 Controller 感知到分区 Leader 下线需要执行 Leader 选举。</p>
<p>此时的选举策略是：Controller 会从 AR 副本集合（同时也在ISR 副本集合）中按照副本的顺序取出第一个存活的副本作为 Leader。</p>
<p>⼀个分区的 AR 副本集合在分配的时候就被指定，并且只要不发⽣重分配集合内部副本的顺序是保持不变的，而分区的 ISR 副本集合中副本的顺序可能会改变。</p>
<p><strong>注意这里是根据 AR 副本集合的顺序而不是 ISR 副本结合的顺序进行选举的。</strong></p>
<p>此时如果 ISR 副本集合中没有可用的副本，还需要再检查⼀下所配置的 unclean.leader.election.enable 参数「 <strong>默认值为false</strong>」。<strong>如果这个参数配置为true，那么表示允许从非 ISR 副本集合中选举 Leader，从 AR 副本集合列表中找到第⼀个存活的副本即为 Leader</strong>。</p>
<p>2）当分区进行重分配的时候也需要进行 Leader 选举。</p>
<p>此时的选举策略是：<strong>从重分配的 AR 副本集合中找到第⼀个存活的副本，且这个副本在当前的 ISR 副本集合中。当发生优先副本的选举时，直接将优先副本设置为 Leader 即可，AR 副本集合中的第⼀个副本即为优先副本</strong>。</p>
<p>3）当某节点执⾏ ControlledShutdown 被优雅地关闭时，位于这个节点上的 Leader 副本都会下线，所以与此对应的分区需要执行 Leader 的选举。</p>
<p>此时的选举策略是：<strong>从 AR 副本集合中找到第⼀个存活的副本，且这个副本在当前的 ISR 副本集合中，同时还要确保这个副本不处于正在被关闭的节点上</strong>。</p>
<h2 id="谈谈你对Kafka控制器及选举机制是如何理解"><a href="#谈谈你对Kafka控制器及选举机制是如何理解" class="headerlink" title="谈谈你对Kafka控制器及选举机制是如何理解"></a>谈谈你对Kafka控制器及选举机制是如何理解</h2><p>所谓的控制器「<strong>Controller</strong>」就是通过 ZooKeeper 来管理和协调整个 Kafka 集群的组件。集群中任意一台 Broker 都可以充当控制器的角色，但是在正常运行过程中，只能有一个 Broker 成为控制器。</p>
<p><strong>控制器的职责主要包括：</strong></p>
<blockquote>
<p>1）集群元信息管理及更新同步 (Topic路由信息等)。</p>
<p>2）主题管理（创建、删除、增加分区等）。</p>
<p>3）分区重新分配。</p>
<p>4）副本故障转移、 Leader 选举、ISR 变更。</p>
<p>5）集群成员管理（通过 watch 机制自动检测新增 Broker、Broker 主动关闭、Broker 宕机等）。</p>
</blockquote>
<h3 id="控制器机制"><a href="#控制器机制" class="headerlink" title="控制器机制"></a>控制器机制</h3><p>我们知道 Kafka 2.X 版本是依赖 Zookeeper 来维护集群成员的信息：</p>
<blockquote>
<p>1）Kafka 使用 Zookeeper 的临时节点来选举 Controller。</p>
<p>2）Zookeeper 在 Broker 加入集群或退出集群时通知 Controller。</p>
<p>3）Controller 负责在 Broker 加入或离开集群时进行分区 Leader 选举。</p>
</blockquote>
<h3 id="控制器数据分布"><a href="#控制器数据分布" class="headerlink" title="控制器数据分布"></a>控制器数据分布</h3><p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1132-l7T1Os.png" alt="1132-XtrOlE"></p>
<p>从上面表格可以看出,存储的大概有3大类:</p>
<blockquote>
<p>1）<strong>所有topic信息</strong>：包括具体的分区信息，比如 Leader 副本是谁，ISR 集合中有哪些副本等。</p>
<p>2）<strong>所有 Broker 信息</strong>：包括当前都有哪些运行中的 Broker，哪些正在关闭中的 Broker 等。</p>
<p>3）<strong>涉及运维任务的副本分区</strong>：包括当前正在进行 Leader 选举以及分区重分配的分区列表等。</p>
</blockquote>
<h3 id="控制器故障转移"><a href="#控制器故障转移" class="headerlink" title="控制器故障转移"></a>控制器故障转移</h3><p>在 Kafka 集群运行过程中，只能有一台 Broker 充当控制器的角色，存在「<strong>单点故障</strong>」的风险，Kafka 如何应对单点故障呢？</p>
<p>其实 Kafka 为控制器提供故障转移功能「<strong>Failover</strong>」。<strong>指当运行中的控制器突然宕机时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败控制器的过程</strong>。</p>
<p>下面通过一张图来展示控制器故障转移的过程：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1133-yarAzV.png" alt="图片"></p>
<h3 id="控制器触发选举场景"><a href="#控制器触发选举场景" class="headerlink" title="控制器触发选举场景"></a>控制器触发选举场景</h3><p>至此你一定想知道控制器是如何被选出来的？前面说过，每台 Broker 都能充当控制器，当集群启动后，Kafka 是如何确认控制器在哪台 Broker 呢？</p>
<p>实际上这个问题很简单，即 <strong>Broker 启动时， 会尝试去 ZooKeeper 中创建 /controller 节点， 第一个成功创建 /controller 节点的 Broker 会被选为控制器</strong>。</p>
<p>接下来我们看下<strong>触发 Controller 选举的场景</strong>有哪些？</p>
<p><strong>场景一、集群首次启动时</strong>：</p>
<p>集群首次启动时，Controller 还未被选举出来，因此 Broker 启动后，会干4件事：</p>
<blockquote>
<p>1）先注册 Zookeeper 状态变更监听器，用来监听 Broker 与 Zookeeper 之间的会话是否过期。</p>
<p>2）然后将 Startup 这个控制器事件写入到事件队列中。</p>
<p>3）然后开始启动对应的控制器事件处理线程即「<strong>ControllerEventThread</strong>」、以及 「<strong>ControllerChangeHandler</strong>」 Zookeeper 监听器，开始处理事件队列中Startup 事件。</p>
<p>4）最后依赖事件处理线程来选举 Controller。</p>
</blockquote>
<p><strong>场景二、Broker 监听 /controller 节点消失时</strong>：</p>
<p>集群运行过程中，当 <strong>Broker 监听到 /controller 节点消失时，就表示此时当前整个集群中已经没有 Controller 了</strong>。所有监听到 /controller 节点消失的 Broker，此时都会开始执行竞选操作。 </p>
<p>那么 Broker 是如何监听到 ZooKeeper 上的变化呢？主要依赖 ZooKeeper 监听器提供的功能，所以 Kafka 是依赖 ZooKeeper 来完成 Controller 的选举。</p>
<p>对于 Kafka 3.X 版本中，内部实现一个类似于 Raft 的共识算法来选举 Controller。</p>
<p><strong>场景三、Broker 监听 /controller 节点数据变化时</strong>：</p>
<p>集群运行过程中，当 <strong>Broker 检测到 /controller 节点数据发生变化，此时 Controller 可能已经被「易主」了</strong>，这时有以下两种情况：</p>
<blockquote>
<p>1）假如 Broker 是 Controller，那么该 Broker 需要首先执「<strong>退位</strong>」操作，然后再尝试进行竞选 Controller。</p>
<p>2）假如 Broker 不是 Controller，那么，该 Broker 直接去竞选新 Controller。</p>
</blockquote>
<h3 id="控制器选举机制"><a href="#控制器选举机制" class="headerlink" title="控制器选举机制"></a>控制器选举机制</h3><p>其实选举最终都是通过调用底层的 elect 方法进行选举，如下图所示：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1136-lra2F8.png" alt="图片"></p>
<h2 id="谈谈-kafka-的数据可靠性是怎么保证的"><a href="#谈谈-kafka-的数据可靠性是怎么保证的" class="headerlink" title="谈谈 kafka 的数据可靠性是怎么保证的"></a>谈谈 kafka 的数据可靠性是怎么保证的</h2><p>开始数据可靠性之前先看几个重要的概念：AR、OSR、ISR、HW、LEO，前面已经讲了 AR、OSR、ISR。这里我们重点讲下 HW、LEO。</p>
<p><strong>HW：</strong>全称「<strong>Hign WaterMark</strong>」 ，即高水位，它标识了一个特定的消息偏移量 offset ，消费者只能拉取到这个水位 offset 之前的消息。</p>
<p><strong>LEO：</strong>全称「<strong>Log End Offset</strong>」，它标识当前日志文件中下一条待写入的消息的 offset，在 ISR 副本集合中的每个副本都会维护自身的LEO。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1137-xMwgU3.png" alt="图片"></p>
<p>从上图可以看出 HW 和 LEO 的作用：</p>
<blockquote>
<p><strong>HW 作用</strong>：</p>
<p>1）用来标识分区下的哪些消息是可以被消费者消费的。</p>
<p>2）协助 Kafka 完成副本数据同步。</p>
<p><strong>LEO 作用</strong>：</p>
<p>1）如果 Follower 和 Leader 的 LEO 数据同步了, 那么 HW 就可以更新了。</p>
<p>2）HW 之前的消息数据对消费者是可见的，属于 commited 状态, HW 之后的消息数据对消费者是不可见的。</p>
</blockquote>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1137-JexxNf.png" alt="图片"></p>
<p><strong>HW 更新是需要一轮额外的拉取请求才能实现，</strong>Follower 副本要拉取 Leader 副本的数据，也就是说，Leader 副本 HW 更新和 Follower 副本 HW 更新在时间上是存在错配的。<strong>这种错配是很多“数据丢失”或“数据不一致”问题的根源</strong>。因此社区在 0.11 版本正式引入了 「<strong>Leader Epoch</strong>」 概念，来规避因 HW 更新错配导致的各种不一致问题。</p>
<p> 所谓 Leader Epoch，我们大致可以认为是 Leader 版本。它由两部分数据组成：</p>
<blockquote>
<p>1）<strong>Epoch</strong>: 一个单调递增的版本号。每当副本 Leader 权力发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</p>
<p>2）<strong>起始位移（Start Offset）:</strong> Leader 副本在该 Epoch 值上写入的首条消息的位移。</p>
</blockquote>
<p>Kafka Broker 会在<strong>内存中为每个分区都缓存 Leader Epoch 数据</strong>，同时它还会定期地将这些信息<strong>持久化到一个 checkpoint 文件</strong>中。当 Leader Partition 写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么  Broker 会向缓存中增加一个 Leader Epoch 条目，否则就不做更新。这样，每次有 Leader 变更时，新的 Leader  副本会查询这部分缓存，取出对应的 Leader Epoch 的起始位移，以避免数据丢失和不一致的情况。</p>
<p>严格来说，这个场景发生的前提是 <strong>Broker 端参数 min.insync.replicas 设置为 1</strong>。此时一旦消息被写入到 Leader 副本的磁盘，就会被认为是 commited 状态，但因存在时间错配问题导致 Follower 的 HW 更新是有滞后的。如果在这个短暂的滞后时间内，接连发生 Broker 宕机，那么这类数据的丢失就是无法避免的。</p>
<p>接下来, 我们来看下如何利用 Leader Epoch 机制来规避这种数据丢失。如下图所示:</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1138-wdHb98.png" alt="图片"></p>
<p>因此 Kafka 只对 「<strong>已提交</strong>」的消息做「<strong>最大限度的持久化保证不丢失</strong>」<strong>。</strong>由于篇幅详细请看：<span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1NemczTVRjeE1EZ3hOQT09JmFtcDttaWQ9MjI0NzQ5MDQ4OSZhbXA7aWR4PTEmYW1wO3NuPTE3ODE3ZjZkOTgzN2FkNmE4ODIzMzYyZDVlZDM4Njg3JmFtcDtjaGtzbT1jZWZiMzI4OGY5OGNiYjllZGViNTY4ZTUxMTI3YzI1Y2FhOTBkYTZkZDA2NDkzNjU2MGE4NTFhOWM5ZTViODY1YmI0OWNhMDQzMTJkJmFtcDtzY2VuZT0yMSN3ZWNoYXRfcmVkaXJlY3Q=">刨根问底: Kafka 到底会不会丢数据<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="谈谈-Kafka-消息分配策略都有哪些"><a href="#谈谈-Kafka-消息分配策略都有哪些" class="headerlink" title="谈谈 Kafka 消息分配策略都有哪些"></a>谈谈 Kafka 消息分配策略都有哪些</h2><p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1139-ygE1jr.png" alt="图片"></p>
<p>这里主要说的是<strong>消费的分区分配策略</strong>，我们知道一个 Consumer Group 中有多个 Consumer，一个 Topic 也有多个 Partition，所以必然会有 Partition 分配问题「 <strong>确定哪个 Partition 由哪个 Consumer 来消费的问题</strong>」。</p>
<p>Kafka 客户端提供了3 种分区分配策略：RangeAssignor、RoundRobinAssignor 和 StickyAssignor，前两种分配方案相对简单一些StickyAssignor 分配方案相对复杂一些。</p>
<h3 id="RangeAssignor"><a href="#RangeAssignor" class="headerlink" title="RangeAssignor"></a>RangeAssignor</h3><p><strong>RangeAssignor 是 Kafka 默认的分区分配算法，它是按照 Topic 的维度进行分配的</strong>，首先对 每个Topic 的 Partition 按照分区ID进行排序，然后对订阅该 Topic 的 Consumer Group 的 Consumer 按名称字典进行排序，之后<strong>尽量均衡的按照范围区段将分区分配给 Consumer</strong>。此时也可能会造成先分配分区的 Consumer 任务过重（分区数无法被消费者数量整除）。</p>
<p><strong>分区分配场景分析如下图所示（同一个消费者组下的多个 consumer）：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1141-HeOa2X.png" alt="图片"></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1141-WDb11i.png" alt="图片"></p>
<p><strong>总结：该分配方式明显的问题就是随着消费者订阅的Topic的数量的增加，不均衡的问题会越来越严重。</strong></p>
<h3 id="RoundRobinAssignor"><a href="#RoundRobinAssignor" class="headerlink" title="RoundRobinAssignor"></a>RoundRobinAssignor</h3><p><strong>该分区分配策略是将 Consumer Group 订阅的所有 Topic 的 Partition 及所有 Consumer 按照字典进行排序后尽量均衡的挨个进行分配。</strong>如果 Consumer Group 内，每个 Consumer 订阅都订阅了相同的Topic，那么分配结果是均衡的。如果订阅 Topic 是不同的，那么分配结果是不保证「 <strong>尽量均衡</strong>」的，因为某些 Consumer 可能不参与一些 Topic 的分配。</p>
<p><strong>分区分配场景分析如下图所示：</strong></p>
<p><strong>1) 当组内每个 Consumer 订阅的相同 Topic ：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1142-VQUTaw.png" alt="图片"></p>
<p> <strong>2) 当组内每个订阅的不同的 Topic ，这样就可能会造成分区订阅的倾斜:</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1143-4QBLYi.png" alt="图片"></p>
<h3 id="StickyAssignor"><a href="#StickyAssignor" class="headerlink" title="StickyAssignor"></a>StickyAssignor</h3><p>该分区分配算法是最复杂的一种，<code>可以通过 partition.assignment.strategy 参数去设置</code>，从 0.11 版本开始引入，目的就是在执行新分配时，尽量在上一次分配结果上少做调整，其主要实现了以下2个目标：</p>
<blockquote>
<p><strong>1、Topic Partition 的分配要尽量均衡。</strong></p>
<p><strong>2、当 Rebalance 发生时，尽量与上一次分配结果保持一致。</strong></p>
</blockquote>
<p>注意：<code>当两个目标发生冲突的时候，优先保证第一个目标，这样可以使分配更加均匀</code>，其中第一个目标是3种分配策略都尽量去尝试完成的， 而第二个目标才是该算法的精髓所在。</p>
<p>下面我们看看该策略与RoundRobinAssignor策略的不同：</p>
<p><strong>分区分配场景分析如下图所示：</strong></p>
<p>1）组内每个 Consumer 订阅的相同的 Topic ，RoundRobinAssignor 跟StickyAssignor 分配一致：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1145-sl6JNK.png" alt="图片"></p>
<p><strong>当发生 Rebalance 情况后，可能分配会不太一样，假如这时候C1发生故障下线：</strong></p>
<p><strong>RoundRobinAssignor：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1145-w3iSze.png" alt="图片"></p>
<p><strong>StickyAssignor</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1146-woSiuw.png" alt="图片"></p>
<p><strong>结论: 从上面 Rebalance 发生后的结果可以看出，虽然两种分配策略最后都是均匀分配的，但是 RoundRoubinAssignor 分区分配策略完全是重新分配了一遍，而 StickyAssignor则是在原先的基础上达到了均匀的状态。</strong></p>
<p><strong>2) 当组内每个 Consumer 订阅的 Topic 是不同情况:</strong></p>
<p><strong>RoundRobinAssignor：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1147-O04CtK.png" alt="图片"></p>
<p><strong>StickyAssignor</strong>：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1148-4ceydf.png" alt="图片"></p>
<p><strong>当发生 Rebalance 情况后，可能分配会不太一样，假如这时候C1发生故障下线：</strong></p>
<p><strong>RoundRobinAssignor：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1148-b4AYOl.png" alt="图片"></p>
<p><strong>StickyAssignor：</strong></p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1149-rLbj0n.png" alt="图片"></p>
<p>从上面结果可以看出，RoundRoubin 的分配策略在 Rebalance 之后造成了严重的分配倾斜。<strong>因此在生产环境上如果想要减少重分配带来的开销，可以选用 StickyAssignor 的分区分配策略。</strong> </p>
<h2 id="谈谈-Kafka-消费者重平衡机制是怎样的"><a href="#谈谈-Kafka-消费者重平衡机制是怎样的" class="headerlink" title="谈谈 Kafka 消费者重平衡机制是怎样的"></a>谈谈 Kafka 消费者重平衡机制是怎样的</h2><p><strong>所谓的消费者组的重平衡目的就是让组内所有的消费者实例对消费哪些主题分区达成一致。</strong></p>
<p>对于 Consumer Group 来说，可能随时都会有 Consumer 加入或退出，那么 Consumer 列表的变化必定会引起 Partition 的重新分配。我们将这个分配过程叫做 Consumer Rebalance，但是<strong>这个分配过程需要借助 Broker 端的 Coordinator 协调者组件，在 Coordinator 的帮助下完成整个消费者组的分区重分配，也是通过监听ZooKeeper 的 /admin/reassign_partitions 节点触发的。</strong></p>
<h3 id="Rebalance-触发与通知"><a href="#Rebalance-触发与通知" class="headerlink" title="Rebalance 触发与通知"></a>Rebalance 触发与通知</h3><p>Rebalance 的触发条件有三种:</p>
<blockquote>
<p>1）当 Consumer Group 组成员数量发生变化(主动加入或者主动离组，故障下线等)。</p>
<p>2）当订阅主题数量发生变化。</p>
<p>3）当订阅主题的分区数发生变化。</p>
</blockquote>
<p>Rebalance 触发后如何通知其他 Consumer 进程？</p>
<blockquote>
<p>Rebalance 的通知机制就是<strong>靠 Consumer 端的心跳线程</strong>，它会定期发送心跳请求到 Broker 端的 Coordinator 协调者组件,当协调者决定开启 Rebalance 后，它会将「<strong>REBALANCE_IN_PROGRESS</strong>」封装进心跳请求的响应中发送给 Consumer ,当 Consumer 发现心跳响应中包含了「<strong>REBALANCE_IN_PROGRESS</strong>」，就知道是 Rebalance 开始了。</p>
</blockquote>
<h3 id="Rebalance-协议说明"><a href="#Rebalance-协议说明" class="headerlink" title="Rebalance 协议说明"></a>Rebalance 协议说明</h3><p>其实 Rebalance 本质上也是一组协议，Consumer Group 与 Coordinator 共同使用它来完成 Consumer Group 的 Rebalance。</p>
<p>下面我看看这5种协议完成了什么功能： </p>
<blockquote>
<p>1）<strong>Heartbeat 请求：</strong>Consumer 需要定期给 Coordinator 发送心跳来证明自己还活着。</p>
<p>2）<strong>LeaveGroup 请求：</strong>主动告诉 Coordinator 要离开 Consumer Group。</p>
<p>3）<strong>SyncGroup 请求：</strong>Group Leader Consumer 把分配方案告诉组内所有成员。</p>
<p>4）<strong>JoinGroup 请求：</strong>成员请求加入组。</p>
<p>5）<strong>DescribeGroup 请求：</strong>显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用。</p>
</blockquote>
<p><strong>Coordinator 在 Rebalance 的时候主要用到了前面4种请求。</strong></p>
<h3 id="Consumer-Group-状态机"><a href="#Consumer-Group-状态机" class="headerlink" title="Consumer Group 状态机"></a>Consumer Group 状态机</h3><p>如果 Rebalance 一旦发生，就会涉及到 Consumer Group 的状态流转，此时 Kafka 为我们设计了一套完整的状态机机制，来帮助 Broker Coordinator 完成整个重平衡流程。</p>
<p>了解整个状态流转过程可以帮助我们深入理解 Consumer Group 的设计原理。5种状态，定义分别如下：</p>
<blockquote>
<p>1）<strong>Empty 状态</strong>：表示当前组内无成员， 但是可能存在 Consumer Group 已提交的位移数据，且未过期，这种状态只能响应 JoinGroup 请求。。</p>
<p>2）<strong>Dead 状态</strong>：表示组内已经没有任何成员的状态，组内的元数据已经被 Broker Coordinator 移除，这种状态响应各种请求都是一个Response：UNKNOWN_MEMBER_ID。</p>
<p>3）<strong>PreparingRebalance 状态</strong>：表示准备开始新的 Rebalance, 等待组内所有成员重新加入组内。</p>
<p>4）<strong>CompletingRebalance 状态</strong>：表示组内成员都已经加入成功，正在等待分配方案，旧版本中叫「<strong>AwaitingSync</strong>」。</p>
<p>5）<strong>Stable 状态</strong>：表示 Rebalance 已经完成， 组内 Consumer 可以开始消费了。</p>
</blockquote>
<p>5种状态流转图如下：</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1153-gTWZRv.png" alt="图片"></p>
<h3 id="Rebalance-流程分析"><a href="#Rebalance-流程分析" class="headerlink" title="Rebalance 流程分析"></a>Rebalance 流程分析</h3><p>通过上面5种状态可以看出，Rebalance 主要分为两个步骤：加入组「<strong>JoinGroup请求</strong>」和等待 Leader Consumer 分配方案「<strong>SyncGroup 请求</strong>」。</p>
<p><strong>JoinGroup请求</strong></p>
<p>组内所有成员向 Coordinator 发送 JoinGroup 请求，请求加入组，顺带会上报自己订阅的 Topic，这样 Coordinator  就能收集到所有成员的 JoinGroup 请求和订阅 Topic 信息，Coordinator 就会从这些成员中选择一个担任这个Consumer Group 的 Leader「<strong>一般情况下，第一个发送请求的 Consumer 会成为 Leader</strong>」。</p>
<p><strong>这里说的 Leader 是指具体的某一个 Consumer，它的任务就是收集所有成员的订阅 Topic 信息，然后制定具体的消费分区分配方案。</strong>待选出 Leader 后，Coordinator 会把 Consumer Group 的订阅 Topic 信息封装进 JoinGroup 请求的 Response 中，然后发给 Leader ，然后由 Leader 统一做出分配方案后，进入到下一步</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1154-gZhBei.png" alt="图片"></p>
<p><strong>SyncGroup 请求</strong></p>
<p>Leader 开始分配消费方案，<code>即哪个 Consumer 负责消费哪些 Topic 的哪些 Partition</code>。</p>
<p>一旦完成分配，Leader 会将这个分配方案封装进 SyncGroup 请求中发给 Coordinator ，其他成员也会发 SyncGroup 请求，只是内容为空，待  Coordinator 接收到分配方案之后会把方案封装进 SyncGroup 的 Response 中发给组内各成员,  这样各自就知道应该消费哪些 Partition 了。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1155-E4Jbcx.png" alt="图片"></p>
<h3 id="Rebalance-场景分析"><a href="#Rebalance-场景分析" class="headerlink" title="Rebalance 场景分析"></a>Rebalance 场景分析</h3><p>刚刚详细的分析了关于 Rebalance 的状态流转，接下来我们通过时序图来重点分析几个场景来加深对 Rebalance 的理解。</p>
<p><strong>场景一：新成员(c1)加入组</strong></p>
<p>这里新成员加入组是指组处于 Stable 稳定状态后，有新成员加入的情况。当协调者收到新的 JoinGroup 请求后，它会通过心跳机制通知组内现有的所有成员，强制开启新一轮的重平衡。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1156-fR76r7.png" alt="图片"></p>
<p><strong>场景二：成员(c2)主动离组</strong></p>
<p>这里主动离组是指消费者所在线程或进程调用 close() 方法主动通知协调者它要退出。当协调者收到 LeaveGroup 请求后，依然会以心跳机制通知其他成员，强制开启新一轮的重平衡。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1156-tzCaWi.png" alt="图片"></p>
<p><strong>场景三：成员(c2)超时被踢出组</strong></p>
<p>这里超时被踢出组是指消费者实例出现故障或者处理逻辑耗时过长导致的离组。此时离组是被动的，协调者需要等待一段时间才能感知到，<strong>一般是由消费者端参数 session.timeout.ms 控制的</strong>。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1157-4FAVNu.png" alt="图片"></p>
<p><strong>场景四：成员(c2)提交位移数据</strong></p>
<p>当重平衡开启时，协调者会要求组内成员必须在这段缓冲时间内快速地提交自己的位移信息，然后再开启正常的 JoinGroup/SyncGroup 请求发送。</p>
<p><img data-src="https://xuemingde.com/pages/image/2022/04/09/1157-KbV0VC.png" alt="图片"></p>
<h2 id="谈谈Kafka线上大量消息积压你是如何处理的"><a href="#谈谈Kafka线上大量消息积压你是如何处理的" class="headerlink" title="谈谈Kafka线上大量消息积压你是如何处理的"></a>谈谈Kafka线上大量消息积压你是如何处理的</h2><p><code>消息大量积压这个问题，直接原因一定是某个环节出现了性能问题，来不及消费消息，才会导致消息积压。</code>接着就比较坑爹了，此时假如 Kafka 集群的磁盘都快写满了，都没有被消费，这个时候怎么办？或者消息积压了⼏个⼩时，这个时候怎么办？生产环境挺常⻅的问题，⼀般不出问题，而⼀出就是⼤事故。</p>
<p>所以，我们先来分析下，在使用 Kafka 时如何来优化代码的性能，避免出现消息积压。如果你的线上 Kafka 系统出现了消息积压，该如何进行紧急处理，最大程度地避免消息积压对业务的影响。</p>
<h3 id="优化性能来避免消息积压"><a href="#优化性能来避免消息积压" class="headerlink" title="优化性能来避免消息积压"></a>优化性能来避免消息积压</h3><p>对于 Kafka 性能的优化，主要体现在生产者和消费者这两部分业务逻辑中。而 Kafka 本身不需要多关注的主要原因是，对于绝大多数使用Kafka 的业务来说，Kafka  本身的处理能力要远大于业务系统的处理能力。Kafka 单个节点，消息收发的性能可以达到每秒钟处理几十万条消息的水平，还可以通过水平扩展  Broker 的实例数成倍地提升处理能力。</p>
<p>对于业务系统处理的业务逻辑要复杂一些，单个节点每秒钟处理几百到几千次请求，已经非常不错了，所以我们应该更关注的是消息的收发两端。</p>
<p><strong>1. 发送端性能优化</strong></p>
<p>发送端即生产者业务代码都是先执行自己的业务逻辑，最后再发送消息。<strong>如果说性能上不去，需要你优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的</strong>。</p>
<p>对于发送消息的业务逻辑，只需要注意设置合适的并发和批量大小，就可以达到很好的发送性能。我们知道 Producer 发消息给 Broker 且收到消息并返回 ack 响应，假设这一次过程的平均时延是 1ms，它包括了下面这些步骤的耗时：</p>
<blockquote>
<p>1）发送端在发送网络请求之前的耗时。</p>
<p>2）发送消息和返回响应在网络传输中的耗时。</p>
<p>3）Broker 端处理消息的时延。</p>
</blockquote>
<p>假设此时你的发送端是单线程，每次只能发送 1 条消息，那么每秒只能发送 1000 条消息，这种情况下并不能发挥出 Kafka 的真实性能。此时无论是增加每次发送消息的批量大小，还是增加并发，都可以成倍地提升发送性能。</p>
<p>如果当前发送端是在线服务的话，比较在意请求响应时延，此时可以采用并发方式来提升性能。</p>
<p>如果当前发送端是离线服务的话，更关注系统的吞吐量，发送数据一般都来自数据库，此时更适合批量读取，批量发送来提升性能。</p>
<p><strong>另外还需要关注下消息体是否过大</strong>，如果消息体过大，势必会增加 IO 的耗时，影响 Kafka 生产和消费的速度，也可能会造成消息积压。</p>
<p><strong>2. 消费端性能优化</strong></p>
<p>而在使用 Kafka 时，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。</p>
<p>要是消费速度一直比生产速度慢，时间长了系统就会出现问题，比如Kafka 的磁盘存储被写满无法提供服务，或者消息丢失，对于整个系统来说都是严重故障。</p>
<p>所以我们在设计的时候，<strong>一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行</strong>。</p>
<p>消费端的性能优化除了优化业务逻辑外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。需要注意的是，<strong>在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区数量，确保 Consumer 的实例数和分区数量是相等的，如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的</strong>。</p>
<h3 id="消息积压后如何处理"><a href="#消息积压后如何处理" class="headerlink" title="消息积压后如何处理"></a>消息积压后如何处理</h3><p>日常系统正常时候，没有积压或者只有少量积压很快就消费掉了，但某时刻，突然开始积压消息且持续上涨。这种情况下需要你在短时间内找到消息积压的原因，迅速解决问题。</p>
<p><strong>导致消息积压突然增加，只有两种：发送变快了或者消费变慢了。</strong></p>
<p>假如赶上大促或者抢购时，短时间内不太可能优化消费端的代码来提升消费性能，<strong>此时唯一的办法是通过扩容消费端的实例数来提升总体的消费能力</strong>。如果短时间内没有足够的服务器资源进行扩容，只能降级一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，保证重要业务服务正常。</p>
<p>假如通过内部监控到消费变慢了，需要你检查消费实例，分析一下是什么原因导致消费变慢？</p>
<blockquote>
<p>1、优先查看日志是否有大量的消费错误。</p>
<p>2、此时如果没有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在哪里「<strong>触发死锁或者卡在某些等待资源</strong>」。</p>
</blockquote>
<hr>
<blockquote>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvQ0c5M3hCNnViakpSbFlKbHhodGNTZw==">【建议收藏】Kafka 面试连环炮, 看看你能撑到哪一步?（中）<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>

      
    </div>
   <div>
        
    </div>

   
    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>

  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/12/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><span class="page-number current">13</span><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><a class="extend next" rel="next" href="/page/14/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



           </div>
          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

          
        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="meadel"
      src="/images/touxiang.jpeg">
  <p class="site-author-name" itemprop="name">meadel</p>
  <div class="site-description" itemprop="description">我的愿望，世界和平</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">154</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uY24vdXNlci80MDE5NDcwMjQ0MjU4NTUyL3Bvc3Rz" title="掘金 → https:&#x2F;&#x2F;juejin.cn&#x2F;user&#x2F;4019470244258552&#x2F;posts"><i class="fa fa-share-alt fa-fw"></i>掘金</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1ZV9taW5k" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;xue_mind"><i class="fa fa-th-list fa-fw"></i>CSDN</span>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-star"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">meadel</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">846k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">12:49</span>
</div>
  <div class="powered-by">这个世界会好吗？我是那么热爱这个世界。  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="js/canvas-ribbon.js"></script>
  <script src="//lib.baomitu.com/animejs/3.2.1/anime.min.js"></script>
  <script src="//lib.baomitu.com/next-theme-pjax/0.5.0/pjax.min.js"></script>
  <script src="//lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script>
  <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"></script>
  <script src="//lib.baomitu.com/medium-zoom/1.0.6/medium-zoom.min.js"></script>
  <script src="https://lib.baomitu.com/lozad.js/1.16.0/lozad.min.js"></script>
  <script src="https://lib.baomitu.com/pangu/4.0.7/pangu.min.js"></script>
  <script src="//lib.baomitu.com/velocity/1.5.2/velocity.min.js"></script>
  <script src="//lib.baomitu.com/velocity/1.5.2/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>


  <script defer src="js/three.min.js"></script>


  
  <script data-pjax>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>



  <script data-pjax>
  if (CONFIG.page.isPost) {
    wpac_init = window.wpac_init || [];
    wpac_init.push({
      widget: 'Rating',
      id    : 34163,
      el    : 'wpac-rating',
      color : 'fc6423'
    });
    (function() {
      if ('WIDGETPACK_LOADED' in window) return;
      WIDGETPACK_LOADED = true;
      var mc = document.createElement('script');
      mc.type = 'text/javascript';
      mc.async = true;
      mc.src = '//embed.widgetpack.com/widget.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
    })();
  }
  </script>

  
<script src="/js/local-search.js"></script>









<script data-pjax>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




    <div id="pjax">
  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//lib.baomitu.com/valine/1.4.17/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'xOnoKG9QyBMz9vYupNusn9fn-gzGzoHsz',
      appKey     : 'RfiNClAkp7Ewe9rlzrjAQEXC',
      placeholder: "吐槽一下...",
      avatar     : 'monsterid',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : '',
      requiredFields : ['nick','mail']
    });
  }, window.Valine);
});
</script>

    </div>
  <link rel="stylesheet" href="/dist/APlayer.min.css">
  <div id="aplayer"></div>
  <script type="text/javascript" src="/dist/APlayer.min.js"></script>
  <script type="text/javascript" src="/dist/music.js"></script>
</body>
</html>
